---
tags:
  - 深度学习
---
# 卷积神经网络

卷积神经网络 (convolutional neural network, CNN) 是一种强大的，为处理图像数据而设计的神经网络。基于卷积神经网络架构的模型在[[00-笔记/深度学习/计算机视觉|计算机视觉]]领域中已经占据主导地位，得益于参数少于全连接架构的网络，且卷积神经网络的结构很容易使用 GPU 进行并行计算，因此卷积神经网络不仅可以高效的采样从而获得精确的模型，还能高效的进行计算。

## 从全连接层到卷积

[[00-笔记/深度学习/多层感知机]] 的结构非常适合于处理表格数据，但是当处理高维感知数据时，这种结构可能会变得不实用。而且全连接神经网络的参数数量非常大，在处理一些复杂的数据时效率非常低。例如在处理图像时，一个图像可以有着几百万像素，因此我们需要一种更加高效的方法提取图像中的信息。

一般而言，我们处理图像一般会有下面的另个特性：
1. 平移不变性：不管检测对象出现在图像的哪个位置，神经网络的前几层应该对相同的图像区域有着相似的反映。
2. 局部性：神经网络的前几层应该只探索输入图像中的局部区域，而不在意图像中相隔较远的区域。

### 数学表示

假设多层感知机输入的是二维图像 $X$，其隐藏层表示为 $H$ ，为了保证输出可以保持空间结构的信息，则 $H$ 应当是一个与输入相同形状的矩阵。使用 $[X]_{i,j}$ 与 $[H]_{i,j}$ 分别表示输入图像与隐藏表示在位置 $(i, j)$ 的像素，为了使下一个神经元可以接受上一个神经元输入的所有信息，我们令权重为一个四阶张量 $W$，设 $U$ 为偏置参数，那么有：
$$
\begin{align}
[H]_{i,j}&=[U]_{i,j} + \sum_k\sum_l[W]_{i,j,k,l}[X]_{k,l}
\\&=[U]_{i,j} + \sum_a\sum_b[V]_{i,j,a,b}[X]_{i+a,j+b}
\end{align}
$$
其中 $V$ 仅仅是 $W$ 重新索引下标的结果，所以两个式子没有本质上的区别，上式相当于图像数据的全连接层。在满足平移不变形与局部性的要求下，我们对上式进行修改。

#### 平移不变性

为了满足检测对象在输入 $X$ 中平移，仅导致目标的隐藏表示在 $H$ 中平移，那么 $[V]_{i,j,a,b}$ 应当不依赖 $i,j$ 的值，即 $[V]_{i,j,a,b}=[V]_{a,b}$，并且 $[U]_{i,j}=u$ 是一个常数，所以上式变为：
$$
[H]_{i,j} = u+\sum_a\sum_b[V]_{a,b}[X]_{i+a,j+b}
$$
这就是卷积操作。

#### 局部性

为了满足局部性，那么 $a,b$ 的值就不能过大，我们设范围限制为 $\Delta$，那么卷积操作就应当为：
$$
[H]_{i,j} = u+\sum_{a=-\Delta}^\Delta\sum_{b=-\Delta}^\Delta[V]_{a,b}[X]_{i+a,j+b}
$$
上式就是卷积层 (convolutional layer)，而 $V$ 称为卷积层的卷积核 (convolution kernel) 或者滤波器 (filter)，或者简单的称为卷积层的权重。通过权重是卷积层可以学习的参数，而卷积核的大小 $\Delta$ 则是作为超参数或者网络的结构而被实现设定。

#### 卷积

实际上这个'卷积'与数学上的卷积定义式不相符的，在数学上，卷积被定义为了两个函数中一个函数翻转并位移 $x$ 后，与另一个函数的重叠。假设两个函数为 $f,g:\mathbb R^d\to \mathbb R$，那么这两个函数的卷积为：
$$
(f*g)(x)=\int f(z)g(x-z)dz
$$
当函数为离散时，积分就变成了求和。
$$
(f*g)(x)=\sum_af(a)g(x-a)
$$
而对于二维张量，卷积操作应当为：
$$
(f*g)(i,j)=\sum_a\sum_bf(a,b)g(i-a,j-b)
$$
可以看出，上式与之前定义的卷积形式上并不相同，因为数学上的卷积操作使用的是相减。虽然我们总是可以匹配两个式子的符号，但是实际上我们所使用的卷积在数学上更加接近与互相关 (cross-correlation)操作，接近于传统计算机视觉中使用的 [[00-笔记/计算机视觉/图像滤波#滤波|滤波]]
，但是是由模型自己学习得到的。
#### 通道

在实际中，图像并不能仅使用一个二维矩阵描述，因为一般的图像都包含了 RGB 三个通道。实际上，图像是一个三维的张量，此时我们对卷积的定义也需要进行修改，为了更好的表述卷积运算，我们在 $V$ 中添加第四个坐标表示输出的通道：
$$
[H]_{i,j,d} = u+\sum_{a=-\Delta}^\Delta\sum_{b=-\Delta}^\Delta\sum_c[V]_{a,b,c,d}[X]_{i+a,j+b,c}
$$
一般而言，输出的通道数由卷积核的数量决定。

## 图像卷积

卷积在图像处理中有着最广泛的运用。在计算中，我们使用卷积核在图像上进行移动，每个位置都计算一次加权求和，最终得到一个与输入形状相同，大小更小的输出。在 pytorch 中，我们使用 `conv2d` 函数来实现卷积层的操作，即对输入进行卷积并加上偏置，使用 `nn.Conv2d` 来定义一个二维卷积层。

卷积核可以通过对数据的学习获得，同样使用自动微分功能就可以实现，实际上，无论使用严格的卷积运算还是使用互相关运算，卷积层的输出不会受到影响，这两种运算直接的差异仅仅只有参数不同，为了与深度学习的文献中的表述相同，我们仍然将互相关运算称为卷积。

### 特征映射和感受野

这里给出两个概念，特征映射 (feature map) 与感受野 (receptive field)。其中特征映射指将图像通过卷积操作转换为输出的过程，感受野指一个输出在经过卷积层之前对应的输入的大小。

### 填充和步幅

在前面的介绍中，卷积的输出形状只与输入形状与卷积核的大小有关，接下来介绍的填充 (padding) 和步幅 (stride) 也可以影响输出的大小。其中填充是为了不在卷积的过程中损失图像边缘的信息，步幅是为了在原始输入分辨率过于冗余时减少数据量。

#### 填充

由于在应用多层卷积时，我们常常丢失边缘像素。在使用小卷积核时，对于任何卷积操作，我们可能只会损失几个像素的信息，但是当我们使用连续的卷积层时，累计的丢失像素就会越来越多。解决这个问题的一个简单的方法就是填充，即**在输入图像的边缘填充元素**（通常是 0）。

设卷积核的大小为 $(k_h,k_w)$，我们一般在边缘填充 $p_h=k_h-1$ 与 $p_w=k_w-1$ 层，使输入与输出有相同的高度与宽度。在填充操作中，当 $k$ 是奇数时，我们常在对应边缘填充 $p/2$ 行，而当 $k$ 是偶数时，我们在顶部或左边填充 $\lceil p/2\rceil$ 行，在底部或者右边填充 $\lfloor p/2\rfloor$ 行。

一般而言卷积核的高度与宽度都是奇数，这样的好处是可以在保持空间维度的同时，填充操作可以在边缘填充相同数量的行。在 pytorch 的卷积层中，我们通过指定 `padding` 参数来指定边缘填充的行数或者列数。

#### 步幅

在计算卷积时，卷积窗口从输入张量的左上角开始，向下、右滑动，一般我们默认每次滑动一个元素，而在某些情况下，为了高效计算或者缩减采样次数，卷积窗口可以每次多滑动几个元素。我们将每次滑动的长度称为步幅。

在 pytorch 的卷积层中，我们通过 `stride` 参数指定步幅。

> [!example] 
> 对于填充 $p_h$ 行和 $p_w$ 列，输出的形状为
> $$
(n_h-k_h+p_h+1)\times (n_w-k_w+p_w+1)
>$$
>通常取 $p_h=k_h-1,p_w=k_w-1$
>- 当 $k_h$ 为奇数时，在上下两侧填充 $p_h/2$
>- 当 $k_h$ 为偶数时，在上侧填充 $\lceil p_h/2\rceil$，在下侧填充 $\lfloor p_h/2\rfloor$（上侧向上取整，下侧向下取整）

### 多输入多输出通道

每个 RGB 图像都是一个三维的 $3\times h\times w$ 的张量，我们将这个大小为 3 的轴称为**通道** (channel) 维度。

#### 多输入通道

当输入包含多个输入通道时，我们需要构造一个与输入通道数相同的卷积核，以便与输入数据进行运算，根据卷积的计算方式，多通道图像与多通道卷积核进行卷积的计算方式为：**图像的对应通道与卷积核的对应通道进行卷积操作，最后将这些通道的结果相加。**

#### 多输出通道

前面的讨论中卷积层都只有一个输出通道，在最流行的神经网络的架构中，随着神经网的层数增加，我们通常会增加神经网络的输出通道的维数，通过减少空间分辨率获得更大的通道深度。直观的说，我们仅不同的通道视为对不同特征的响应。因此，多输出通道并不是学习多个单通道检测器。

要达到多输出通道的效果，我们使用多个卷积核，每个卷积核对应一个通道进行输出。

#### 1 × 1 卷积核

1 × 1 卷积核虽然看上去没有多大的意义，因为卷积本质上是提取相邻像素间的相关特征。尽管如此， 1 × 1 卷积核仍然十分流行。1 × 1 卷积核虽然不能在高度与宽度上提取相关特征，但是却唯一地提取了通道上的相关特征。一般的，我们使用 1 × 1 卷积核来进行通道压缩。

> [!note] 卷积的好处
> [[00-笔记/深度学习/多层感知机|全连接网络]] 适合用于各种各样的变化，但是不一定把特定的任务做好。在进行图像计算这类操作时，全连接网络需要付出的代价过大。
> 图像中的一些模式远比整个图像要小，同时一些相同的模式可能出现在不同的位置。
> 卷积层是专门设计用于处理图像的网络层，可以从图像的不同位置提取类似的特征。

## 汇聚层

通常在处理图像时，我们希望逐渐降低隐藏表示的空间分辨率，聚合信息，随着层数的增加，每个神经元的感受野就越大。此外，在检测较低层时，我们希望图像的轻微移动不会影响判断效果。汇聚层 (pooling layer) 也称为池化层的目的是降低卷积层对位置的敏感性，同时降低对空间采样表示的敏感性。

### 最大汇聚与平均汇聚

与卷积层类似，汇聚层运算有一个固定的窗口实现，该窗口在输入数据上进行滑动，遍历每一个位置并计算一个输出。与卷积层不同的是，汇聚层不包含参数，汇聚操作是确定性的，如最大汇聚 (maximum pooling) 与平均汇聚 (average pooling) 就是对窗口中的所有元素取最大值或者平均值。

与卷积层一样，汇聚层也可以改变输出形状，通过填充和步幅操作获得所需的输出形状。在处理多个通道时，汇聚层在每个通道上单独进行运算，因此汇聚层不会改变输入数据的通道数。

在 pytorch 中，使用 `nn.MaxPool2d` 来创建一个最大汇聚层，它可以传入参数 `padding` 与 `stride` 来控制形状。其余的汇聚层同理。

## 其他卷积操作

### 空洞卷积

一般而言，卷积层想要获得更大的感受野，可以通过：
- 增加卷积核的大小
- 增加卷积层数
- 在卷积之前进行汇聚

空洞卷积希望通过较小的参数量取得更大的感受野。它通过给卷积核插入空洞来变相的增加其大小。
![[Assets/Pasted image 20240624174230.png]]

### 转置卷积/微步卷积

某些场景下，希望输出比输入多很多。例如图像生成任务中，输入是很小的图像，输出需要一级一级放大，此时我们通过转置卷积或者微步卷积实现。

## 卷积神经网络 LeNet

LeNet 神经网络是最早的卷积神经网络，在 1989 年由 AT&T 贝尔工作室的研究员 Yann LeCun 提出，目的是识别图像中的手写数字。在当时，LeNet 取得了与[[00-笔记/机器学习/支持向量机|支持向量机]]向媲美的成果，称为了监督学习的主流方法。

总体来看，LeNet (LeNet-5) 有以下两个部分组成：
- 卷积编码器：由两个卷积层组成
- 全连接稠密块：有 3 个全连接层组成

其结构如下图所示：![[Assets/Pasted image 20230525201304.png]]
每个卷积块中的基本单元是一个卷积层，一个 sigmoid 激活函数和平均汇聚层。每个卷积层使用 $5\times 5$ 卷积核和一个 sigmoid 函数，这些层将输入映射到多个二维特征输出，同时增加通道的数量。第一个卷积核有 6 个通道输出，而第二个卷积核有 16 个通道输出。每个 $2\times2$ 汇聚操作通过空间采样将维数减少四倍。

为了将卷积块传递给稠密块，我们必须在小批量中展平每个样本。该操作可以通过 `nn.Flatten()` 层来实现。最后通过三个全连接层和激活函数可以得到最终的结果。