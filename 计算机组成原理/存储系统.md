---
aliases:
  - storage 
tags:
  - 计算机组成原理
---

# 存储系统

## 存储器概述

存储器包含 CPU 中的**寄存器、Cachae、主存、辅存**。存储器的层次结构，从速度快到速度慢，从容量小到容量大，从价格高到价格低可以划分为：
- 寄存器：CPU 在进行计算时会将变量保存到寄存器中；
- Cache：高速缓冲存储器，用于缓冲主存和 CPU 速度不匹配的问题；
- 内存：可以直接被 CPU 读写的最大单位，后面的都不可以被 CPU 直接读写；
- 辅存：一般将磁盘称为辅存，包括机械硬盘和固态硬盘；
- 外存：光盘、U 盘等，辅存和外存一般看作一个东西，很少区分开；

> [!note] 存储器结构层次
> 存储器层次结构的主要思想是**上一层的存储器作为低一层存储器的高速缓存**。当 CPU 要从存储器中存取数据时，先访问 Cache，若不在 Cache 中，则访问主存，若不在主存中，则访问磁盘。
> - **Cache-主存层**主要解决 CPU 和主存速度不匹配的问题。主存和 Cache 之间的数据调动是由硬件自动完成的，*对所有的程序员均是透明的*。
> - **主存-辅存层**主要解决存储系统的容量问题，主存和辅存之间的数据调动是由硬件和操作系统共同完成的，*对应用程序员是透明的*。

> [!tip]
> 在 Cache-主存层和主存-辅存层中，上一层中的内容都只是下一层中的内容的副本，也即 Cache (或者主存) 中的内容只是主存 (或者辅存) 中的内容的一部分。

### 存储器的分类

存储器种类繁多，可以从不同的角度对存储器进行分类。

> [!note] 按层次结构分类
> 1. 主存储器。简称主存，也称为内存，用来存放计算机运行期间所需的程序和数据。CPU 可以直接随机地对其进行访问，也可以通过和高速缓冲存储器 (Cache) 及辅助存储器交换数据。其特点是*容量较小，存储器速度较快，每位的价格较高*。
> 2. 辅助存储器。简称为辅存，也称为外存储器或外存，用来存放当前暂时不用的程序和数据，以及一些需要永久性保存的信息。辅存的内容需要调入主存后才能被 CPU 访问，其特点是*容量大，存取速度较慢，单位成本低*。
> 3. 高速缓冲存储器。简称 Cache，位于主存和 CPU 之间，用来存放当前 CPU 经常使用的指令和数据，以便 CPU 能够高速地访问它们。Cache 的存取速度可以与 CPU 的速度相匹配，但是*储存容量小、价格高*。现代计算机通常将它们制作在 CPU 中。

> [!note] 按存储介质分类
> 1. 半导体存储器，以半导体介质存储信息
> 2. 磁性表面存储器：以磁性材料存储信息
> 3. 光存储器：以光介质存储信息

> [!note] 按照存取方式分类
> 1. 随机存储器 (random Access Memory, RAM)。存储器读写任何一个存储单元所需的时间都相同，与单元的物理位置无关。其优点是*读写方便，使用灵活*，主要用于主存或者高速缓冲存储器。RAM 又分为静态 RAM 和动态 RAM。
> 2. 只读存储器 (Read Only Memory, ROM)。存储器的内容只能顺序读出而不能写入，信息一旦写入存储器就固定不变，即使断电，内容也不会丢失。因此，通常用它存放固定不变的程序、常数和汉字字库等。它与随机存储器一起作为主存的一部分，统一构成主存的地址域。
> 3. 串行访问存储器。对存储单元进行读写操作时，需按照其物理位置的写入顺序寻址，包括顺序存存取存储器和直接存取存储器。
> 	1. 顺序存取存储器 (Sequential Access Memory, SAM)：读写一个存储单元所需的时间取决于存储单元所在的物理位置。例如磁带。
> 	2. 直接存取存储器 (Direct Access Memory, DAM)：既有随机存取性也有顺序存储性。先直接选取信息所在的区域，然后按顺序方式存取。例如磁盘、光盘等。
> 4. **相联存储器** (Associative Memory)，既是可以**按内容访问**的存储器 (Content Addressed Memory, CAM)**，也可以按照内容检索到存储位置**进行读写。" 快表 " 就是一种相联存储器。

> [!note] 按照信息的可保存性
> 1. 断掉后，存储信息消失的存储器，称为**易失性存存储器** (例如 RAM)。
> 2. 断电后，存储信息依然保持的存储器，称为**非易失性存储器** (磁盘，光盘，ROM)。
> 3. 信息读出后，原存储信息被破坏，称为破坏性读出。具有破坏性读出性能的存储器，每次读出操作后，必须紧接着一个再生的操作，以便恢复破坏的信息。
> 4. 信息读出后，原存储信息不被破坏，称为非破坏性读出。

### 存储器的性能指标

设计存储系统所追求的目标就是大容量、低成本和高速度，因此存储器的三个主要性能指标为：
1. **存储容量**：存储字数×存储字长 (例如 1M×8 位)。存储字数表示存储器的地址空间大小，字长表示一次存取操作的数据量。
2. **单位成本**：每位价格=总成本/总容量。
3. **存储速度**：数据传输速率 (每秒传送信息的位数) = 数据的宽度/存储周期 (数据的宽度即存储字长)
	1. 存取时间 ($T_{a}$)：存取时间是指从启动一次存储器操作到完成该操作所经历的时间，分为读出时间和写入时间。
	2. 存取周期 ($T_{m}$)：存取周期又称为读写周期或者访问周期，指存储器进行一次完整的读写操作所需的全部时间，即连续两次独立的访问存储器操作 (读或者写) 之间所需的最小时间间隔。
	3. 主存带宽 ($B_{m}$)：主存带宽又称为数据传输速率，表示每秒从主存进出信息的最大数量，单位为字/秒、字节/秒或者位/秒。

> [!note]
> **存取时间不等于存取周期，通常存取周期大于存取时间**。这是因为对任何一种存储器，在读、写操作后，总要有一段恢复内部状态的复原时间。对于破坏性读出的存储器，存取周期往往比存取时间大得多。

> [!example]- 存储器时间与存储周期的关系
> ![[image/storage-1.png|300|存取周期与存取时间的关系]]

## 主存储器的基本组成

### 基本半导体元件及原理

一个基本存储元一般可以使用下面的两种元件组合构成：
1. MOS 管：半导体元件，输入电压到达某个阈值时，MOS 管就可以接通。
2. 电容：使用电容的充电与放电状态表示二进制的 01。

> [!note]
> 将多个存储元以合理的方式连接，可以构成一个存储元。一般存储一个字节的存储元集合称为一个存储单元。使用译码器可以从多个存储单元中选择一条读出一个字的数据，送到数据总线上。然后 CPU 可以从数据总线中得到的数据。

一般而言，一块存储芯片包括下面的引脚：
1. 片选线：表示该芯片目前是否可用，一块内存条会有多块存储芯片，内存条会根据地址来选择不同的存储芯片。
2. 地址线：表示需要读取的地址，将会被输入给译码器。
3. 数据线：地址线表示的地址所在的数据单元的数据。
4. 读、写控制线：可以被设计为两根，也可以被设计为一根。表示数据的读取与写入。

> [!example]- 主存储器的基本组成
> ![[image/存储系统-1.png#center|300|主存储器的基本组成]]

> [!example]- 一块完整的存储芯片
> ![[image/storge_4.png]]
> 1. 译码驱动：译码器与驱动器电路。译码器用于解析地址，而驱动器用于稳定译码器输出的信号。
> 2. 存储矩阵：将多个存储元以合理的方式连接得到的存储体。是数据存放的地方。
> 3. 读写电路：控制电路中控制读与写的部分。
> 4. 其他部分：包括供电、接地等功能。

> [!note] [[计算机组成原理/计算机系统概述#^MarMdr|MAR 与 MDR]]
> 指令执行的过程中需要访问主存时，CPU 首先把被访问单元的地址送到 MAR 中，然后通过地址线将 MAR 中的地址送到主存中的地址寄存器，以便地址译码器进行译码，选中相应单元，同时 CPU 将读写信号通过控制线送到主存的读写控制电路。
> - 若是写操作，则 CPU 同时将要写的信息送到 MDR 中，在读写控制电路的控制下，经过数据线将 MDR 中的数据写入选中的单元。
> - 若是读操作，则主存将选中单元的内容读到数据线中，然后被送到 MDR 中。
>
> **因此，MDR 的位数与数据线的位数相同，MAR 的位数与地址线的位数相同。**

> [!tip]
> 数据线的位数通常等于存储字长，因此 MDR 的位数通常等于存储字长。若数据线的位数不等于存储字长，则 MDR 的位数由数据线的位数决定。

根据上面的原理，可以得到一个存储体的总容量的计算方式为**存储单元数×存储字长**。常见的描述：
- $8k\times 8$ 位，即 $2^{10+3}\times 8bit$
- $8k\times 1$ 位，即 $2^{10+3}\times 1bit$
- $64k\times 16$ 位，即 $2^{10+6}\times 16bit$

> [!note] 寻址方式
> 现代计算机一般是按字节编址的，但是支持按照不同的方式寻址：
> 1. 按字节寻址，即每个存储单元对应一个地址。
> 2. 按字寻址，即按照存储字长来寻址，存储字长个单元对应相应数量的地址。我们在计算中可以将字的编号左移相应的位数，来得到其地址。
> 3. 按半字寻址，即按照存储字长的一半寻址。
> 4. 按双字寻址，即按照两个存储字长来寻址。
>
> 常见的描述寻址的说法是 CPU 的寻址范围、可寻址单元个数等，即按照对应的寻址方式，可以得到的地址的个数。

> [!tip] 存储字与机器字
> 在存储器中，数据按照存储字存储，而 CPU 是按照机器字读取数据的。因此，CPU 的一次读取可能会读出多个存储字的数据。一般而言，在引入了 [[计算机组成原理/数据的表示和运算#数据的对齐|边界对齐]] 后，我们的数据一般按照如下格式存储：
> $$
\begin{array}{|c|c|c|c|}
\hline
\text{0x00} & \text{0x01} & \text{0x02} & \text{0x03} \\ \hline
\text{0x04} & \text{0x05} & \text{0x06} & \text{0x07} \\ \hline
\text{0x08} & \text{0x 09} & \text{0x0A} & \text{0x0B} \\ \hline
\end{array}
> $$
> 在上面这个例子中，存储字是 1 个字节，而机器字是 4 个字节。如果我们给出 $\text{0x00}$ 地址，则将会直接取出第一行中的所有内容。

## 主存储器

我们通常把存放一个二进制位的物理器件称为**存储元**，它是存储器的最基本的构件。地址码相同的多个存储元构成一个存储单元，若干存储单元的集合构成存储体。

半导体存储器分为随机存储器 (RAM) 和只读存储器 (ROM)。而 RAM 又分为静态随机存储器 (SRAM) 和动态随机存储器 (DRAM)，主存储器主要由 DRAM 实现，而靠近处理器的那一层 (Cache) 则由 SRAM 实现。

> [!note] SRAM 和 DRAM 的区别
> 1. 存储元不一样 (核心区别)：
> 	1. DRAM 使用栅极电容存储信息：破坏性读出，读写后应该有重写的操作，称为再生。读写速度更**慢**。每个存储元的制造成本**更低**，集成度更**高**，功耗**低**。
> 	2. SRAM 使用双稳态触发器存储信息：读出数据，触发器状态保持稳定，是非破坏性读出，无需重写。读写速度更**快**。每个存储元制造成本更**高**，集成度**更低**，功耗**大**。
> 2. DRAM 常用作 Cache，SRAM 常用作内存。
> 3. DRAM 需要进行刷新，SRAM 不需要进行刷新。

|  类型特点  | SRAM (静态 RAM) | DRAM (动态 RAM) |
| :----: | :-----------: | :-----------: |
|  存储信息  |      触发器      |      电容       |
| 破坏性读出  |       否       |       是       |
|   再生   |      不需要      |      需要       |
|  运行速度  |       快       |      相对慢      |
|  集成度   |       高       |       低       |
|  发热量   |       大       |       小       |
|  存储成本  |       高       |       低       |
| 易失性存储器 |      易失       |      易失       |
|   刷新   |      不需要      |      需要       |
| 送行列地址  |      同时送      |     分两次送      |
|   用途   |   常用于 Cache   |     常用于主存     |

> [!warning] SRAM 与 DRAM 都是易失性存储器。

> [!info] 行列地址
> 将地址的前半部分作为行地址，送入行地址译码器，将后半部作为列地址，送入列地址译码器。**使用行列地址可以减少选通线的数量**^[也称为字选线]。
>
> 对于一个简单的存储器模型来说，我们可以通过一系列选通线和一个译码器来选择对应地址的存储单元。假设有 $n$ 位地址，则需要 $2^{n}$ 个选通线来选通 $2^{n}$ 个存储单元。
>
> 为了节约选通线的个数，我们可以采用两个译码器来实现，即将存储单元按照行列排成一个矩阵，使用行译码器和一个行地址来选择一行，使用一个列译码器和一个列地址来选择一列，通过行列信息就可以得到目标的存储单元。假设有 $n$ 位地址，我们使用前 $n/2$ 位表示行，后 $n/2$ 表示列，则需要选通线 $2^{n/2}+2^{n/2}$ 根选通线选通 $2^{n}$ 个存储单元。

### SRAM

静态随机存储器 SRAM 的存储元是用双稳态触发器 (六晶体管 MOS) 来记忆信息的，静态是指即使信息被读出后，它仍然保持其原状态而不需要再生 (**非破坏性读出**)。

> [!note]
> SRAM 的读取速度快，但是集成度低，功耗较大，价格昂贵，一般用于高速缓冲存储器 (Cache)。

> [!example]- SRAM 存储元
> ![[image/storge-3.png#center|400|SRAM]]
> SRAM 由双稳态的触发器来存储信息，因此是非破坏性的读出。SRAM 不需要刷新，速度更快，因此可以用于高速缓冲器。

### DRAM

动态随机存储器 (DRAM) 是利用存储元电路中栅极电容上的电荷来存储信息的，DRAM 的基本存储元通常只使用一个晶体管，所以它比 SRAM 的密度要高很多。

> [!note]
> 相对于 SRAM 来说，DRAM 具有集成度高、价位低和功耗低等有点，但是 DRAM 的存取速度比 SRAM 慢，且必须定时刷新和读后再生，一般用于大容量的主存系统。

> [!example]- DRAM 存储元 (栅极电容)
> ![[image/storge-2.png#center|DRAM]]
> 使用栅极电容，则信息被存储在电容中，当我们读取数据时，需要由栅极电容放电来得到数据。因此，DRAM 是破坏性读出，在读出数据后，需要对其重新充电，即再生。

#### DRAM 的刷新

DRAM 电容上的电荷一般只能维持 1~2ms，因此即使电源不断电，信息也会自动消失。此外，读操作会使其状态发生改变 (破坏性读出)，需要读后再生，因此其被称为动态存储器。

刷新可以采用读出的方法进行，根据读出的内容对相应的单元进行重写，即读后再生。对同一行进行相邻两次刷新的时间间隔称为**刷新周期**，通常使用 2ms。常用的刷新方式有以下 3 种：
1. 集中刷新：集中安排时间全部刷新。*在一个段固定的时间内，一次对存储器的所有行进行逐一再生，再次期间停止对存储器的读写操作，称为死时间，也称为访存死区*。
	- 优点：读写操作时不再受刷新工作的影响。
	- 缺点：在集中刷新区间不能访问存储器。
2. 分散刷新：将一个存储器系统的工作周期分为两部分：前半部分用于正常的读操作，后半部分用于刷新。*这种刷新方式大大增加了系统的存储周期，如果存储器芯片的存取周期为 0.5μs，则系统的存取周期为 1μs*。
	- 优点：没有死区。
	- 缺点：加长了系统的存取周期。
3. 异步刷新：结合了前两种方法，使得在一个刷新周期内每一行仅刷新一次，即将每行的刷新分散到不同的时间中。具体做法是将刷新周期除以行数，得到相邻两行之间刷新的时间间隔 t，每隔时间 t 产生一次刷新请求。
	- 优点：使得死区的分布分散，避免让 CPU 连续等待过长时间。

> [!note]
> DRAM 刷新需要注意以下问题：
> 1. 刷新对于 CPU 是透明的，刷新不依赖于外部访问，是自动完成的。
> 2. DRAM 的刷新是以行为单位的，由芯片内部自行生成行地址。*对于有多个 DRAM 的芯片，刷新是各自芯片自主完成的，与其他芯片无关。也就是说，刷新是所有芯片一起完成的*。
> 3. 刷新操作类似于读操作，但是不同。
> 4. 刷新不需要选片，整个存储器的所有芯片同时被刷新。
> 5. 这里的刷新不需要读出数据，再写入数据，而是由专用电路将数据通过一个放大器再输送回到存储元中，因此只需要一个存取周期。

> [!warning]
> 虽然 DRAM 的刷新和再生都是恢复数据，但是刷新与再生的过程并不完全相同。
> - 刷新：以行为单位，逐行恢复数据。
> - 再生：恢复被读出的单元的数据。

> [!note] DRAM 芯片缓冲器容量
> 目前更加常用的是 SDRAM (同步 DRAM) 芯片，其工作方式与传统 DRAM 不同。
> - 传统的 DRAM 与 CPU 采用异步方式交换数据，CPU 发出地址和控制信号后，经过一段延迟时间，数据菜读出或写入，CPU 不进行其他工作。
> - SDRAM 与 CPU 采用同步方式交换数据，它将 CPU 发出的地址和控制信号锁存起来，CPU 在其读写完成之前可以进行其他操作。SDRAM 的每一步操作都在系统时钟的控制下进行，支持突发传输方式^[突发传输方式指在寻址阶段发送数据单元的首地址，在传输阶段传送多个连续单元的数据]。第一次存取时给出首地址，同一行的所有数据都被送到行缓冲器，因此，以后每个时钟都可以连续地从 SDRAM 输出一个数据。*行缓冲器用于缓存指定行中整行的数据，其大小为列数×位平面数，通常用 SRAM 实现*。

> [!note] DRAM 的地址线复用技术
> DRAM 通常用于大容量的内存，因此为了减少其引脚，我们常在行列地址的基础上，使用地址线复用技术，即使用一个译码器电路，将地址分为行、列地址，分两次送入 DRAM 中，第一次送行地址，第二次送列地址，使得需要的地址线减半。即 DRAM 的芯片引脚数减半。
>
> **由于地址复用技术的存在，如果为 DRAM 增加一根地址线，则地址范围提高到原来的 4 倍**。

> [!warning] 涉及到 DRAM 芯片的引脚，默认使用地址线复用技术，因此只需要一半的地址线

#### DRAM 芯片的读写周期

- 读周期：在 $\overline{\text{RAS}}$ 有效前将行地址送到芯片的地址引脚，$\overline{\text{CAS}}$ 滞后 $\overline{\text{RAS}}$ 一段时间，在 $\overline{\text{CAS}}$ 有效前再将列地址送到芯片的地址引脚，$\overline{\text{RAS}}$、$\overline{\text{CAS}}$ 应该至少保持 $t_{\text{RAS}}$ 和 $t_{\text{CAS}}$ 的时间。在读周期中 $\overline{\text{WE}}$ 为高电平，并在 $\overline{\text{CAS}}$ 有效前建立。
- 写周期：行列选通信号的时序关系与读周期相同。在写周期中 $\overline{\text{WE}}$ 为低电平，同样在 $\overline{\text{CAS}}$ 有效前建立。为了保证数据可靠的写入，写数据必须在 $\overline{\text{CAS}}$ 有效前在数据总线上保持稳定。

> [!example]- DRAM 芯片的读写周期时序图
> ![[image/存储系统-6.png]]

## 只读存储器

> [!note] ROM 与 RAM 的区别
> ROM 和 RAM 都是支持随机访问的存储器，其中 SRAM 和 DRAM 均为易失性半导体存储器。而 ROM 中一旦有了信息，就不能轻易改变，即使掉电也不会丢失。ROM 具有两个显著的优点：
> 1. 结构简单，所以位密度比可读写存储器高。
> 2. 具有非易失性，所以可靠性高。

根据制造工艺的不同，ROM 可以分为掩模式只读存储器 (MROM)、一次可编程只读存储器 (PROM)、可擦除可编程只读存储器 (EPROM)、Flash 存储器和固态硬盘 (SSD)。
- **MROM**：掩模式只读存储器 (Mask ROM)。厂家按照客户要求，在芯片的生产过程中直接写入信息，之后任何人不可重写。
	- 优点：可靠性高，集成度高；
	- 缺点：灵活性差，生产周期长，只适合批量定制。
- **PROM**：可编程只读存储器。用户可用专门的 PROM 写入器写入信息。写一次后就不可以更改。
- **EPROM**：可擦除可编程的只读存储器。允许用户写入信息，之后用某种方式擦除数据，可以多次重写。但是它不能替代 RAM，因为 EPROM 的编程次数有限，且写入的时间较长。
	- UVEPROM：用紫外线照射，可以擦除所有的信息
	- EEPROM，可用电擦除的方式，擦除特定的字
- **Flash 存储器**：闪速存储器 (U 盘、SD 卡就是闪存)。在 EEPROM 基础上发展而来，断电后也可以保存信息，且可以进行多次快速擦除重写，兼具 ROM 和 RAM 的优点。
- **SSD**：固态硬盘。由控制单元 + 存储单元构成。SSD 速度快、功耗低、价格高。

> [!note] 计算机内的重要 ROM
> 断电后 RAM 内部数据全部丢失。所以引导开机的程序不能存储在 RAM 上。主板上的 BIOS 芯片存储的自具装入程序，负责引导操作系统 (开机)。

> [!tip]
> 我们常见的固态硬盘、SD 卡、U 盘等实际上就是 ROM，它们的读写速度不相同，一般读取速度要快于写入的速度。

## 双端口 RAM 和多模块存储器

DRAM 芯片的恢复时间比较长，可能是存取时间的几倍。为了提升主存的速度，提出了双口 RAM 和多模块存储器的概念。

> [!tip] 双端口 RAM 与多模块存储器是主存优化的方法

### *双端口 RAM*

双端口 RAM 可以优化多核 CPU 访问一根内存条的速度。该技术需要有两组完全独立的数据线、地址线、控制线。CPU、RAM 中也要有更加复杂的控制电路。

两个端口对同一主存操作一般有下面的 4 中情况，其中：
1. 两个端口同时对不同的地址单元存取数据。
2. 两个端口同时对同一地址单元读出数据。
3. 两个端口同时对同一地址单元写入数据。该操作会导致冲突，不应该被允许。
4. 两个端口同时对同一地址单元，一个写入数据、另一个读出数据。该操作也会导致错误，不应该被允许。

为了解决同时访问的问题，使用下面的方法：
- 置忙信号为 0，有判断逻辑决定暂时关闭一个端口 (即被延时)，未被关闭的端口正常访问，被关闭的端口延长一个很短的时间段后再访问。这实际上与操作系统中的 [[操作系统/进程管理#读者写者问题|读者写者问题]] 相同。

> [!tip] *~~408 大纲已删除~~*

### 多模块存储器

多模块存储器是一种空间并行技术，利用多个结构完全相同的存储模块的并行工作来提高存储器的吞吐率。常用的单体多字存储器和多体低位交叉存储器。

#### 单体多字存储器

在单体多字系统中，每个存储单元存储 $m$ 个字，总线宽度也为 $m$ 个字，一次并行读出 $m$ 个字。在一个存取周期内，从同一地址取出 $m$ 条指令，然后将指令逐条送至 CPU 执行，即每隔 $1/m$ 存储周期，CPU 向主存取一条指令。
- 优点：提高了单体存储器的工作速度。
- 缺点：只有指令和数据在主存中连续存放时，这种方法才能有效提升存取速度。一旦遇到转移指令，或者操作数不能连续存放时，这种方法的提升就不明显。

#### 多体并行存储器

多体并行存储器由多体模块组成，每个模块都有相同的容量和存取速度。各模块都有独立的读写控制电路、地址寄存器和数据寄存器。他们既能并行工作，又能交叉工作。

多体并行存储器有高位交叉编址和低位交叉编址两种方式。
- 高位交叉编址：将最高的几位作为所在存储器的编码，即高位地址表示模块号 (体号)，低位地址表示模块内地址 (体内地址)。*在这种方式下，访问连续的地址时，相当于访问同一个存储器，没有速度上的提升，仅相当于简单的扩容*。
- 低位交叉编址：将最低的几位作为所在存取器的编码，即低位地址表示模块号 (体号)，高位地址表示模块内地址 (体内地址)。*在这种方式下，连续访问地址时，会交替地访问每个存储器，相当于一种流水线的形式，每个访存周期中等待恢复的时间很短，甚至没有，可以极大地增加存储器的带宽*。使用低位交叉编址的多体存储器又称为**交叉存储器**。

> [!example]- 多体并行存储器的两种编址方式
> - 两种编址方式示意图：
> ![[image/存储系统-2.png#center|多体并行存储器的两种编址方式]]
> - 高位交叉编址时，访存甘特图
> ![[image/存储系统-3.png]]
> - 低位交叉编址时，访存甘特图
> ![[image/存储系统-4.png]]

交叉存储器可以采用轮流启动或者同时启动两种方式：
- 轮流启动：每个模块采用流水线的方式并行存取。存取周期为 T，存取时间为 r，为了使流水线不间断，应当保证模块数 $m\geqslant T/r$。
- 同时启动：若所有模块一次并行读写的总位数正好等于数据总线位数，则可以同时启动所有模块进行读写。设每个模块一次读写的位数为 16 位，模块数 $m=4$，数据总线位数为 64 位，4 个模块一共提供 64 位，正好构成一个存储字，因此可以同时启动 4 个模块进行并行读写。

> [!note] 交叉存储器中访存冲突的分析
> 在理想情况下，$m$ 体交叉存储器每隔 $1/m$ 存取周期可读写一个数据，若相邻的 $m$ 次访问的访存地址出现在同一个模块内，则会发生访存冲突，此时需要延迟发生冲突的访问请求。

## 主存储与 CPU 的连接

主存储器与 CPU 的连接原理如下：
1. 主存储器通过数据总线、地址总线和控制总线与 CPU 连接。
2. 数据总线的位数与工作频率的乘积正比于数据传输速率。
3. 地址总线的位数决定了可寻址的最大内存空间。
4. 控制总线 (读/写) 指出总线周期的类型和本次输入/输出操作完成的时刻。

> [!example]- 主存与 CPU 的连接
> ![[image/storge_5.png#center|主存与 CPU 的连接]]
为了便于描述，下面为存储器芯片的输入与输出进行命名：
> - 地址线：$A_0\cdots A_7$
> - 数据线：$D_0\cdots D_7$
> - 片选线：低电平有效 $\overline{CS}$ (Chip select) 或者 $\overline{CE}$，高电平有效 $CS$ 或者 $CE$
> - 读写控制线：低电平读，高电平写 $\overline{WE}$ 或者 $\overline{WE}$，也可以分开为 $\overline{WE}$ 与 $\overline{OE}$ 两根。

> [!note]
> 单个芯片的容量是有限的，因此通过存储器芯片拓展技术，将多个芯片集成在一个内存条上，然后由多个内存条及主板上的 ROM 芯片组成计算机所需的主存空间，再通过总线与 CPU 相连。

### 主存容量的扩展

对于一个 $n\times m$ 的存储芯片，它的容量和位数都输固定的，与实际的存取需求有些差距。对于地址总线和数据总线位数不同的 CPU，我们需要对存储芯片的字数与位数进行拓展，才能更好的匹配 CPU 的传输性能。

#### 位扩展法

位扩展是指对字长进行扩展 (增加存储字长)，当 CPU 的系统数据线数多余存储芯片的数据位数时，必须对存储芯片扩位，使其数据位数与 CPU 的数据线相等。

位扩展用于数据总线没有被用完的情况。将地址总线送入每个存储芯片，然后将每个信息的输入分别送到一个数据总线上，将数据总线占满。

> [!example]-
> 下面的例子中，数据总线的宽度为 8 位，但是存储芯片的字长为 1 位，为了更好的匹配 CPU，我们将其进行位扩展，即使用 8 个相同的存储芯片分别连接到不同的数据总线上。
> ![[image/stroge_6.png#center|位扩展|600]]

#### 字扩展

字扩展用于 CPU 地址总线没有用完的情况。基本思路为将地址总线输入到每个存储芯片中，然后使用剩余的 CPU 地址线来控制每个存储芯片的片选信号 (CS)。
- 线选法：每个片选信号直接由一个地址位控制。这样得到的地址不能有重复的 1 或者全部为 0，否则会导致数据总线冲突。线选法的缺点是利用率过低，且会发生冲突，得到的地址不是连续的。
- 译码器片选法：使用译码器来输出片选信号。$n$ 条线对应 $2^n$ 个选片信号。这样得到的地址是连续的。

> [!example]-
> 下面的例子中，我们 4 块存储芯片，通过译码器片选法，充分利用了 CPU 提供的寻址能力。
> ![[image/存储系统-5.png#center|字扩展|500]]

#### 字位同时扩展法

位扩展法更好的利用了 CPU 的数据总线传输能力，字扩展法更好的利用了 CPU 的寻址能力。这是两种不同方向上的扩展，我们可以同时使用它们。

> [!example]-
> ![[image/storge_7.png#center|字位同时扩展|600]]

## 外部存储器

计算机中的外存储器又称为辅助存储器。其主要特点包括：
- 优点：
	1. 存储容量大，位价格低。
	2. 记录介质可以重复使用。
	3. 记录信息可以长期保存不丢失，甚至可以脱机存档。
	4. 非破坏性读出，读出时不需要再生。
- 缺点：
	1. 存取速度慢。
	2. 机械结构复杂。
	3. 对工作环境要求较高。

> [!note]
> 磁表面存储器的输入与输出一次只能 1 bit 数据，且不能同时读写。因此需要一个电路将并行输入的数据转换为串行的数据。

### 磁盘存储器

#### 磁盘设备的组成

磁盘设备主要可以分为以下三个部分：
1. **硬盘存储器**：硬盘存储器由磁盘驱动器、磁盘控制器和盘片组成。
	- 磁盘驱动器：核心部件是磁头组件和盘片组件。
	- 磁盘控制器：是硬盘存储器和主键的接口，主流的标准有 IDE、SCSI、SATA 等。
2. **存储区域**：一个磁盘有若干个记录面，每个记录面划分为若干个磁道，而每个磁道又划分为若干个扇区。**扇区是磁盘读写的最小单位，也就是说磁盘按块存取**。
	- 磁头数：即记录面数，表示硬盘总共有多少个磁头，磁头用于读取、写入盘片上记录面的信息。一个记录面对应一个磁头。
	- 柱面数：表示硬盘每一个盘面上有多少条磁道。在一个盘组中，不同记录面的相同编号的诸磁道构成一个圆柱面。
	- 扇面区：表示每条磁道上有多少扇区
3. **磁盘高速缓存**：在内存中开辟一部分区域，用于缓冲将被送到磁盘上的数据。
	- 优点：写磁盘是按==簇==进行的，可以避免频繁地用小块数据写盘。有些中间结果数据在写回磁盘前可以被重复使用。

> [!note]
> 相邻磁道及相邻扇区间通过一定的间隔分隔开，以避免精度错误。由于扇区按固定圆心角度划分，因此位密度从最外道向里道增加，磁盘的存储能力受限于最内道的最大记录密度。

> [!note] 磁记录原理
> 磁头和磁性记录介质相对运动时，通过电磁转换完成读写操作。
>
> 编码方式：按某种方案，把一连串的二进制信息变成存储介质磁层中一个磁化翻转状态的序列，并使读写控制电路容易、可靠的实现转换。磁记录方式通常采用调频制 (FM) 和改进型调频制 (MFM) 的记录方式。

#### 磁盘的性能指标

1. 记录密度：记录密度是指盘片单位面积上记录的二进制信息量，通常以道密度、位密度和面密度表示。
	- 道密度：沿磁盘半径方向单位长度上的磁道数。
	- 位密度：磁道单位长度上能记录的二进制代码数。
	- 面密度：位密度和道密度的乘积。
2. 磁盘的容量：一个磁盘所能存储的字节总数称为磁盘容量。磁盘容量有非格式化容量和格式化容量之分。
	- 非格式化容量：磁记录表面可以利用的磁化单元总数，非格式化容量=记录面数×柱面数×每条磁道的磁化单元数。
	- 格式化容量：指按照某种特定的记录格式所能存储信息的总量。格式化容量=记录面数×柱面数×每道扇区数×扇区的容量。*格式化后的容量比非格式化容量要小*。
 3. 平均存取时间：平均存取时间=寻道时间^[磁头移动到目的磁道]+ 旋转延迟时间^[磁头定位到所在盘区]+ 传输时间^[传输数据所花费的时间]+ 磁盘控制器的延迟时间。由于寻道和找扇区的距离远近不一，因此寻道时间和旋转延迟时间通常取平均值 ^[平均寻道时间为从最外道移动到最内道时间的一半，平均旋转延迟取旋转半周的时间]
 5. 数据传输率：磁盘存储器在单位内向主机传送数据的字节数。假设磁盘转数为 $r$ 转每秒，每条磁道容量为 $N$ 字节，则数据传输速度为 $rN$。

> [!note] 磁盘的地址结构
> 主机向磁盘控制器发送寻址信息，磁盘的地址一般如图所示：
> $$
\begin{array}{|c|c|c|}
\hline
\small\text{柱面 (磁道) 号} & \small\text{盘面 (磁头) 号} & \small\text{扇区号} \\ \hline
\end{array}
> $$

> [!note] 磁盘的工作过程
> 磁盘的主要操作是寻址、读盘、写盘。每个操作都对应了一个控制字，磁盘工作时，第一步是取控制字，第二步是执行控制字。磁盘属于机械式部件，其读写是串行的，不可能在同一个时刻又读又写，也不可能在同一时刻读两组数据或者写两组数据。

### 磁盘阵列

RAID (Redundant Array of Inexpensive Disks) 廉价冗余磁盘阵列，是将多个独立的物理磁盘组成一个独立的逻辑盘，数据在多个物理盘上分割交叉存储、并行访问，具有更好的存储性能、可靠性、安全性。RAID 的分级如下，级别越高的分级越可靠：
- RAID 0：无冗余和无校验的磁盘阵列，没有容错能力。
- RAID 1：镜像磁盘阵列，由容错能力，但是两个磁盘当一个磁盘使用，容量减少一半。
- RAID 2：采用纠错的海明码的磁盘阵列。
- RAID 3：位交叉奇偶校验的磁盘阵列。
- RAID 4：块交叉奇偶校验的磁盘阵列。
- RAID 5：无独立校验的奇偶校验磁盘阵列。

> [!note] RAID 技术的特点
> - 通过同时使用多个磁盘，提高了传输率。
> - 通过在多个磁盘上并行存取来大幅提高存储系统的数据吞吐量。
> - 通过镜像的功能，可以提高安全可靠性。
> - 通过数据校验，可以提供容错能力。

### 固态硬盘

固态硬盘 SSD 是一种基于闪存技术的存储器。它与 U 盘并无本质差异，只是容量更大，存取性能更好。一个 SSD 由一个或者多个闪存芯片和闪存翻译层组成。
- 闪存芯片：一个或者多个闪存芯片替代传统旋转磁盘中的机械驱动器。
- 闪存翻译层：将来自 CPU 的逻辑块读写请求翻译成对底层物理设备的读写控制信号。闪存翻译层替代了磁盘控制器的角色。

> [!note] 闪存芯片
> 闪存芯片由多个块组成，每个块由多个页组成。通常，页的大小是 512B 到 4KB，每个块由 32 到 128 页组成，块的大小为 16KB 到 512KB。
> - 数据的读写是以页为单位的。
> - 只有在一页所属的块整个被擦除后，才能写这一页。
> - 若某个块进行了若干次重复写之后，就会损坏。
>
> 闪存芯片随机写的速度很慢，有两个原因：
> 1. 擦除块比较慢，通常比访问页高一个数量级。
> 2. 若写操作试图修改一个以及包含数据项的页，则这块中所有含有有用数据的页都必须复制到一个新块中 (已经被擦除的块)，才能对这个页进行操作。

> [!note] 固态硬盘和磁盘的对比
> 相较于传统磁盘，固态硬盘有很多的优点：
> 1. 固态硬盘由半导体存储器构成，没有移动的部件，随机访问的时间比机械硬盘快得多。
> 2. 没有任何机械噪声和震动，能耗更低，抗震性能更好，安全性更高。

> [!note] 固态硬盘的磨损均衡
> 闪存的擦写寿命是有限的，一般是几百次到几千次，若直接用普通闪存组装 SSD，则实际的寿命表现可能非常令人失望。即读写数据时会集中在 SSD 的一部分闪存，这部分闪存寿命会损耗的很快，一旦这部分的闪存损坏，整块 SSD 也就损坏了。为了弥补 SSD 的寿命缺陷，引入了磨损均衡。SSD 磨损均衡的技术大致分为两种：
> 1. 动态磨损均衡：写入数据时，自动选择较新的闪存块。
> 2. 静态磨损均衡：是一种更加先进的技术，就算没有数据写入，SSD 也会检测并自动进行数据分配，让老的闪存承担无须写数据的存储任务，同时让较新的闪存腾挪空间，平时的读写操作在较新的闪存块中进行。

## 高速缓冲存储器

高速存储缓冲器 (Cache) 用于缓冲内存与 CPU 间的速度差异。Cache 通常被集成在 CPU 内部，使用 SRAM 实现，速度快，成本高。

> [!note] 程序访问的局部性原理
> 程序访问的局部性原理包括**时间局部性**和**空间局部性**。
> - 时间局部性指最近未来要用到的信息，很可能是现在正在使用的信息，因为程序中存在循环和多次重复执行的子程序段，以及对数组的存储和访问操作。
> - 空间局部性指最近的未来要用到的信息，很可能与现在正在使用的信息在存储空间上是邻近的，因为指令通常是顺序存放，顺序执行的。数据一般也是以向量、数组等形式簇聚地存储的。
>
> 高速缓冲技术就是基于局部性原理，把 CPU 目前访问的地址周围的部分数据放到一个高速、容量较小的 Cache 中，使得 CPU 的访存操作大多数针对 Cache 进行，从而提高程序的执行速度。
^localityPrinciple

> [!warning]
> - 一般对于单个变量，我们不讨论空间局部性。在代码中，空间局部性体现在一个数组的访问顺序与其物理存储顺序是一致的。
> - 在代码中，时间局部性指一个数据在一段时间内被反复多次的访问，例如循环变量就具有很好的时间局部性。

> [!example]-
> 指令 Cache 一般比数据 Cache 具有更好的空间局部性。
> - 每次执行完成指令后都会使得 PC 自增，使其指向下一条指令。因此，在大部分情况下指令都是顺序执行的，具有较好的空间局部性。
> - 数据的访问在更多的情况下是随机存取的，因此空间局部性不如指令 Cache。

### Cache 的基本工作原理

为了便于 Cache 与主存交换信息，Cache 和主存都被划分为大小相等的块，Cache 块也称为 Cache 行，每块由若干字节组成，块的长度称为块长 (行长)。因为 Cache 的容量远小于主存的容量，因此 Cache 中的块数要远小于主存中的块数，Cache 中仅保存主存中最活跃的若干块的副本。通常按照某种策略预测 CPU 在未来一段时间内欲访存的数据，将其装入 Cache 中。

> [!note] Cache 命中对于 CPU 执行效率的影响
> - 当 CPU 发出读请求时：
> 	- 若访存地址在 Cache 中命中，则直接将此地址转换为 Cache 地址，直接对 Cache 进行读操作，与主存无关。
> 	- 若访存地址在 Cache 中未命中，则仍需要访问主存，并把此字所在的块一次性从主存调入 Cache。若此时 Cache 已满，则根据 [[#Cache 替换算法]] 替换原来的某个 Cache 块。**整个过程全部由硬件实现**。
> - 当 CPU 发出写请求时：
> 	- 若 Cache 命中，有可能遇到 Cache 与主存中内容不一致的问题。*例如，CPU 写 Cache，将 Cache 中的 X 修改为 Y，而主存对应的单元中的内容仍然是 X，没有改变*。因此，若 Cache 命中，需要按照 [[#Cache 写策略]] 处理。

> [!tip]
> 在现在的很多计算机中，采用同时访问 Cache 和主存的方式，由于 Cache 访问较快，如果 Cache 命中，则可以终止访存操作，否则 Cache 不影响访存操作。

我们常使用 Cache 的命中率和缺失率来计算 CPU 的性能。
- 命中率 $H$：CPU 欲访问的信息已经在 Cache 中的比率。设一个程序执行期间，Cache 的总命中次数为 $N_{c}$，访问主存的总次数为 $N_{m}$，则命中率 $H$ 为
$$
H=\dfrac{N_{c}}{N_{c}+N_{m}}
$$
- 缺失率 $M$：未命中的概率 $M=1-H$。

> [!note] 平均访问时间的计算
> 为了提供访问效率，命中率越接近 1 越好。设 $t_{c}$ 为命中时的 Cache 访问时间，$t_{m}$ 为未命中时的访问时间，1- $H$ 代表未命中率。
> - 若采用则同时访问 Cache 和主存的方式，Cache-主存系统的平均访问时间 $T_{a}$ 为：
> $$
T_a=Ht_{c}+(1-H)t_{m}
> $$
> - 若采用先访问 Cache，未命中再访问主存的方式，Cache-主存系统的平均访问时间 $T_{a}$ 为
> $$
T_{a}=Ht_{c}+(1-H)(t_{m}+t_{c})
> $$

> [!tip] 如何界定周围的数据
> 将主存的存储空间分块，主存与 Cache 之间以块为单位进行数据交换。这里的 Cache 块与页框不一定大小相同。

根据 Cache 的读、写流程，可知实现 Cache 时需要解决以下关键问题：
1. 数据查找。如何快速判断数据是够在 Cache 中。
2. 地址映射。主存块如何存放在 Cache 中，如何将主存地址转换为 Cache 地址。
3. 替换策略。Cache 满后，使用何种策略对 Cache 块进行替换或者淘汰。
4. 写入策略。如何既保证主存块和 Cache 块的数据一致性，又尽量提升效率。

### Cache 与主存的映射方式

由于 Cache 行数比主存块数少得多，因此主存中只有一部分块的信息可以放在 Cache 中，因此要在 Cache 中为每块添加一个标记位^[长度与主存块号长度和映射方式有关]，指明它是主存中哪一块的副本。标记内容相当于主存中块的编号。为了说明 Cache 行中的信息是否有效，每个 Cache 行需要一个有效位^[长度为 1 位]。

> [!note] 地址映射
> Cache 行中的信息是主存某个块的副本，地址映射是指把主存地址空间映射到 Cache 地址空间，即把存放在主存中的信息按照某种规则装入 Cache。
>
> 我们知道这样一个事实：在主存中，每个主存块的地址结构为
> $$
\begin{array}{|c|c|}
\hline
\small\text{主存块号} & \small\text{块内地址}\\ \hline
\end{array}
> $$
> 在引入了 Cache 后，我们将主存块号进一步划分，则主存地址在逻辑上转换为了
> $$
\begin{array}{|c|c|c|}
\hline
\small\text{tag 位} & \small\text{Cache 块号} & \small\text{块内地址} \\ \hline
\end{array}
> $$
> 这里的 tag 位与 Cache 块号就构成了原来的主存块号。而 tag 位则区别了 Cache 块号相同的主存块。根据这样的划分，我们可以得到 Cache 块在 Cache 中的地址格式为
> $$
\begin{array}{|c|c|c|}
\hline
\small\text{Cache 块号} & \small\text{块内地址} \\ \hline
\end{array}
> $$
> 在每个 Cache 行的开头，保存了地址映射关系，用于指向该 Cache 块对应的主存块，所有的地址映射关系构成了一个地址映射表。

> [!tip] Cache 块的结构
> 这里先给出完整的 Cache 块结构作为参考，每个标志位在后面将会被逐渐引入。
> $$
\begin{array}{|c|c|c|c|}
\hline
\small\text{有效位} & \small\text{脏位} & \small\text{替换控制位} & \small\text{tag 标记位} & \small\text{每行存储的数据} \\ \hline
\end{array}
> $$
> - 有效位：表明该行是否有效，0 表示该行还没有存储数据。
> - 脏位：用于写策略中的写回法，表明该 Cache 块是否被修改过。如果脏位为 1，则在换出 Cache 块时需要写回内存。
> - 替换控制位：保存有关替换算法的信息，主要是 LRU 算法中的计数。
> - 标记位：常称为 tag 位，标记 Cache 对应的主存块地址，一般根据主存大小与 Cache 大小的倍数进行计算，即 $\text{tag}=\log_{2}(\text{主存容量}/\text{Cache容量})$。我们在访问内存地址时，需要先根据地址中的 tag 位查找 Cache 块，如果命中，则直接从 Cache 块中读取。

> [!note] 比较器
> 在主存的映射中，通常是基于值的比较，即比较 tag 位是否与对应的 Cache 块中记录的 tag 相同。为了实现 Cache 中的快速并行比较，我们需要为每一个可能发生比较的 Cache 行都设置一个比较器。
> - 全相联映射：一个主存地址可能位于 Cache 中的任何位置，因此每个 Cache 行都需要设置一个比较器。
> - 直接映射：由于每个主存地址唯一对应了一个 Cache 地址，因此我们只需要一个比较器比较需要访问的主存地址对应的 Cache 地址即可。
> - 组相联映射：由于每个主存地址都唯一对应了一个 Cache 组，因此我们需要一个比较器比较 Cache 组中的每一个 Cache 行，因此对于 $n$ 路组相联映射，我们需要设置 $n$ 个比较器。
>
> **比较器的位数**：比较器用于比较 tag 位，因此位数与 tag 位相同。

#### 全相联映射 (随意放)

主存块可以放在 Cache 的任意位置。在这种方式中，每个 Cache 行中标记位需要记录完整的主存块号，且在访存时，需要一一对比主存块号，按值访问。在全相联映射中，主存地址被划分为
$$
\begin{array}{|c|c|c|}
\hline
\small\text{tag 位} & \small\text{块内地址} \\ \hline
\end{array}
$$
其中 Cache 地址就是块内地址。每个 Cache 行中需要保存较长的 tag 位。

> [!note] 全相联映射 CPU 访存过程
> 1. 将访存地址的主存块号与 Cache 中的所有块进行对比。
> 2. 若匹配且有效位为 1，则 Cache 命中，访问对应的块内地址。
> 3. 若未命中或有效位为 0，则正常访问主存。

> [!note] 全相联映射的特点
> - 优点：Cache 存储空间利用充分，命中率高。
> - 缺点：查找标记最慢，有可能需要对比所有的行的标记。不适用于大容量 Cache。

#### 直接映射

每个主存块只能放到一个特定的位置。**Cache 块号=主存块号\%Cache 总块数**。设 Cache 块数目为 $2^{n}$，则直接映射中主存地址被划分为了
$$
\begin{array}{|c|c|c|}
\hline
\small\text{tag 位} & \small\text{Cache 行号} & \small\text{块内地址} \\ \hline
\end{array}
$$
其中 Cache 行号与块内地址共同组成了 Cache 地址。在直接映射方法中，我们可以根据 Cache 地址计算出 Cache 行号，因此需要在 Cache 块中保存的 tag 位相较于全相联映射要少很多。

> [!note] CPU 访问主存地址的步骤
> 1. 根据主存块号的后 n 位确定 Cache 的行^[这是因为 Cache 块数一般为 $2^{n}$，在二进制中，对该数字取余相当于取最后的 $n$ 个二进制数]。
> 2. 若主存块号与 Cache 标记匹配且有效位为 1，则 Cache 命中。
> 3. 若未命中或有效位为 0，则正常访问主存。

> [!note] 直接映射的特点
> - 优点：计算简便。只需要对比一个标记，速度最快。
> - 缺点：每个块号只能使用对应的块，即使别的块有空闲，也不能使用。Cache 的存储空间利用不充分，命中率低。

> [!tip]
> 如果待装入 Cache 块中已有数据，则新数据会无条件替换原来的数据 (无需使用替换算法)。

#### 组相联映射

Cache 块分为若干大小相等的组。每个主存块可放到特定分组的任意一个位置。**组号=主存块号\% 分组数**。设 Cache 分为 $2^{n}$ 个组，则组相联映射的地址结构为
$$
\begin{array}{|c|c|}
\hline
\small\text{tag 位} & \small\text{Cache 组号} & \small\text{块内地址} \\ \hline
\end{array}
$$
其中 Cache 组号与块内地址共同组成 Cache 地址。在组相联映射中，我们可以根据 Cache 地址计算出 Cache 组号，由于是分组存放，因此 Cache 组号占用的信息比直接映射要少，因此 tag 位的长度介于全相联映射与直接映射之间。

> [!note] CPU 访问主存地址的步骤
> 1. 根据主存块号的后 n 位确定 Cache 的组
> 2. 对比主存块号与 Cache 的组内的所有标记，若有匹配且有效位为 1，则 Cache 命中。
> 3. 若未命中或有效位为 0，则正常访问主存。

> [!note] 组相联映射的特点
> 全相连映射与直接映射方式的折中，综合效果好。

> [!tip] n 路组相联映射
> 表示每 n 个 Cache 行分为一组。

### Cache 替换算法

由于每一次被访问的主存块都一定会被装入 Cache 中，因此 Cache 很容易被装满，需要找到一个方式在 Cache 已满的时候选择替换一块。
- 全相联映射：Cache 完全满了才替换需要再全局选择替换那一块。
- 直接映射：不需要选择替换哪一块，直接替换，因此不需要考虑替换算法。
- 组相联映射：分组内满了才需要替换。需要在分组内选择替换哪一块。

Cache 替换算法与 [[内存管理#页面置换算法]] 有异曲同工之处。

#### 随机算法 (RAND)

若 Cache 已满，则随机选择一块替换。

> [!note] 随机替换算法特点
> - 优点：实现简单。
> - 缺点：完全没考虑局部性原理，命中率低，实际效果不稳定。

#### 先进先出算法 (FIFO)

若 Cache 已满，则替换最先被调入 Cache 的块。该算法需要设置记录位来记录每个 Cache 块被调入的次序。

> [!note] 先进先出算法特点
> - 优点：实现简单。
> - 缺点：
> 	- FIFO 依然没有考虑局部性原理，最先被调入 Cache 的块也可能是被频繁访问的。
> 	- 存在抖动现象，即频繁的换入换出现象。

#### 近期最少使用算法 (LRU)

为每个 Cache 块设置一个计数器，用于记录每个 Cache 块已经有多久没有被访问。当 Cache 满了之后替换计数器最大的。
1. 命中时，所命中的计数器清零，比其值低的计数器^[这样可以保证计数器的大小关系反应了未被访问的时间顺序,这样的实现方式可以保证只需要对于大小为 $2^n$ 的 Cache 只需要 $n$ bit 的冗余信息就可以实现算法。] 加 1，其余不变。
2. 未命中且还有空闲行时，新装入的行的计数器置 0，其余空闲行全加 1。
3. 为命中且无空闲行时，计数值最大的行的 Cache 块被淘汰，新装入的块的计数器置 0，其余全加 1。

> [!note] 最近最少使用算法的特点
> - 优点：基于局部性原理，LRU 算法是合理的。LRU 算法的实际运行效果优秀，Cache 的命中率高。
> - 缺点：若被频繁访问的主存块数量大于 Cache 行的数量，则也有可能发生抖动现象。

#### 最不经常使用算法 (LFU)

为每个 Cache 块设置一个计数器，用于记录每个 Cache 块被访问的次数。当 Cache 满后替换计数器最小的。若有多个计数器最小的行，可以按照行号递增、或按照 FIFO 策略进行选择。

> [!note] 最不经常使用算法特点
> - 缺点：曾经经常访问的主存块在未来不一定会用到。因此 LFU 算法并没有很好的遵循局部性原理，因此实际运行效果不如 LRU。

### Cache 写策略

因为 Cache 中的内容是主存块副本，当对 Cache 中的内容进行更新时，就需要选用写操作策略使得 Cache 内容和主存内容保持一致。

当我们需要写内存，而需要写入的内存块在 Cache 中命中时，称为写命中。此时，我们有两种写策略：
- **写回法**：当 CPU 对 Cache 写命中时，只修改 Cache 的内容，而不立即写入主存，只有当此块被换出时才写回主存。
	- ==该策略需要添加**脏位**==，表示该 Cache 块是否被修改。只有当脏位置为 1 时，CPU 才在调出 Cache 块的同时将其写回内存中。
	- 这种方法存在主存和 Cache 数据不一致的隐患。
- **全写法** (写直通法)：当 CPU 对 Cache 写命中时，必须把数据同时写入 Cache 和主存，一般使用写缓冲。
	- 这种方式增加了访存次数，速度变慢，但是更能保证数据的一致性。
	- **写缓冲**：在 CPU 对 Cache 写命中时，先把数据写入 Cache 和写缓冲^[一般使用 SRAM 实现，CPU 写入的速度很快，但是容量有限。] 中。在 CPU 进行其他操作时，由硬件电路控制，自动将写缓冲中的数据写入主存。
		- 优点：CPU 写的速度很快，如果写操作不频繁，则效果很好。
		- 缺点：若写操作很频繁，可能会因为写缓冲饱和而发生阻塞。

> [!note] 写不命中时的策略
> - **写分配法**：当 CPU 与 Cache 写不命中时，把主存中的块调入 Cache 中，在 Cache 中修改。之后搭配写回法，在换出 Cache 时将数据写入主存。
> - **非写分配法**：当 CPU 对 Cache 写不命中时只写入主存，而不调入 Cache，一般搭配全写法使用。

#### 多级 Cache

现代计算机通常采用多级 Cache，不同级别的 Cache 的速度不同。当 CPU 需要访问主存时，可以同时访问多级 Cache。在多级 Cache 中：
- 离 CPU 越近的速度越快，容量越小，例如 2 级 Cache 中的 L1 Cache。
- 离 CPU 越远的速度越慢，容量越大，例如 2 级 Cache 中的 L2 Cache。

> [!note]
> - 不同级的 Cache 之间通常采用全写法和非写分配法。
> - Cache 与主存之间通常采用写回法和写分配法。
>
> 这样一来，由于 L2 Cache 的存在，避免了因为频繁写时造成的写缓冲饱和溢出。

> [!note] 分离指令 Cache 和数据 Cache
> 随着指令流水线技术的发展，需要将指令 Cache 和数据 Cache 分开设计，这就有了分离的 Cache 结构。
> - 统一 Cache 的优点是设计和实现相对简单，但是由于执行部件存取数据时，指令预取部件要从同一 Cache 读指令，因此会发生冲突。
> - 采用分离的 Cache 结构可以解决这个问题，并且分离的指令和数据 Cache 还可以充分利用指令和数据的不同局部性来优化性能。

## 虚拟存储系统

> [!tip]
> 更多有关本章内容见 [[内存管理#虚拟内存]]。

主存和辅存共同构成了虚拟存储器，二者在硬件和系统软件的共同管理下工作。对于应用程序员而言，虚拟存储器是透明的。**虚拟存储器具有主存的速度和辅存的容量**。

虚拟存储器将主存与辅存的地址空间统一编址，形成一个庞大的地址空间。在这个空间内，用户可以自由编程，而不必在乎实际的主存容量和程序在主存中实际的存放位置。
- 用户编程允许涉及的地址称为虚地址或逻辑地址，虚地址对应的存储空间称为虚拟空间或程序空间。
- 实际的主存单元地址称为实地址或物理地址，实地址对应的是主存地址空间，也称实地址空间。**虚地址比实地址要大得多**。

> [!note] 虚地址的作用
> CPU 使用虚地址时，先判断这个虚地址对应的内容是否已经转入主存。
> - 若已在主存中，则通过地址变换，CPU 可以直接访问主存指示的实际单元。
> - 若不在主存中，则把包含这个字的一页或一段调入主存后，再由 CPU 访问。若主存已满，则采用 [[操作系统/内存管理#页面置换算法|页面置换算法]] 置换主存中的页面 (段)。

> [!warning]
> 虚拟存储器也采用和 Cache 类似的技术，将辅存中经常访问的数据副本存放到主存中。但是缺页 (段) 而访问辅存的代价很大，提高命中率是关键。
> - 因此虚拟存储机制采用命中率最高的全相联映射，每个虚页面可以存放到对应主存区域的任何一个空闲页位置。
> - 同时，当进行写操作时，不能每次写操作都同时写回磁盘，因此处理一致性问题时，只能使用写回法。

### 页式虚拟存储器

页式虚拟存储器以页为基本单位。主存空间和虚拟地址空间都被划分为了大小相同的页。
- 主存空间中的页称为物理页 (实页、页框)。
- 虚拟地址空间中的页称为虚拟页 (虚页)。

#### 页表

页表记录了程序的虚页调入主存时安排在主存中的位置。一个页表项如下所示
$$
\begin{array}{|c|c|c|c|}
\hline
\small\text{有效位} & \small\text{脏位} & \small\text{引用位} & \small\text{物理页地址/磁盘地址} \\ \hline
\end{array}
$$
- 有效位：也称装入位，用来表示对应页面是否在主存中。
	- 若为 1，表示该虚拟页已经从外存调入主存，此时页表项存放该页的**物理页号**；
	- 若为 0，表示没有调入主存，此时页表项存放该页的**磁盘地址**；
- 脏位：也称修改位，用来表示页面是否被修改过。虚拟机制采用 [[#Cache 写策略|写回策略]] ，利用脏位来判断是否需要写回磁盘。
- 引用位：也称使用位，用来配合替换策略进行设置，例如 LRU 中的计数、FIFO 中的调入顺序等。

> [!note] 页表的运作过程
> CPU 欲访问一个页中的数据时，检查页表：
> - 若页表的有效位为 1，表示该页已经放入主存中。通过地址转换部件将虚拟地址转换为物理地址，然后在相应的主存实页中存储数据。
> - 若页表的有效位为 0，表示该页还没有放入主存中，发生**缺页异常**，需要调用操作系统的缺页异常处理程序。缺页异常处理程序的工作过程为：
> 	- 根据对应表项中存放位置字段，将所缺页面从磁盘中调入到一个空闲的物理页框。若主存中没有空闲的物理页框，则选择一个页框替换。
> 	- 如果被替换的页框的脏位为 1，则将其写回磁盘。

> [!note] 页式虚拟存储器的特点
> - 优点：页面长度固定，页表简单，调入方便。
> - 缺点：
> 	- 因为程序不一定是页面的整数倍，最后一页的零头将无法利用而造成浪费。
> 	- 页不是逻辑上的实体，所以处理、保护和共享都不如段式虚拟存储器方便。

> [!tip]
> 在页式虚拟存储设备中，每个进程都对应了一张页表，**页表常驻内存**。每个进程都有一个**页表基址寄存器**，存放该进程的页表首地址。

#### 地址转换

在虚拟存储系统中，指令给出的地址是虚拟地址，因此当 CPU 执行指令时，需要先将虚拟地址转化为主存物理地址，才能到主存中存取指令和数据。
- 虚拟地址分为两个字段，高位的虚页号，低位的页内偏移地址。
- 物理地址分为两个字段，高位的物理页号，低位的页内偏移地址。

> [!note]
> 物理页和虚拟页的大小是相同的，页表实际上就是一个存放在主存中的虚页号和实页号的对照表。

> [!note] 地址转换的过程
> 1. 根据页表基址寄存器，找到对应页表的首地址。
> 2. 根据虚拟地址高位的虚拟页号找到对应的页表项。
> 	- 若页表项中装入位为 1，则取出物理页号，和虚拟地址低位的页内地址拼接，形成实际的物理地址。
> 	- 若装入位为 0，出发缺页异常，由操作系统进行缺页中断处理。

#### 快表 TLB

根据地址转换的过程，访存时先访问一次主存去查页表，在访问主存取得数据。若缺页，则还要进行页面替换、页面修改等，因此采用虚拟存储机制后，访问主存的次数更多了。

从 Cache 的实现中，我们可以根据局部性原理，保存一些近期可能被经常访问的数据在更加快速的存储器中。在虚拟存储中，我们也可以使用同样的策略，使用高速缓冲器存放页表中的一部分。我们将这里的高速缓冲器称为**快表** (TLB)。相应的，在主存中的页表成为**慢表**。
- 在进行地址转换时，首先查找快表，若命中，则无须访问主存中的页表。

> [!note] 快表的实现方式
> 快表类似于 Cache，使用 SRAM 实现，通常采用全相联映射或者组相联映射。TLB 表项由页表表项内容和 TLB 标记组成。
> - 在全相联映射下，TLB 标记就是对应表项的虚拟页号。
> - 组相联映射下，TLB 标记就是对应虚拟页号的高位部分，虚拟页号的低位部分作为 TLB 的组号。

> [!example]- TLB 和 Cache 的多级存储系统
> 虚拟存储系统和 Cache 系统是两个独立的结构，可以一起工作。下面是一个具有 TLB 和 Cache 的多级存储系统，其中 Cache 采用二路组相联方式，TLB 采用全相联方式。
> ![[image/存储系统-7.png#center|TLB 和 Cache的多级存储系统]]
> 其访问过程为：
> 1. 将虚拟地址转换为物理地址：CPU 给出一个 32 位的虚拟地址，TLB 查找时将虚页号和每个 TLB 标记字段同时进行比较。
> 	- 若有某一项相等且对应有效位为 1，则 TLB 命中，此时可以直接通过 TLB 进行地址转换。
> 	- 若未命中，则 TLB 缺失，需要访问主存去查页表，并将页表项调入 TLB 中。若 TLB 已满，还须采用替换策略。
> 2. CPU 根据物理地址访问数据：Cache 机构根据映射方式将物理地址划分为多个字段，然后根据映射规则找到对应的 Cache 行，将对应的 Cache 行中的标记与物理地址中的高位部分进行比较：
> 	- 若相等且有效位为 1，则 Cache 命中，此时根据块内地址取出对应的字送给 CPU。
> 	- 若 Cache 未命中，则访问内存地址，并写入 Cache。

> [!example] TLB、Cache 和 Page 缺失组合分析
> 在一个具有 TLB 和 Cache 的多级存储系统中，CPU 一次访存操作可能同时涉及 TLB、页表、Cache、主存和磁盘的访问。CPU 访存过程中存在三种缺失情况：
> 1. TLB 缺失：要访问的页表项不在 TLB 中，则要访问主存中的慢表，并调入 TLB 中。
> 2. Cache 缺失：要访问的主存块不在 Cache 中，则要直接访问主存，并调入 Cache 中。
> 3. 缺页：要访问的页面不在主存中，即页表项中的有效位为 0，此时需要出发缺页异常。
>
> 由于 TLB 是根据局部性原理保存的一些页表项，因此发生缺页时，TLB 中一定没有该页的页表项，即**缺页时 TLB 必然缺失**。同理，缺页时，Cache 中必然没有该内存块内容，即**缺页时 Cache 必然缺失**。

### 段式虚拟存储器

段式虚拟存储器中的段是按程序的逻辑结构划分的，各个段的长度因程序而异。把虚拟地址分为两部分：段号和段地址。虚拟地址到实地址的变换是由段表实现的。段表是程序的逻辑段和主存中存放位置的对照表。段表的每行记录与某个段的段号、装入位、段起始和段长等信息。因为段的长度可变，因此段表中给出处各段的起始地址与长度。一个段表项如下所示：
$$
\small\text{段号}\quad
\begin{array}{|c|c|c|}
\hline
\small\text{段首址} & \small\text{装入位} & \small\text{段长} \\ \hline
\end{array}
$$

> [!note]
> - 由于段本身是程序的逻辑结构所决定的一些独立部分，因而分段对程序员来说是不透明的。
> - 而分页对于程序员来说是透明的，程序员编写程序时不需要知道程序将如何分页。

> [!note] 段式虚拟存储特点
> - 优点：段的分界与程序的自然分界相对应，因而具有逻辑独立性，使得它容易编译、管理、修改和保护，也便于多道程序的共享。
> - 缺点：由于段长度可变，分配空间不便，容易在段间留下碎片，不好利用，造成浪费。

> [!note] 段页式虚拟存储器
> 在段页式虚拟存储器中，把程序按逻辑结构分段，每段再划分为固定大小的页，主存空间也划分为大小相等的页。
> - 程序对主存的调入、调出仍然以页为基本交换单位。
> - 每个程序对应一个段表，每段对应一个页表，段的长度为页的整数倍，段的起点是某一页的起点。
> - 虚地址分为段号、段内页号、页内地址三部分。
> 	- CPU 根据虚地址访存时，首先根据段号得到段表地址。
> 	- 然后从段表中取出该段的页表起始地址，与虚地址段内页号合成，得到页表地址。
> 	- 最后从页表中取出实页号，与页内地址拼接形成主存地址。
>
> 段页式虚拟存储器的优点是兼具页式和段式虚拟存储器的优点，可以按段实现共享和保护。缺点是在地址变换过程中需要两次查表，系统开销较大。

### 虚拟存储器和 Cache 的比较

相同之处：
1. 最终目标都是为了提供系统性能，两者都有容量、速度、价格的梯度。
2. 都把数据分为小信息块，作为基本的交换单位。虚拟存储系统的信息块更大。
3. 都有地址映射、替换算法、更新策略等问题。
4. 都依赖于局部性原理的**快速缓存**的思想，将活跃的数据放在相对高速的部件中。

不同之处：
1. Cache 主要解决系统速度，而虚拟存储器主要解决主存容量问题。
2. Cache 全部由硬件实现，是硬件存储器，对所有程序员是透明的；虚拟存储器由 OS 和硬件共同实现，是逻辑上的存储器，对系统程序员不透明，但是对应用程序员透明。
3. 虚拟存储系统不命中时，需要访问外存，此时对系统的性能影响比 Cache 不命中大。
4. CPU 与 Cache 和主存都建立了直接访问的通路，而辅存于 CPU 没有直接通路。也就是说，在 Cache 不命中时，主存能够和 CPU 直接通信，同时将数据调入 Cache。而虚拟存储器系统不命中时，只能先由硬盘调入主存，而不能直接和 CPU 通信。

< [[计算机组成原理/数据的表示和运算|数据的表示和运算]] | [[计算机组成原理/指令系统|指令系统]] >
