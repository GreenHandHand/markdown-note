---
aliases:
  - process
  - 进程
  - 线程
tags:
  - 操作系统
---

# 进程管理

现代操作系统的一个重要特性是程序的并发性与资源的共享性，为了满足多用户并发计算的要求，现代操作系统围绕进程这个概念进行设计和构造。

## 进程的定义

> [!tip] 进程这个概念是为了描述系统中的并发活动而引入的。
> **进程** (process)，又叫做任务 (task)，是操作系统中最基本、最重要的概念之一，它对于操作系统的理解、描述与设计都具有非常重要的意义。

从不同的角度，进程可以有不同的定义，下面是几种比较典型的定义：
1. 进程是程序的一次执行过程，*是一个正在执行程序的实例*。
2. 进程是一个程序及其数据从磁盘加载到内存后，在 CPU 上执行的过程。
3. 进程是程序在一个数据集合上顺序执行时发生的活动。它是系统进行资源分配和调度的一个独立单位。

> [!note] PCB 描述块
> 为了使得并发执行的每个程序 (包括数据) 都可以独立的运行，必须为之配备一个专门的数据结构，称为**[[#进程控制块]]** (Process Control Block, PCB)。系统通过 PCB 来描述进程的基本情况和运行状态，进而管理进程。
> - 程序段、相关数据段和 PCB 三个部分构成了**进程实体**([[操作系统/内存管理#进程的内存映像|进程映像]])。
> - 所谓的创建进程，就是创建进程的 PCB；撤销进程，就是撤销进程的 PCB。

> [!note] 进程实体的组成 ([[操作系统/内存管理#进程的内存映像|进程的内存映像]])
> 对于一个进程实体，一般包含了 PCB、共享正文段、数据堆段和数据栈段。其中
> - PCB 保存了进程的描述性内容，例如进程的 PID、处理机信息等；
> - 共享正文段保存了代码和数据赋值内容，即二进制代码和常量均保存在共享正文段；
> - 数据堆段：全局变量、静态变量、用户分配内存
> - [[计算机组成原理/指令系统#栈帧的概念|数据栈段]]：局部变量、函数参数等

> [!definition|Definition] 进程
> 进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。

> [!note] 进程的特点
> 1. 进程是程序的一次执行过程，具有**动态性**；*程序是完成某个特定功能的指令的有序序列，是一个静态的概念。进程是程序的一次执行过程，是临时的，有生命周期的；而程序可以作为一种长期储存的资源。* **动态性是进程最基本的特征**。
> 2. 进程是系统进行资源分配和调度的一个独立单位，具有**独立性**。*而同一个程序可以在同一时间被多个用户使用。资源分配时以进程为单位的，而不是以程序为单位的。*
> 3. 一个进程可以与其他进程并发执行，具有**并发性**。
> 4. 进程具有**结构性**。*为了描述进程，系统为每个进程创建了一个进程描述块。从结构上来看，一个进程包含了程序、数据和进程控制块。*
> 5. 进程具有**异步性**。*各进程按各自独立的、不可预知的速度向前推进，操作系统要提供进程同步机制来解决异步问题。*

> [!note] 进程与程序的区别
> 简单来说，程序是静态的，是个存放在磁盘里的可执行文件，是一系列的指令集合。进程是动态的，是程序的一次执行过程。

## 进程的描述

进程是一个独立的运行单位，也是操作系统进行资源分配和调度的基本单位。它由进程控制块、程序段和数据段组成。

### 进程控制块

进程控制块 (process control block) 是进程存在的唯一标识，通常包含了：
1. **进程描述信息**：进程标识符，标识各个进程。如进程 ID (PID, process ID)，进程所属用户 ID (UID)；
2. **进程控制和管理信息**：进程当前状态，描述进程的状态信息。如进程的 CPU 使用时间、磁盘使用时间、网络流量使用情况等，此外还包含了进程当前的状态：就绪态/阻塞态/运行态等；
3. **资源分配清单**：如分配了多少内存、正在使用哪些 IO 设备，正在使用哪些文件。
4. **处理机相关信息**：也称 CPU 上下文，主要指 CPU 各寄存器中的值，如 PSW、PC 等各种寄存器的值，当进程被切换时，CPU 状态信息应该被保存在 PCB 中，以便该进程重新执行时，能够从断点继续执行。

> [!note]
> 进程创建时，操作系统为它新建立一个 PCB，该结构之后常驻内促，任意时刻都可以进行存取，并随进程删除一起删除。**PCB 是进程存在的唯一标志**。

> [!note] PCB 的组织方式
> 为了方便进程的管理和调度，需要将各个进程的 PCB 用适当的方式组织起来。目前，常用的组织方式有链接方式和索引方式两种。(详细见 [[#进程的组织]])
> - 链接方式：将同一个状态的 PCB 链接成一个队列，不同状态对应不同的队列。
> - 索引方式：将同一个状态的进程组织来一个索引表中，索引表的表项指向相应的 PCB。

> [!note] 程序段和数据段
> - 程序段：能够被进程调度程序调度到 CPU 中执行的程序段代码。*一个程序可以被多个进程共享，即多个进程可以运行同一个程序*；
> - 数据段：可以是进程对应的程序加工处理的原始数据，也可以是程序执行时产生的中间结果；

### 进程的状态

进程在生命周期内一直处于一个状态不断变化的过程中。为了刻画这种变化过程，操作系统将进程分为了若干状态，使用状态机来表述。这些状态信息记录在进程的 PCB 结构中。

一个进程的状态有以下几种：
1. **创建态**：进程正在被创建时，它的状态是创建态，在这个阶段操作系统会为进程分配资源，初始化 PCB。
2. **就绪态**：进程创建完毕后，便进入了就绪态，处于就绪态的进程已经具备了运行条件，但是由于没有空闲的 CPU，暂时不能运行。*系统中的就绪进程可能有多个，通常将他们排成就绪队列。*
3. **运行态**：当 CPU 空闲时，操作系统就会选择一个就绪进程，让它上处理机运行。
4. **阻塞态**：在进程运行的过程中，可能会请求等待某个事件的发生 (如等待某种系统资源的分配，或者等待其他进程的响应)。在这个事件发生之前，进程无法向下执行，这时操作系统会让这个进程下 CPU，让其进入阻塞态，然后选择另一个就绪态的进程上 CPU 运行。*系统通常将处于阻塞状态的进程也排成一个队列，甚至会根据阻塞的原因不同，设置多个阻塞队列*。
5. **终止态**：一个进程可以请求 `exit` 的系统调用，请求操作系统终止该进程。此时一个进程进入终止态，操作系统会让该进程下 CPU，并回收内存空间等资源，最后还要回收该进程的 PCB。当终止进程的工作完成后，该进程就彻底消失了。

> [!example]- 五种进程状态的转换
> ![[image/进程管理-1.png#center|五种进程状态的转换]]

> [!note] [[#进程的创建 (创建原语)]]
> 1. 首先，申请一个空白 PCB，并向 PCB 中填写用于控制和管理进程的信息；
> 2. 然后，为该进程分配运行时所必须的资源；
> 3. 最后，将该进程转入就绪态，加入就绪队列；
>
> 进程在所需的资源尚不能满足的情况下，会留在创建态，等待资源分配。*例如，无法分配足够的内存，则创建工作未完成*。

> [!note] 引起进程状态转换的事件
> - 就绪态 -> 运行态：处于就绪态的进程被调度后，获得了 CPU 资源 (分配 CPU 时间片)，于是进程进入运行态。
> - 运行态 -> 就绪态：
> 	- 处于运行态的进程在时间片用完后，让出 CPU，转换为就绪态。
> 	- 在可剥夺的操作系统中，有更高优先级的进程就绪时，调度程序将正在执行的进程转换为就绪态，让更高优先级的进程执行。
> - 运行态 -> 阻塞态：进程以系统调用的方式请求操作系统提供服务，例如请求某一资源的分配和使用、等待某一事件的发生 (如 IO 操作的完成) 时，它将从运行态转换为阻塞态。
> - 阻塞态 -> 就绪态：进程等待的事件到来时，中断处理程序将相应的进程状态转换为就绪态。

> [!warning]
> **不能直接从阻塞态直接转换为运行态，也不能直接从就绪态转为阻塞态**。
> 在进程的整个生命周期中，大部分时间都是处于就绪态、运行态、阻塞态三种状态。在单核 CPU 下，同一时刻只会有一个进程处于运行态，多核 CPU 情况下，可能有多个进程处于运行态。
> - 进程从运行态变为阻塞态是主动的行为。
> - 进程从阻塞态并为就绪态是被动的行为。

> [!tip]
> 在 PCB 中，会有一个变量 state 来表示进程的当前状态。为了便于管理，操作系统会将处于同一状态的进程组织起来。

### 进程的组织

为了便于进程的管理，通常对系统中的进程采用两种组织方式。
- **线性表组织方式**：把所有进程的 PCB 存放在一个数组中，系统通过数组下标访问每一个 PCB。系统根据进程的状态，建立了多张索引表，并把索引表的内存首地址记录在内存中的一些专用单元中以完成索引。
- **链表组织方式**：把具有相同状态的 PCB 组织成一个队列。
	- 处理就绪态的进程可按照某种策略排成多个就绪队列。
	- 处于阻塞态的进程又可以根据阻塞的原因组织成多个阻塞队列。

> [!tip]
> 在单 CPU 系统中，任何时间都只有一个进程处于运行状态，因此系统专门设定了一个指针指向当前运行进程的 PCB。

## 进程控制

进程控制的主要功能是对系统中所有的进程实施有效的管理，它具有创建进程、撤销已有进程、实现进程状态转换等功能。简单说，进程控制是：
- 系统使用一些具有特定功能的程序段来创建、撤销进程，以及完成进程各状态之间的转换。进程控制是由操作系统内核实现的，属于原语一级操作，不能被中断。

> [!definition|Definition] 原语
> 原语是一种特殊的程序，它的执行具有原子性。也就是说，这段程序运行必须一气呵成，不能中断。

> [!tip] 进程控制需要使用原语的原因
> 如果进程控制不能一气呵成的执行，可能导致操作系统中的某些关键数据结构不统一的情况，如 PCB 中的进程状态与进程所处的队列不一致，这会影响操作系统进行别的管理工作，可能导致操作系统出错。

> [!note] 原语的实现方式
> 在计算机中，CPU 每执行完一条指令后，会例行检查是否有中断信号。在进行原语之前，CPU 先执行**关中断**指令，此时不再例行检查中断信号，在原语执行完毕后，再执行**开中断**指令。关中断与开中断指令为特权指令，只能由内核使用，而不能由用户使用。

### 进程的创建 (创建原语)

系统一般通过下面的步骤创建进程，创建原语使一个进程由创建态进入就绪态。
1. 扫描进程表，找到一个空闲的 PCB。*为进程分配一个唯一的进程标识符，并申请一个空白 PCB (PCB 是有限的)，若 PCB 申请失败，则创建失败*；
2. 为进程分配其运行所需的资源。*例如内存、文件、IO 设备和 CPU 时间等，这些资源从操作系统或者父进程中获得。如果资源不足，则停留在创建态，等待内存资源*；
3. 初始化 PCB。*把调用者提供的参数（进程名、进程优先级、实体所在主存的起始地址、所需的资源清单、记账信息及进程家族关系等）填入 PCB 中*；
4. 将新的进程插入就绪队列，等待被调度。

> [!note]
> 下面是常见的引起创建原语的事件：
> 1. **用户登录**：在分时系统中，用户登录成功，系统为其创建一个新进程
> 2. **作业调度**：多道批处理系统中，有新的作业放入内存时，会为其创建一个新的进程
> 3. **提供服务**：用户向操作系统提出某些请求时，会新建一个进程处理该请求
> 4. **应用请求**：由用户进程主动请求创建一个子进程

> [!tip] 分配设备不会创建新的进程

> [!tip]
> 允许一个进程创建另一个进程，此时创建者称为父进程，被创建的进程称为子进程。
> - 子进程可以继承父进程所拥有的资源，当子进程被撤销时，应将其从父进程那里获得的资源还给父进程。
> - 当父进程被撤销时，通常也会撤销所有其所有子进程。

### 进程的终止 (撤销原语、终止原语)

如果一个进程已经完成任务或者由于故障不能继续运行时，应当被撤离系统而消亡。撤销原语的功能是在 PCB 集合中寻找要撤销的进程，若有子孙进程，也需要终止，以防称为不可控的；将其全部资源或者归还其父进程或者归还系统。撤销其 PCB。

撤销原语使一个进程由其他状态进入终止态，其过程为：
1. 从 PCB 集合中找到终止进程的 PCB，从中读取出进程的状态；
2. 若进程处于运行态，立即剥夺 CPU，将 CPU 分配给其他进程；
3. 若进程还有子孙进程，终止所有子孙进程^[不是所有操作系统都这样规定]；
4. 将该进程拥有的所有资源归还给父进程或者操作系统；
5. 删除 PCB。

> [!note] 引起进程终止的事件
> 1. 进程正常结束：*表示进程的任务已经完成，并且准备退出运行*；
> 2. 异常结束：发生了某种异常事件，使程序无法继续运行，例如数组越界、保护错、非法指令、特权指令错、运行超时、算术运算错、IO 故障等；
> 3. 外界干预：指进程应外界的请求而终止运行。*例如操作员或者操作系统干预、父进程请求、父进程终止等*。

### 进程的阻塞和唤醒 (阻塞原语、唤醒原语)

处于运行状态的进程，在其运行过程中期待某一事件^[如等待键盘输入、等待磁盘数据传输完成] 发生，将会自己执行**阻塞原语** (Block)，由运行态变为阻塞态。

阻塞原语的功能是中断 CPU，将其运行现场保存在其 PCB 中，置状态为阻塞态，插入相应事件的阻塞队列中。之后，由处理机调度，重选一个进程投入运行。其过程为：
1. 根据 PID 找到要阻塞的进程对应的 PCB；
2. 保护进程的运行现场，将 PCB 状态信息设置为阻塞态，暂时停止进程进行；
3. 将 PCB 插入相应事件的等待队列，将 CPU 资源调度给其他就绪进程。

当某进程等待的事件^[例如它所期待的 IO 操作完成、期待的数据到达等] 出现时，由有关进程^[例如，释放该 IO 设备的进程，或提供等待的数据的进程] 调用唤醒原语 (Wakeup) 将等待该事件的进程唤醒。唤醒原语的执行过程如下：
1. 在该事件等待队列中找到相应进程的 PCB；
2. 将 PCB 从等待队列移出，设置进程为就绪态；
3. 将 PCB 插入就绪队列，等待被调度。

> [!note]- 挂起原语\*
> - 在实时系统中，根据实时现场的需要，会将正在执行或者没有执行的进程挂起一段时间。被挂起的进程由活动状态转换为静止状态。
> - 在分时系统中，将进程从内存换到外存中，进程就处于了进制状态，不被调度。

> [!note]- 解挂原语\*
> 当挂起进程的原因被解除时，系统调用解挂原语将指定的进程解挂，使其由静止态变为活动态。当被解挂的进程变为活动就绪时，通常立即转进程调度。

## 进程通信

进程间通信 (Inter-Process Communication, IPC) 指两个进程之间产生数据交互。进程之间的通信必须有操作系统的支持。

> [!note] 进程通信的必要性
进程是分配系统资源的单位，包括内存地址空间，因此各进程拥有的内存地址空间相互独立。为了保证安全，一个进程不能直接访问另一个进程的地址空间。因此需要操作系统的支持才能完成。

> [!tip]
> PV 操作是低级的通信方式，高级通信方式是指以较高的效率传输大量数据的通信方式。高级的通信方式主要包括共享存储、消息传递和管道通信。

### 共享存储

共享存储方式通过系统调用申请了一片共享内存区，使得通信的进程都可以访问共性存储区从而实现进程通信。进程间如果通过共享存储的方式进行通信，那么进程间对于共享空间的访问是互斥的，需要使用同步互斥工具 (例如 PV 操作) 对共享空间的读写进行控制。一个进程访问共享空间时，其他进程不能访问。

共享存储有两种形式：
- **基于存储区的共享**：操作系统在内存中划出一块共享存储区，数据的形式、存放位置都由通信进程控制，而不是操作系统。这种共享方式传输数据的速度非常快，是一种高级的方式。
- **基于数据结构的共享**：例如共享空间中只能放一个长度为 10 的数组，这种共享方式速度慢，限制多，是一种低级的方式。

> [!tip]
> 操作系统只负责为通信进程提供可共享使用的存储空间和同步互斥工具，而数据的交换则由用户自己安排读写指令完成。

### 消息传递

进程间的数据交换以**格式化的消息**（Message）为单位，进程通过操作系统提供的发送消息/接受消息两个原语进行数据交换。进程通过操作系统提供的发送消息和接受消息两个原语进行数据交换。

消息传递分为两种方式：
- 直接通信方式：消息进程指明接受进程的 ID。在每个进程的 PCB 中包含了每个进程的消息队列，其中保存了其他进程发送给该进程的消息。
	- 需要发送消息的进程通过发送原语发送消息，操作系统内核将消息放入接收进程的消息缓冲队列；
	- 接受进程通过接收原语从消息缓冲队列中取得消息。
- 间接通信方式：通过“信箱”间接地通信，因此又称为信箱通信方式。发送进程通过发送原语将消息发送到指定的信箱，接受进程通过接收原语从指定的信箱接受消息。*该通信方式广泛的应用于计算机网络中*。

> [!tip]
> 若通信的进程之间不存在可以直接访问的共享空间，则必须利用操作系统提供的消息传递方式实现进程通信。这种方式隐藏了通信实现细节，使得通信过程对用户透明，简化了通信程序的设计，是当前应用最广泛的进程通信机制。在微内核操作系统中，微内核和服务器之间就采用了消息传递机制。
>
> 此外，由于该机制能很好的支持多 CPU 系统、分布式系统和计算机网络，因此也成为了这些领域的主要通信工具。

### 管道通信

**管道**是一种特殊的共享文件，也被称为 pipe 文件。管道本质上是在内存中创建了一个固定大小的缓冲区，数据在其中以先进先出的方式流动。管道通信允许两个进程以生产者-消费者的模式进行通信：
- 当管道未满时，写进程可以向管道的一端写入数据；
- 当管道非空时，读进程可以从管道的另一端读取数据。

> [!note] 管道通信的特点
> 为了保证通信的顺利进行，管道机制必须具备以下三方面的协调能力：
> - **互斥**：当一个进程对管道进行读写操作时，其他进程必须等待 (通过读写锁实现)；
> - **同步**：
>   - 写进程写入数据后，如果管道已满或需要等待读进程消费数据，写进程将被阻塞，直到读进程读取数据后唤醒它；
>   - 读进程读取完管道中的数据后，如果管道为空，读进程将被阻塞，直到写进程写入新数据后唤醒它；
> - **双方存在**：通信过程中，必须确保至少一个读进程和一个写进程同时存在。

> [!tip] 管道通信与共享内存的对比
> 与共享内存不同，管道通信中只有一方可以写入数据，另一方读取数据。此外，管道通信遵循先进先出的原则，数据的读取顺序与写入顺序一致。管道可以视为一个 [[数据结构/栈、队列和数组#循环队列|循环队列]]。

> [!note]
> 在 Linux 系统中，管道是一种非常常用的进程间通信机制。管道与普通文件不同，它克服了使用文件通信时的两个主要问题：
> 1. **大小限制**：管道文件是一个固定大小的缓冲区，在 Linux 中通常为 4KB。这一限制防止了管道文件像普通文件那样无限制增长。
> 2. **同步问题**：使用普通文件进行通信时，可能出现读进程比写进程读取得更快的情况。此时，管道通信通过阻塞 `read` 操作来等待数据写入，从而确保同步。

> [!note] 管道的访问权限
> 管道通信只能在创建它的进程及其子进程之间进行。当父进程创建一个管道时，子进程会继承父进程的管道文件描述符，因此子进程可以通过该管道与父进程进行通信。
>
> 需要注意的是，从管道中读取数据是一次性的，数据一旦被读取，对应的缓冲区空间就会释放，以便写入更多的数据。**普通管道只能用于单向通信，如果需要双向通信，则必须使用两个管道**。

## 线程

> [!note] 进程与线程的引入
> - 引入进程的目的是更好的使多道程序并发执行，提供资源利用率和操作系统吞吐量；
> - 引入线程的目的是减小程序在并发执行时所付出的时空开销，提供操作系统的并发性能。

线程最直观的理解就是轻量级进程，它是一个基本的 CPU 执行单元，也是程序执行流的最小单元，由线程 ID、程序计数器 PC、寄存器集合和堆栈组成。线程是进程中的一个实体，是被系统独立调度和分派的基本单位。

引入线程机制后，为操作系统带来了如下的变化：
1. **资源分配、调度**：传统进程机制中，进程是资源分配、调度的基本单位，但是在引入线程后，进程是资源分配的基本单位，线程是调度的基本单位。
2. **并发性**：传统进程机制中，只能进程间并发。在引入线程后，各个线程间也能并发，提升了并发度。
3. **系统开销**：传统进程间并发，需要切换进程的运行环境，系统开销很大。引入线程后，线程间的并发，如果是同一进程内的线程切换，则不需要切换进程环境，系统开销小，并发所带来的系统开销减小。

> [!note] 线程的属性
> 多线程操作系统中的进程已经不再是一个基本的执行实体，但是它任何具有与执行相关的状态。因此，进程处于执行状态，实际上是该进程中的线程正在执行。线程的主要属性如下：
> 1. 每个线程都有唯一的标识符和一个线程控制块 (TCB)，线程控制块记录线程执行的寄存器和栈等现场状态。
> 2. 不同的线程可以执行相同的程序，*即同一个服务程序被不同用户调用时，操作系统将它们创建为不同的线程。*
> 3. 同一进程中的各个线程共享该进程所拥有的资源。
> 4. 线程是 CPU 的独立调度单位，多个线程是可以并发执行的。
> 	- 在单 CPU 的计算机系统中，各线程可以交替地占用 CPU；
> 	- 在多 CPU 的计算机系统中，各线程可以同时占用不同的 CPU。
> 5. 一个线程被创建后，便开始了它的生命周期，直到终止。线程在生命周期内也会经历阻塞态、就绪态和运行态等各种状态变化。

> [!note] 线程的状态与转换
> 与进程一样，各个线程之间也存在共享资源和互相制约关系，致使线程在运行时也具有间断性。相应地，线程在运行时也具有下面三种基本状态：
> - 执行态：线程已获得 CPU 而正在执行；
> - 就绪态：线程已具备各种执行条件，只需要获得 CPU 便可立即执行；
> - 阻塞态：线程在执行中因为某事件受阻而处于暂停状态；
>
> 线程的状态与转换与 [[#进程的状态]] 是一致的。

> [!warning]
> 在引入线程后，进程的内涵发生了改变，进程只作为除了 CPU 外的系统资源的分配单位，而线程则作为 CPU 的分配单元。一个进程内部有多个线程，若线程的切换发生在同一个进程内部，则只需要很少的时空开销。

> [!note] 进程和线程的对比
> 1. **调度**：
> 	- 在传统操作系统中，用于资源和独立调度的基本单位都是进程，每次调度都要进行上下文切换，开销较大。
> 	- 在引入线程的操作系统中，线程是独立调度的基本单位，在同一个进程中，线程的切换不会引起进程的切换。
> 2. **并发性**：在引入线程的操作系统中，不仅进程之间可以并发执行，而且一个进程中的多个线程之间也可以并发执行，不同进程之间的线程也可以并发执行，使得操作系统具有更好的并发性，提高了系统资源的利用率和系统的吞吐量。
> 3. **拥有资源**：进程是系统中拥有资源的基本单位，而线程不拥有系统资源，*仅有一点必不可少、能保证独立运行的资源*。但是线程可以访问其隶属的进程的系统资源。
> 4. **独立性**：
> 	- 每个进程都拥有独立的地址空间和资源，处理共享全局变量，不允许其他进程访问。
> 	- 同一进程的不同线程是为了提供并发性以及进行相互之间的合作而创建的，它们共享进程的地址空间和资源。
> 5. **支持多处理器系统**：
> 	- 对于传统单线程进程，不管有多少个 CPU，进程只能运行在一个 CPU 上。
> 	- 对于多线程进程，可将进程中的多个线程分配到多个 CPU 上。

### 线程的实现方式

#### 用户级线程 (User-Level Thread, ULT)

早期的操作系统只支持进程，不支持线程。此时的线程是由线程库实现的。很多的编程语言提供了强大的线程库，可以实现线程的创建、调度、销毁的功能。用户级线程由以下特点：
- 用户级线程通过调用线程库实现，所有的线程管理工作都应由应用程序负责（包括线程切换）。
- 用户级线程中，线程切换可以在用户态下完成，无需操作系统干涉。
- 在用户看来，程序是由多个线程的。但是操作系统内核看来，还是使用一个进程。

> [!note] 用户级线程的优缺点：
> - 优点：
> 	- 用户级线程的切换在用户空间中即可完成，不需要切换到核心态，线程管理的系统开销小，效率高。
> 	- 调度算法可以是进程专用的，不同进程可以根据自身需要，对自己的线程选择不同的调度算法。
> 	- 用户级线程的实现与操作系统平台无关，对线程管理的代码是属于用户程序的一部分。
> - 缺点：
> 	- 在用户级线程中，如果一个线程被阻塞，那么其他线程也将被阻塞，并发度不高，多个线程不可在多核处理机上并行运行。
> 	- 不能发挥多 CPU 的优势，内核每次分配给一个进程的仅有一个 CPU，因此进程中仅有一个线程能够执行。

> [!tip] 在用户级线程中，进程仍然时调度的基本单位，线程间不能并行的进行。

#### 内核级线程 (Kernel-Level Thread, KLT)

大多数的现代操作系统都实现了内核级线程。内核级线程由以下特点：
1. 内核级线程的管理工作由操作系统内核完成。
2. 线程调度、切换等操作都由内核负责，因此内核级线程的切换必然在核心态才能完成。
3. 操作系统会为每个内核级线程建立相应的 TCB (Thread Control Block)，通过 TCB 对线程进行管理。

> [!note] 内核级线程的优缺点：
> - 优点：
> 	- 当一个线程被阻塞后，别的线程还可以继续执行，并发能力强。
> 	- 能够利用多 CPU 的优势，多线程可以在多核处理机上并发执行。
> 	- 内核支持线程具有很小的数据结构和堆栈，线程切换比较快，开销小。
> 	- 内核本身也可以采用多线程技术，可以提高系统的执行速度和效率。
> - 缺点：一个用户进程会占用多个内核级线程，线程的切换由操作系统内核完成，需要切换到核心态，因此线程管理的成本较高，开销大。

#### 组合方式

有些系统使用组合方式的多线程实现。在组合实现方式中，内核支持多个内核级线程的建立、调度和管理，同时允许用户程序建立、调度和管理用户级线程。一些内核级线程对应多个用户级线程，这是用户级线程通过时分多路复用内核级线程实现的。用一进程中的多个线程可以同时在多 CPU 上并行执行，且在阻塞一个线程时不需要将整个进程阻塞，所以组合方式结合 KLT 和 ULT 的优点，并且克服了各自的不足。

> [!note] 线程库
> 线程库 (Thread Library) 是为程序员提供创建和管理线程的 API，实现线程库的主要方法有如下两种：
> 1. 在用户空间中提供一个没有内核支持的库。这种库的所有代码和数据结构都位于用于空间中，这意味着，调用库内的一个函数只导致用户空间中的一个本地函数的调用。
> 2. 实现由操作系统直接支持的内核级的一个库。对于这种情况，库内的代码和数据接口位于内核空间。调用库中的一个 API 函数通常会导致对内核的系统调用。

### 线程的组织与控制

线程的组织方式与进程相似。系统会为每个线程建立一个线程控制块 (TCB)，用于记录控制和管理线程的信息。每个线程控制块通常包含：
1. 线程标识符 TID：与 PID 类似，标识线程；
2. 程序计数器 PC：线程目前执行到哪里；
3. 其他寄存器：线程运行的中间结果，包含状态寄存器、通用寄存器；
4. 堆栈指针：堆栈保存函数调用信息，局部变量等，用于过程调用时保存局部变量及返回地址；
5. 线程运行状态：运行/就绪/阻塞；
6. 优先级：线程调度、资源分配的参考；

> [!tip]
> 同一进程的所有线程都完全共享进程的地址空间和全局变量，各个线程都可以访问进程地址空间中的每个单元，所以一个线程可以读、写、甚至清除另一个线程的堆栈。

> [!note] 线程的创建和终止
> 在操作系统中，有用于创建线程和终止线程的系统调用。
> - 用户程序启动时，通常仅有一个称为初始化线程的线程正在执行，其主要功能是创建新线程；
> - 在创建新线程时，需要利用一个线程创建函数，并提供相应的参数。
> - 线程创建函数执行完后，将返回一个线程标识符。
>
> 当一个线程完成自己的任务后，或者线程在执行中出现异常而要被强制终止时，由终止线程调用相应的函数执行终止操作。通常，线程被终止后，并不立即释放它所占用的资源，只有当进程中的其他线程执行了分离函数后，被终止线程才与资源分离，此时资源才能被其他线程利用。*被终止但尚未释放资源的线程仍可被其他线程调用，以使被终止线程重新恢复运行*。

### 多线程模型

在同时支持内核级线程和用户级线程的系统中，根据用户级线程和内核级线程的映射关系，可以划分为几种多线程模型。
- **一对一模型**：一个用户级线程映射到一个内核级线程，每个用户进程有与用户级线程同数量的内核级线程。
	- 优点：当一个线程被阻塞后，别的线程还可以继续执行，并发能力强。多线程可以在多核处理机上并行执行。
	- 缺点：一个用户进程会占用多个内核级线程，线程的切换由操作系统内核完成，需要切换到核心态，因此线程的管理成本高，开销大。
 - **多对一模型**：多个用户线程映射到一个内核级线程，且一个进程只被分配一个内核级线程。这种方式相当于退化到了普通的用户级线程。
 - **多对多模型**：n 个用户级线程映射到 m 个内核级线程 (n $\geqslant$ m)，每个用户进程对应 m 个内核级线程。
	 - 克服了多对一模型并发度不高的缺点 (一个阻塞全部阻塞)，又克服了一对一模型中一个用户进程占用太多内核级线程，开销太大的缺点。

> [!note]
> - 一对一模型：并发性能好，但是线程管理成本大
> - 多对一模型：并发性能差，相当于多进程
> - 多对多：并发性能好，且线程管理成本不高

> [!warning]
> 内核级线程才是处理机分配的单位。内核级线程中可以运行任意一个由映射关系的用户级线程代码，只有两个内核级线程中正在运行的代码都阻塞时，整个进程才阻塞。

## CPU 调度

系统中的用户进程数远远超过处理机数，这么多的进程竞争处理机，就需要操作系统采用一些策略，将处理机动态的分配给系统中的各个就绪进程。分配资源的过程就是调度，即 CPU 需要从就绪队列中按照一定的算法 (公平、高效原则) 选择一个进程，并将 CPU 分配给它运行，以实现进程并发的进行。

### 调度的三个层次

一个作业从提交开始直到完成，往往要经历三级调度：
- **高级调度** (作业调度)：按照某种规则从外存处于后备队列的作业中挑选一个 (或多个) 存入内存，分配相应的资源并创建进程，使得它们获得竞争 CPU 的权利。
	- 每个作业只调入一次，调出一次。
	- 作业调入时建立 PCB，调出时撤销 PCB。
	- 高级调度中进程的状态转换：*无->创建态->就绪态*。
- **中级调度** (内存调度)：按照某种策略决定将哪个处于挂起状态的进程重新调入内存中。
	- 内存不够时，可将某些进程的数据调出外存，等内存空闲或者进程需要运行时再重新调入内存。
	- 暂时调到外存等待的进程称为挂起状态，被挂起的进程 PCB 会被组织成挂起队列。
	- 中级调度发生的频率要高于高级调度。
	- 中级调度中进程的状态转换：*挂起态->就绪态*或者从*阻塞挂起->阻塞态*。
- **低级调度** (进程调度/处理机调度)：按照某种策略从就绪队列中选取一个进程，将处理机分配给它。
	- 进程调度时操作系统中最基本的一种调度.
	- 进程调度的频率很高，一般几十毫秒一次。
	- 低级调度中进程的状态转换：*就绪态->运行态*。

> [!note]
> 1. 多道批处理系统中大多配有作业调度，而其他系统中通常不需要配置作业调度。
> 2. 进程调度是一种最基本的调度，在各种操作系统中都必须配备这种调度。

> [!note] 三级调度的关系
> 1. 作业调度是为进程活动做准备，进程调度使得进程正常活动起来。
> 2. 中级调度将暂时不能运行的进程挂起，中级调度处于作业调度和进程调度之间。
> 3. 作业调度的次数最少，中级调度次数略多，进程调度频率最高。
> 4. 进程调度是最基本的，不可或缺。

> [!tip] 挂起状态
>  暂时调到外存等待的进程状态为挂起状态，挂起态又可以进一步分为就绪挂起、阻塞挂起两种状态。将挂起态加入进行的状态转换图中，就可以得到
 > ```mermaid
graph LR
Cr(创建态)-->A(就绪态)-->B(运行态)-->终止态
B-->A
B-->C(阻塞态)-->A
E(阻塞挂起)
Cr-->D(就绪挂起)-->|激活|A
A-->|挂起|D
B-->D
C-->|挂起|E-->|激活|C
E-->|事件出现|D
> ```

### 进程调度

进程调度 (低级调度) 是按照某种算法从就绪队列中选择一个进程为其分配处理机。一般而言，在下面的情况会发生进程调度：
- 当前运行进程**主动放弃**处理机
	- 进程正常终止；
	- 运行过程中发生异常终止；
	- 进程主动请求阻塞；
- 当前运行进程**被动放弃**处理机
	- 分给进程的时间片用完；
	- 有更加紧急的事需要处理；
	- 有更高优先级的进程进入就绪队列；

> [!note] 进程调度的时机
> 下面几种情况下不能进行进程调度与切换：
> 1. 在处理中断中。中断处理过程复杂，与硬件密切相关，很难做到在中断处理过程中进行进程切换。
> 2. 进程在操作系统内核程序临界区中。
> 3. 在原子操作过程中 (原语)。原子操作不可中断。

> [!note]
> - 临界资源：一个时间段内只允许一个进程使用的资源，各进程需要互斥地访问临界资源。
> - 临界区：访问临界资源的那段代码。
> - 内核程序临界区：一般是用来访问某种内核数据结构的，比如进程的就绪队列。内核程序临界区访问的临界资源如果不尽快释放的话，极有可能影响到操作系统内核的其他管理工作。
> 	- 在访问普通临界资源时，可以发生进程调度；
> 	- 在访问内核程序临界区时，不能发生进程调度；

进程调度方式分为非剥夺调度方式与剥夺调度方式。
- **非剥夺调度方式**，又称为**非抢占式调度方式**，只允许进程主动放弃处理机。在运行过程中即便有更加紧迫的任务到达，当前进程依然会继续使用处理机，直到该进程终止或者主动要求进入阻塞态。
	- 实现简单，系统开销资源小但是无法及时处理紧急任务，适合于早期的批处理系统。
- **剥夺调度方式**，又称为**抢占方式**。当一个进程正在处理机上执行时，如果有一个更重要或者更紧迫的进程需要使用处理机，则立即暂停正在执行的进程，将处理机分配给更重要更紧迫的那个进程。
	- 可以优先处理更紧急的进程，也可以实现让各进程按时间片轮流执行的功能。适合于分式操作系统，实时操作系统。

> [!note] 进程调度和切换的方式
> 广义的进程调度包含了选择一个进程和进程切换两个步骤，其中：
> - **狭义的进程调度**：指从就绪队列中选中一个要运行的进程。
> - **进程切换**：指一个进程让出处理机，由另一个进程占用处理机的过程。进程切换主要完成了：
> 	1. 对原来运行进程的各种数据的保存：将运行进程信息保存到 PCB 中
> 	2. 对新的进程各种数据的恢复：从 PCB 中读取运行进程的信息，恢复到寄存器中。
>
> 进程的切换是有代价的，因此如果过于频繁的进行进程调度、切换，必然会使整个系统的效率降低，使系统的大部分时间都花在进程切换上，而真正用于执行进程的时间减少。

#### 调度程序 (scheduler)

用于调度和分派 CPU 的组件称为调度程序，调用调度程序意味着进行一次调度。进程的调度时机实际上就是调度程序工作的时机。通常，在创建新进程、进程退出、运行进程阻塞、IO 中断等情况会触发调度程序。

在不支持内核级线程的操作系统中，调度程序的处理对象是进程。在支持内核级线程的操作系统中，调度程序的处理对象是线程。

> [!tip]
> 只要就绪队列发生改变，调度程序就会检查是否需要进行调度。

> [!note]
> - 非抢占式调度策略，只有运行进程阻塞或者退出时才出发调度程序工作。
> - 抢占式调度策略，每个时钟中断或 k 个时钟中断会出发调度程序工作。

> [!note] 闲逛进程
> 调度程序在没有其他就绪进程时，将会运行闲逛进程 (idle)，闲逛进程的特点是
> - 优先级最低
> - 可以是 0 地址指令，占一个完整的指令周期
> - 能耗低

#### 进程切换

进程的切换由系统调用在内核的支持下实现。在进行进程调度时，主要进行的操作是进行**上下文切换**，即切换 CPU 到另一个进程时，需要保存当前进程状态并恢复另一个进程的状态。==进程上下文主要保存在进程的 PCB 中，包括 CPU 寄存器的值、进程状态和内存管理信息等==。上下文切换的过程如下：
1. 挂起一个进程，将 CPU 上下文保存到 PCB 中，包括程序计数器 PC 和其他寄存器；
2. 将进程的 PCB 移入相应的队列，如就绪、阻塞队列；
3. 选择另一个进程执行，并更新其 PCB；
4. 恢复新进程的 CPU 上下文；
5. 跳转到新进程 PCB 中的程序计数器所指向的位置执行；

> [!note] 上下文切换的消耗
> 上下文切换通常是计算密集型的，需要相当可观的 CPU 时间，每次切换都需要纳秒量级，每秒都需要进行几十上百次的切换。

> [!note] 模式切换
> 用户态和内核态之间的切换称为模式切换。模式切换与上下文切换是不同的，模式切换时，CPU 逻辑上可能还在执行同一个进程。上下文切换只能发生在内核态，它是多任务操作系统的一个必需的特性。

### 调度算法的评价指标

#### CPU 利用率

由于早期的 CPU 造价昂贵，因此人们希望 CPU 尽量多的工作。CPU 利用率表示 CPU 忙碌的时间占总的时间的比例。
$$
\tiny 利用率=\frac{忙碌的时间}{总时间}
$$

> [!tip]
> 上式不仅可以算 CPU 的利用率，也可以计算其他设备的利用率。对于多道程序并行计算时，需要主要 CPU 与设备、设备与设备之间是可以并行的。

#### 系统吞吐量

对于计算机来说，希望能用尽可能少的时间处理完尽可能多的作业。系统吞吐量表示单位时间内完成作业的数量。
$$
\tiny 系统吞吐量=\frac{总共完成了多少道作业}{总共花了多少时间}
$$

#### 周转时间

对于计算机的用户来说，一般很关心自己的作业从提交到完成总共花了多少时间。周转时间指作业被提交给系统来时，到作业完成为止的这段时间间隔。
$$
\tiny 周转时间=作业完成时间-作业提交时间
$$
此外，我们更加关心系统的整体表现，因此常用平均周转时间
$$
\tiny 平均周转时间=\frac{各作业周转时间之和}{作业数}
$$
上面的指标没有考虑作业的实际运行时间，因此提出了带权周转时间
$$
\tiny 带权周转时间=\frac{作业周转时间}{作业时间运行时间}=\frac{作业完成时间-作业提交时间}{作业实际运行时间}
$$
相应的，系统整体的指标使用
$$
\tiny 平均带权周转时间=\frac{各作业带权周转时间之和}{作业数}
$$

#### 等待时间

计算机的用户希望自己的作业尽可能少的等待处理机。等待时间指作业处于等待处理机状态时间之和。相应的，使用平均等待时间作为系统的整体指标。

> [!note]
> - 对于进程来说，等待之间指进程建立后等待被服务的时间之和，在等待 IO 设备的时间不计入等待时间。
> - 对于作业的等待时间，还需要加上作业在外存后备队列中等待的时间。
> - 不同的调度算法实际上只影响作业的等待时间。

#### 响应时间

响应时间指从用户提交到首次产生响应所用的时间。

### 调度算法

#### 先来先服务 (FCFS)

先来先服务调度算法 (First Come First Serve)，按照到达的先后顺序调度，事实上就是等待的时间的越久的越优先得到服务。

先来先服务算法为非抢占式算法，由于作业调度时，考虑的是哪个作业先到达后备队列，用于进程调度时，考虑的是哪个进程先到达就绪队列。

> [!note] FCFS 调度算法特点
> - 优点：公平，算法实现简单，不会导致饥饿。
> - 缺点：排在长作业 (进程) 后面的短作业需要等待很长的时间，带权周转时间很大。FCFS 算法对长作业有利，对短作业不利。

> [!tip] FCFS 也可以成为 FIFO，是一种常见的算法思想。

#### 短作业优先 (SJF)

短作业优先 (SJF, Shortest Job First) 追求最少的平均等待时间，最少的平均周转时间，最少的平均带权周转时间。
- 非抢占式短作业优先算法，每次调度时选择当前已到达且运行时间最短的作业/进程。
- 抢占式短作业优先算法，又称为**最短剩余时间优先算法** (SRTN)，每当有进程加入就绪队列需要进行调度，如果新到达的进程剩余时间比当前运行的进程剩余时间更短，则由新进程抢占处理机，当前运行进程重新回到就绪队列。此外，在一个进程完成时也需要进程调度。

> [!tip]
> 一般而言，书上提到的短作业/进程优先算法默认是非抢占式的。
>
> 严格来说，抢占式短作业优先算法的平均等待时间、平均周转时间最少。

> [!note] SJF 调度算法的特点
> - 优点：最短的平均等待时间、平均周转时间
> - 缺点：
> 	- 不公平，对短作业有利，对长作业不利。可能会产生饥饿现象。
> 	- 该算法完全没有考虑作业的紧迫程度，不能保证紧迫性作业会被及时处理。
> 	- 由于作业/进程的运行时间由用户提供，不一定真实，不一定可以做到真正的短作业优先。

#### 高响应比优先 (HRRN)

高响应比优先算法综合考虑作业的等待时间和要求服务的时间。是对 FCFS 调度算法和 SJF 调度算法的一种综合平衡。定义进程的响应比为：
$$
\tiny 响应比R_{p}=\frac{等待时间+要求服务时间}{要求服务时间}
$$
高响应比优先算法为非抢占式算法，只有当前运行的进程主动放弃 CPU 时，才需要进程调度。在每次调度时先计算各个作业的响应比，选择响应比最高的作业为其提供服务。

> [!note] NRRN 调度算法特点
> - 优点：综合考虑了等待时间和运行时间，等待时间相同时，要求服务时间短的优先，要求服务时间相同时，等待时间长的优先。
> - 不会导致饥饿。
> - 高响应比优先算法结合了 FCFS 算法与 SJF 算法的优点，是一种折中的算法。

> [!note]
> FCFS 算法、SJF 算法与 HRRN 算法只关心系统整体的性能指标，但不关心响应时间，也不区分任务的紧急程度，因此对于用户来说，交互性很糟糕。因此这三种算法一般适用于早期批处理系统。

#### 时间片轮转调度算法 (RR)

时间片轮转算法 (Round-Robin) 公平地、轮流的为各个进程服务，让每个进程在一定时间间隔内都可以得到响应。

时间片轮转调度算法是==抢占式算法==，只能用于进程调度。按照各个进程到达就绪对列的顺序，轮流让各个进程执行一个时间片，若进程未在一个时间片内执行完，则剥夺处理机，将进程重新放入就绪队列队尾排队。
- 若一个时间片尚未用完而当期进程完成，则调度程序被立即激活。
- 若一个时间片已用完，则产生一个是时钟中断，有时钟中断处理程序来激活调度程序。
- 在进行时间片轮转调度时，始终维护一个进程队列，每次选择一个排在就绪队列队头的进程。

> [!note]
> - 如果时间片太大，使得每个进程都可以在一个时间片内完成，则时间片轮转调度算法退化为了先来先服务算法，并且会增大进程的响应时间。
> - 如果时间片太小，进程切换过于频繁，系统会花大量时间来处理进程切换，从而导致实际用于进程执行的时间比例减少。

> [!note] RR 调度算法的特点
> - 优点：公平，响应快，适用于分式操作系统。不会导致饥饿。
> - 缺点：由于高频率的进程切换，因此有一定的开销。不区分任务的紧急程度。

#### 优先级调度算法

随着计算机发展，特别是实时操作系统的出现，越来越多的应用场景需要根据任务的紧急程度来决定处理顺序。

优先级调度算法在每次调度时选择优先级最高的进程。
- 非抢占式优先级调度：在进程主动放弃处理器后，检查就绪队列，查找优先级最高的进程。
- 抢占式优先级调度：在就绪队列变化时检查就绪队列，如果有优先级更高的进程，则抢占 CPU。

在优先级调度算法中，就绪队列未必只有一个，可以按照不同优先级来组织。另外，也可以把优先级高的进程排在更加靠近队头的位置，使用优先队列实现。根据优先级是否可以动态改变，可以将优先级分为：
1. 静态优先级：创建进程时确定，之后一直不变。
2. 动态优先级：创建进程时有一个初始值，之后会根据情况动态地调整优先级。例如，提高等待时间长的进程的优先级，降低占用处理器很长时间的进程的优先级。

> [!note] 优先级的设置
> 一般来说，进程优先级的设置可以参考以下原则：
> 1. 系统进程 > 用户进程。系统进程作为系统的管理者，理应拥有更高的优先级。
> 2. 交互型进程 > 非交互型进程。
> 3. IO 型进程 > 计算型进程。

> [!note] 优先级调度算法的特点
> - 优点：用优先级区分紧急程度、重要程度，适用于实时操作系统，可以灵活地调整对各种作业/进程的偏好程度
> - 缺点：若源源不断地有高优先级的进程到来，可能会导致饥饿

#### 多级反馈队列调度算法

多级反馈队列是对其他调度算法的这种权衡，是抢占式的算法。多级反馈队列调度算法通过动态调整进程优先级和时间片大小，可以兼顾多方面的系统目标。

多级反馈队列调度的算法步骤为：
- 多级反馈队列调度算法设置了多级就绪队列，各级队列优先级从高到低，时间片从小到大。
- 新进程到达时，先进入第 1 级队列，按照 FCFS 原则排队等待被分配时间片。若用完时间片，进程还未结束，则进程进入下一级队列队尾。如果此时已经在最下级的队列，则重新放回最下级队列队尾。
- 只有第 k 级队列为空时，才会为 k+1 级队头的进程分配时间片。
- 在 k 级队列的进程正在运行过程中，若上级的队列中进入了一个新进程，由于新进程处于优先级更高的队列中，因此新进程会抢占处理机。原来的进程放回 k 级队列队尾。

> [!note] 多级反馈队列调度算法的特点：
> - 优点：
> 	- 对各类型进程相对公平 (FCFS)
> 	- 每个新到达的进程都可以很快得到响应 (RR)
> 	- 短进程只用较少时间就可完成 (SPF)
> 	- 不必实现估计进程的运行时间 (避免用户作假)
> 	- 可以灵活的调整对各类进程的偏好程度
>  - 缺点：会导致饥饿。(一直有新的进程到来)

> [!tip]
> 时间片轮转调度、优先级调度、多级反馈队列调度算法适用于交互式系统，它们更加注重系统的响应时间、公平性、平衡性等指标。

#### 多级队列调度算法

前述的各种算法，由于系统中仅设置一个进程的就绪队列，且调度算法是固定且单一的，无法满足系统中不同用于对于进程调度策略的不同要求。在多 CPU 系统中，这种单一调度策略实现机制的缺点更为突出，多级队列调度算法可以在一定程度上弥补这一缺点。

多级对立调度算法中，系统按进程类型设置多个就绪队列，进程创建成功后插入某个队列。队列之间的调度可以采取固定优先级，或时间片划分
- 固定优先级：高优先级队列为空时低优先级队列的进程才能被调度；
- 时间片划分：为不同的队列中的进程分配不同的时间片；

各个队列还可以使用不同的调度策略，一般来说
- 系统进程队列采用优先级调度；
- 交互式进程采用 RR；
- 批处理队列采用 FCFS；

## 进程同步与互斥

在多道程序环境下，进程是并发执行的，不同进程之间存在着不同的制约关系。为了协调进程之间的相互制约关系，引入了进程同步和互斥的概念。

> [!definition|Definition] 同步
> 同步也称为直接制约关系，它指为了完成某种任务而建立的两个或者多个进程，这些进程因为需要再某些位置上协调它们的工作次序而产生的制约关系。进程间的直接制约关系就是源于它们之间的互相合作。

> [!definition|Definition] 互斥
> 互斥也称为间接制约关系。当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一个进程才允许区访问该临界资源。

为了实现对临界资源的互斥访问，同时保证系统整体性能，需要遵循以下原则：
1. **空闲让进**：临界区空闲时，可以运行一个请求进入临界区的进程立即进入临界区；
2. **忙则等待**：当已有进程进入临界区时，其他试图进入临界区的进程必须等待；
3. **有限等待**：对请求访问的进程，应保证能在有限时间内进入临界区；
4. **让权等待**：当进程不能进入临界区时，应立即释放处理机，防止进程忙等待；

> [!note] 临界资源
> 虽然多个进程可以共享系统中的各种资源，但其中许多资源一次只能为一个进程所用，我们将一次仅允许一个进程使用的资源称为临界资源。许多物理设备都属于临界资源，例如打印机等。此外，很多变量、数据都可以被若干进程共享，也属于临界资源。
>
> 对临界资源的访问，必须互斥地进行。在每个进程中，**访问临界资源的那段代码称为临界区**。为了保证临界资源的正确使用，可以将临界资源的访问过程分为 4 个部分：
> 1. 进入区：为了进入临界区使用临界资源，在进入区要检查是否可以进入临界区，若能够进入，需要设置正在访问临界区的标志，以阻止其他进程同时进入临界区。
> 2. 临界区：进程中访问临界资源的那段代码，又称为临界段。
> 3. 退出区：将正在访问临界区的标志清除。
> ```c
> while(1){
> 	entry section; 			// 进入区
> 	critical section;		// 临界区
> 	exit section;			// 退出区
> 	remainder section;		// 剩余区
> }
> ```

### 进程互斥的软件实现方法

#### 单标志法

算法思想：两个进程在访问完临界区后会把使用临界区的权限转让给另一个进程，也就是说每个进程进入临界区的权限只能被另一个进程赋予。在下面的伪 c 代码中，我们设置 `turn` 为进程标志号，表示目前可以使用临界区的进程。

```c title=进程p0
// P0 进程
while(turn != 0); // 进入区
critical section; // 临界区
turn = 1;         // 退出区
remainder section;// 剩余区
```

```c title=进程p1
// P1 进程
while(turn != 1); // 进入区
critical section; // 临界区
turn = 0;         // 退出区
remainder section;// 剩余区
```

> [!note] 单标志法分析
> 单标志法虽然可以实现互斥的访问资源，但是违反了空闲让进的原则。
>
> 原因：因为在该算法中，两个进程必须交替进入临界区，若某个进程不再进入临界区，则另一个进程也无法进入临界区。例如，若 p0 顺利进入临界区并从临界区离开，则此时临界区是空闲的，且标志位 `turn=1`。如果 p1 之后没有进入临界区的打算，`turn=1` 将会一直保持，使得 p0 无法进入临界区。

#### 双标志先检查法

算法思想：设置一个布尔数组，数组中各个元素用于标记各个进程想要进入临界区的意愿。每个进程在进入临界区之前先检查当前有没有别的进程需要进入临界区，如果没有，则把自身的标志设为 true，之后开始访问临界区。

```c title=进程p0
while(flag[1]); 	// 进入区，检查是否有其他进程在访问
flag[0] = true;	 	// 进入区，设置自己在访问
critical section; 	// 临界区
flag[0] = false; 	// 退出区
remainder section; 	// 剩余区
```

```c title=进程p1
while(flag[0]); 	// 进入区，检查是否有其他进程在访问
flag[1] = true;	 	// 进入区，设置自己在访问
critical section; 	// 临界区
flag[1] = false; 	// 退出区
remainder section; 	// 剩余区
```

> [!note] 双标志法分析
> 双标志法在按照一定的顺序执行时可能会导致两个进程同时访问临界区，违反了忙则等待的原则。
>
> 原因：在检查与上锁的处理不是一气呵成的，可能在中间出错。例如，p0 在执行完第 1 行后，执行第 2 行之前，p1 可能执行了第一行，此时两个进程同时进入了临界区。

#### 双标志后检查法

算法思想：前一个算法的问题是先检查后上锁，但是这样导致了两个进程同时进入临界区的问题。因此该方式使用先上锁后检查的方法来避免上述问题。

```c title=进程p0
flag[0] = true; 	// 进入区，先上锁
while(flag[1]); 	// 进入区，后检查
critical section; 	// 临界区
flag[0] = false;  	// 退出区
remainder section;	// 剩余区
```

```c title=进程p1
flag[1] = true; 	// 进入区，先上锁
while(flag[0]); 	// 进入区，后检查
critical section; 	// 临界区
flag[1] = false;  	// 退出区
remainder section;	// 剩余区
```

> [!note] 双标志后检查法分析
> 这个方法虽然解决了忙则等待的问题，但是如果并发的执行上锁指令，会导致两者都无法进入临界区。因此违背了空闲让进和有限等待的原则，会应各进程都长期无法访问临界资源而产生饥饿现象。
>
> 原因：与之前相同，检查与上锁不是一气呵成的，因此交替进行时可能出错。例如，p0 在执行第 1 行后，执行第 2 行之前，p1 执行了第一行，此时 `flag` 中 p0 和 p1 标志位均为 `true`，导致双方在第 2 行都陷入了等待，无法访问临界区。

#### Peterson 算法

算法思想：结合双标志法、单标志法的思想，如果双方都争着想要进入临界区，则先让对方进入临界区。也就是说，在每个进程进入临界区之前，先设置自己的 `flag` 标志，在设置允许进入 `turn` 标志，之后，再同时检测对方的 `flag` 和 `turn` 标志，以确保双方同时要求进入临界区之前，只允许一个进程进入。

```c title=进程p0
// P0 进程
flag[0] = true;            // 进入区，表示意愿
turn = 1;                  // 进入区，优先让其他进程进入
while(flag[1] && turn==1); // 进入区，有其他进程要进入，等待
critical section;
flag[0] = false;
remainder section;
```

```c title=进程p1
// P0 进程
flag[1] = true;            // 进入区，表示意愿
turn = 0;                  // 进入区，优先让其他进程进入
while(flag[0] && turn==0); // 进入区，有其他进程要进入，等待
critical section;
flag[1] = false;
remainder section;
```

> [!note] Peterson 算法分析
> Peterson 算法用软件的方法解决了进程互斥问题，遵循了空闲让进、忙则等待、优先等待是三个原则，但是仍然未遵循让权等待原则。
>
> 分析：为了进入临界区，p0 先设置 `flag[0]=1`，并设置 `turn=1`，表示让 p1 先进入临界区。若 p1 和 p0 同时试图进入临界区，这时由 `turn` 决定最后由谁进入临界区。即后执行 `turn=i` 的进程将后进入临界区。在进入临界区的进程执行完毕后，将意愿标志 `flag` 恢复为 `0`，此时，另一个进程可以进入临界区。

### 进程互斥的硬件实现方法

计算机提供了特殊的硬件指令，允许对一个字的内容进行检测和修正，或者对两个字的内容进行交换等。

#### 中断屏蔽方法

当一个进程正在执行它的临界区代码时，防止其他进程进入其临界区的最简单的方法是关中断，*因为 CPU 只有在发生中断时引起进程切换，因此屏蔽中断能够保证当前运行的进程让临界区代码顺利执行完*。其典型的模式为：
```c
...
关中断;
临界区;
开中断;
...
```

> [!note] 中断屏蔽方法分析
> - 关中断后即不允许当前进程被中断，也必然不会发生进程切换
> - 直到当前进程访问完临界区，再执行开中断指令，才有可能有别的进程上处理机访问临界区
> - 缺点：
> 	- 只适用于操作系统内核进程，不适用于用户进程 (开/关中断是特权指令)。
> 	- 限制了 CPU 交替执行程序的能力，因此系统效率会明显降低。
> 	- 不适用于多处理机系统，因为在一个 CPU 上关中断并不能防止进程在其他 CPU 上执行相同的临界区代码。

#### TestAndSet 指令

简称为 TS 指令，也可以称为 TSL (Test And Set Lock) 指令。TSL 指令是用硬件实现的，执行过程中不允许被中断，只能一气呵成。TSL 指令的功能使用 c 语言描述如下：
```c
// lock 表示当前区域是否被加锁
bool TestAndSet(bool *lock){
	bool old;
	old = *lock;	// old 用来存放 lock 的旧值
	*lock = true;	// 无论之前是否加锁，都将 lock 设置为 true
	return old;		// 返回 lock 的旧值
}

// 使用TSL指令实现的互斥逻辑
while(TestAndSet(&lock)); // 进入区，上锁并检查
critical section;
lock = false; // 退出区，解锁
remainder section;
```

> [!note] TSL 指令分析
> 与软件实现的方法相比，TSL 指令把上锁和检查用硬件的方式变成了一气呵成的原子操作。
> - 优点：实现简单，且适用于多处理机环境。
> - 缺点：不满足**让权等待**原则。暂时无法进入临界区的进程会循环执行 TSL 指令。

#### Swap 指令

Swap 指令也称为 Exchange 指令，或者简称 XCHG 指令。Swap 指令用于交换两个字的内容，是使用硬件实现的，执行过程不允许被中断，只能一气呵成。下面用 c 语言描述其逻辑：
```c
Swap(bool *a, bool *b){
	bool temp = *a;
	*a = *b;
	*b = temp;
}

// 下面是用Swap实现互斥的算法逻辑
bool old = true;
while (old == true) Swap(&lock, &old); // 进入区
critical section;
lock = false;
remainder section;
```

> [!note] Swap 指令分析
> 使用 Swap 指令与 TSL 并无太大区别，都是先记录下此临界区是否已经被上锁 (记录在 old 变量)，在将上锁标记 lock 设置为 true，最后检查 old。如果 old 为 false 则说明之前没有别的进程对临界区上锁，则可以跳出循环。
> - 优点：实现简单，无需像软件实现方法那样严格检查是否会有逻辑漏洞，适用于多处理机环境
> - 缺点：不满足让权等待原则。

> [!note] 硬件指令方式总结
> 使用硬件指令方法是实现互斥具有以下优点：
> 1. 简单、容易验证其正确性；
> 2. 适用于任意数目的进程，支持多处理器系统；
> 3. 支持系统中有多个临界区，只需要为每个临界区设立一个布尔变量。
>
> 缺点：
> 1. 等待进入临界区的进程会占用 CPU 执行 `while` 循环，不能实现让权等待；
> 2. 从等待进程中随机选择一个进入临界区，有些进程可能一直选不上，导致饥饿现象；

#### 互斥锁

解决临界区最简单的工具是互斥锁 (mutex lock)。一个进程在进入临界区时获得相应的锁，在退出临界区时释放锁。
- 使用函数 `acquire()` 获得锁，使用函数 `release()` 释放锁。
- 每个互斥锁有一个布尔变量 `available` 表示锁是够可用，如果锁可用，调用 `acquire()` 可以成功；如果锁不可用，调用 `acquire()` 会被阻塞，直到锁被释放。
- `acquire()` 与 `release()` 的执行必须是原子操作。
```c
void acquire(){
	while(!available);	// 忙等待
	available=false;	// 获得锁
}

void release(){
	available=true;		// 释放锁
}
```

> [!note] 互斥锁分析
> 互斥锁的主要缺点是忙等待，当有一个进程在临界区中，任何其他进程在进入临界区时必须连续循环调用 `acquire()`。当多个进程共享同一个 CPU 时，就浪费了 CPU 周期，因此，互斥锁通常用于多处理器系统，一个线程可以在一个处理器上等待，不影响其他进程的执行。

> [!note]
> 需要连续循环忙等检查的互斥锁可以称为自旋锁 (spin lock)，如 TSL 指令、Swap 指令、单标志指令。需要忙等的锁都违反让权等待的原则。
> - 优点：等待期间不用切换进程上下文，多处理器系统中，若上锁的时间短，则等待代价很低。
> - 不太适用于单处理器系统，忙等的过程中不可能解锁。

### 信号量机制

用户进程可以通过操作系统提供的一对原语来对信号量进行操作，从而很方便的实现了进程互斥、进程同步。

信号量是一个变量，用于表示系统中某种资源的数量，可以是整数或者更加复杂的记录型信号量。使用两个原语来进行操作
- `wait(S)` 或者 P 操作
- `signal(S)` 或者 V 操作

#### 整型信号量

用一个整数型的变量作为信号量，用来表示系统中某种资源的数量。对于这种信号量，PV 操作描述为
```c
void wait(int S){  // wait 原语，相当于进入区
	while(S <= 0); // 如果资源数不够，就一直等待
	S = S - 1;     // 如果资源数量足够，则占用一个资源
}

void signal(int S){ // signal 原语，相当于退出区
	S = S + 1;      // 使用完资源后，在退出区释放资源
}
```

> [!note] 整型信号量的缺陷
> 在 wait 原语中，如果资源数量不足，会一直占用 CPU，造成忙等待。因此，该机制并未遵守让权等待的原则。

#### 记录型信号量

记录型信号量是一种不存在忙等待问题的进程同步机制。记录型信号量是用记录型数据结构表示的信号量，除了需要一个用于代表资源数目的整型变量 `value` 外，再增加一个进程链表 `L`，用于链接所有等待该资源的进程。记录型信号量可描述为：
```c
/*记录型信号量的定义*/
typedef struct {
	int value;        // 剩余资源数
	struct process *L;// 等待队列
} semaphore;

void wait(semaphore S){ // 相当于申请资源
	S.value--;
	if(S.value < 0){
		// add this process to S.L
		block(S.L);
	}
}

void signal(semaphore S){ // 相当于释放资源
	s.value++;
	if (S.value <= 0){	// 如果有处于等待的进程，则将其唤醒
		wakeup(S.L);
	}
}
```

> [!note]
> - 如果剩余资源不够，使用 block 原语使进程从运行态进入阻塞态，并挂到等待队列中。
> - 释放资源后，若还有别的进程在等待这种资源，则使用 `weakup` 原语唤醒等待队列中的一个进程，该进程转变为就绪态。
>
> `S.value` 的初值表示系统中某种资源的数目。这样的机制遵循了让权等待的原则。

#### 实现进程互斥

为了使多个进程能够互斥的访问某个临界资源，需要为该资源设置一个互斥信号量 `S`，其初值为 `1`，即表示可用的资源数为 1，以达到只有一个进程可以访问临界资源的目的。然后，将各个进程访问该资源的临界区置于 `P(S)` 和 `V(S)` 之间。
```c
semaphore S = 1;
P1(){
	...;
	P(S);
	进程p1的临界区;
	V(S);
	...;
}
P2(){
	...;
	P(S);
	进程p2的临界区;
	V(S);
	...;
}
```

> [!note]
> 在使用信号量解决问题前，需要明确：
> 1. 信号量的值=这种资源的剩余数量 (如果信号量的值小于 0，说明有进程在等待这种资源)
> 2. `P(S)`：申请一个资源 S，如果资源不够就阻塞等待
> 3. `V(S)`：释放一个资源 S，如果有进程在等待该资源，则唤醒一个进程

> [!note] 实现进程互斥的步骤
> 1. 分析并发进程的关键活动，划定临界区
> 2. 设置互斥信号量 mutex，初值为 1 (申请一个进入临界区的名额，设置为 1 以实现互斥)
> 3. 在进入区 `P(mutex)`，申请进入
> 4. 在退出区 `V(mutex)`，申请释放

#### 实现进程同步

同步的目的是让本来异步并发的进程相互配合，有序推进。例如，进程 `P1` 和 `P2` 并发执行，由于异步性，因此二者的推进次序是不确定的，若 `P2` 的语句 `y` 要使用 `P1` 的语句 `x` 的运行效果，则必须保证语句 `y` 一定在语句 `x` 之后执行。为了实现这种同步关系，需要这是一个同步信号量 `S`，其初值为 `0`(可以理解为，刚开始没有这种资源，`P2` 需要使用这种资源，而 `P1` 产生这种资源)。
```c
semaphore S = 0;	// 初始化信号量为0
P1(){
	x;		// 执行语句x
	V(X);	// 告诉p2,x已经执行
	...;
}

P2(){
	...;
	P(S);	// 检查语句x是否执行
	y;		// 获得x的运行结果，执行y
	...;
}
```

> [!note]
> 进程同步需要各并发进程按照有序地推进。实现进程同步的步骤：
> 1. 分析什么地方需要实现同步关系，即必须保证一前一后执行两个操作
> 2. 设置同步信号量 S，初始为 0
> 3. 在需要先运行的代码后使用 `V(S)`，即在前操作后再生产该资源
> 4. 在需要后运行的代码之前使用 `P(S)`，即在后操作前必须获得同步资源

> [!tip]
> 简单来说，就是前 V 后 P。
> - 先执行同步前代码，然后执行 `P` 操作。因此是后 `P`。
> - 先执行 `V` 操作，然后执行同步后的代码，因此是前 `V`。

> [!example] 使用 PV 操作描述程序段之间的关系
> 对于多个进程构成的 [[数据结构/图#图的应用#拓扑排序|AOV网络]]，我们可以利用 PV 同步信号量将每一个前驱关系表达出来，即有多少个箭头，就使用多少信号量，以保证程序的顺序执行。

> [!note] 分析进程同步和互斥问题的方法步骤
> 1. 关系分析。找出问题中的进程数，并分析他们之间的同步和互斥关系。
> 2. 整理思路。根据进程的操作流程，确定 PV 操作的大致顺序。
> 3. 设置信号量。根据上面两步，设置需要的信号量，确定初值。

#### 经典同步问题

##### 生产者消费者问题

> [!info] 问题描述
> 系统中有一组生产者进程和一组消费者进程，生产者进程每次生产一个产品放入缓冲区，消费者进程每次从缓冲区中取出一个产品并使用。其中
> - 生产者、消费者共享一个初始为空，大小为 n 的缓冲区
> - 只有缓冲区没满时，生产者才能把产品放入缓冲区，否则必须等待
> - 只有缓冲区不空时，消费者才能从中取出产品，否则必须等待
> - 缓冲区是一种临界资源，各个进程必须互斥地访问

> [!info] 分析
> 1. 生产者和消费者对缓冲区互斥访问是互斥关系，同时，只有生产者生产之后，消费者才能消费，因此它们也是同步关系。
> 2. 设置一个互斥信号量控制互斥访问缓冲池，设置一个同步信号量用于控制缓冲池不为空时消费者才能读取，设置一个同步信号量用于控制缓冲池不满时生产者才能写入。

```c
semaphore mutex = 1; // 互斥信号量，实现对缓冲区的互斥访问
semaphore empty = n; // 同步信号量，表示空闲缓冲区的数量
semaphore full = 0; // 同步信号量，表示产品的数量，即非空缓冲区的数量

producer(){
	while(1){
		生产一个产品;
		P(empty);
		P(mutex);
		把产品放入缓冲区;
		V(mutex);
		V(full);
	}
}

consumer(){
	while(1){
		P(full);
		P(mutex);
		从缓冲区取出一个产品;
		V(mutex);
		V(empty);
		使用产品;
	}
}
```

> [!warning]
> - 改变相邻 P 操作的顺序后，将会产生死锁。
> - 改变相邻 V 操作的顺序后，不会有任何问题。

> [!tip]
> 在实现 PV 操作时，需要特别注意 P 操作的顺序，因为 P 操作在资源不足时会阻塞进程。如果所有进程的 P 操作可以同时不满足，则所有进程都被阻塞，发生死锁。但是 V 操作不会阻塞进程，因此相邻的 V 操作一般没有影响。
>
> 一般而言，我们将互斥锁放在最内层。

##### 多生产者-多消费者问题

> [!info] 问题描述
> 桌子上有一只盘子，每次只能向其中放入一个水果。
> - 爸爸专向盘子中放苹果，妈妈专向盘子中放橘子，儿子专等着吃盘子中的橘子，女儿专等着吃盘子中的苹果。
> - 只有盘子空时，爸爸或妈妈才可向盘子中放一个水果。
> - 仅当盘子中有自己需要的水果时，儿子或女儿可以从盘子中取出水果。

1. 这里有四个进程，即爸爸、妈妈、儿子、女儿，其中爸爸和妈妈是写进程，儿子和女儿是读进程。
2. 每次只能向盘中放入一个水果，即爸爸和妈妈只能互斥的放入水果。盘子空时，才能放入水果，因此需要一个同步信号量表示盘子为空。实际上，这两个可以使用同一个信号量来实现，因为盘子中只能有一个水果，而数量为 1 的信号量可以用于表示互斥访问。
3. 仅当盘子中有自己需要的水果时，儿子和女儿才能取出对应的水果，因此需要两个同步信号量表示盘子中对应的水果数量。

```c
semaphore plate = 1;
semaphore orange = 0;
semaphore apple = 0;

data(){
	while(1){
		// prepare an apple
		P(plate);
		// 放苹果
		V(apple);
	}
}

mom(){
	while(1){
		// prepare an orange
		P(plate);
		// 放橘子
		V(orange);
	}
}

son(){
	while(1){
		P(apple);
		// 获得苹果
		V(plate);
	}
}

daughter(){
	while(1){
		P(orange);
		// 获得橘子
		V(plate);
	}
}
```

##### 吸烟者问题

> [!info] 问题描述
> 假设一个系统有三个抽烟者进程和一个供应者进程。
> - 每个抽烟者不停地卷烟并抽烟。但是要卷起并抽掉一支烟，抽烟者需要有三种材料：烟草、纸和胶水。
> - 三个抽烟者中，第一个拥有烟草、第二个拥有纸、第三个拥有胶水。
> - 供应者无限地提供三种材料，供应者每次将两种材料放桌子上，拥有剩下那种材料的抽烟者卷一根烟并抽掉它，并给供应者进程一个信号量告诉完成了，供应者就会放另外两种材料在桌上。这个过程一种重复，让三个抽烟者轮流地抽烟。

1. 供应者供应后对应的产品后，抽烟者才能进行抽烟。
2. 抽烟者拿走数据后，供应者才能向桌子上放资源。
3. 抽烟者抽完烟之后，才会去拿材料。

```c
semaphore offer1 = 0;
semaphore offer2 = 0;
semaphore offer3 = 0;
semaphore finish = 0;

process supplier(){
	while(1){
		num = (num + 1) % 3;
		switch(num){
			case 0: V(offer1);	// 供应抽烟者1要的材料
			case 1: V(offer2);	// 供应抽烟者2要的材料
			case 2: V(offer3);	// 供应抽烟者3要的材料
		}
		supply(num);
		P(finish);
	}
}

process smoker1(){
	while(1){
		P(offer1);
		get_and_smoke();
		V(finish);
	}
}
```

##### 读者写者问题

> [!info] 问题描述
> 有读者和写者两组并发进程，共享一个文件，当两个或两个以上的读进程同时访问共享数据时不会产生副作用，但若某个写进程和其他进程 (读进程或写进程) 同时访问共享数据时则可能导致数据不一致的错误。因此要求：
> 1. 允许多个读者可以同时对文件执行读操作
> 2. 只允许一个写者往文件中写信息
> 3. 任一写者在完成写操作执之前不允许其他读者或者写者工作
> 4. 写者执行写操作前，应让已有的读者和写者全部退出

1. 写进程与其他所有的进程互斥的访问文件，需要使用一个互斥量来保证写进程和读进程、写进程与写进程互斥的访问文件。
2. 读进程与读进程之间可以并发的访问文件，因此可以让第一个到来的读进程加锁，最后一个离开的读进程解锁。我们可以使用一个 `count` 变量记录读进程数量，当 `count=0` 时加锁。
3. 在读进程同时到来时，可能会导致同时进行了 `P` 操作，导致一个读进程被阻塞。这是由于 `count` 的操作不是一气呵成的，因此可以使用一个互斥量来保证互斥的访问 `count` 变量。

```c
semaphore wr = 1;
semaphore mutex = 1;
int count = 0;

writer(){
	while(1){
		P(wr);		// 互斥的访问文件
		write();
		V(wr);
	}
}

reader(){
	while(1){
		P(mutex);		//	访问 count 的过程需要是互斥的
		if(count == 0)		// 如果是第一个读进程，加锁
			P(wr);
		count++;
		V(mutex);
		read();
		P(mutex);
		count--;
		if(count == 0)		// 如果是最后一个读进程，解锁
			V(wr);
		V(mutex);
	}
}
```

> [!note]
> 上述过程是读者优先的，如果不断有读者到来，那么写进程就会一直被阻塞在 P 操作处，永远无法进行写操作。

> [!example]- 写优先解决方法
> ```c
> semaphore wr = 1;
> semaphore mutex = 1;
> int count = 0;
> 
> semaphore w = 1; // 用于实现写优先的互斥量
> 
> writer(){
> 	while(1){
> 		P(w);		// 如果有写进程到来，则读者进程不能再进入文件区
> 		P(wr);		// 互斥的访问文件
> 		write();
> 		V(wr);
> 		V(w);
> 	}
> }
> 
> reader(){
> 	while(1){
> 		P(w);			// 如果有写进程到来，则读者进程不能再进入文件区
> 		P(mutex);		//	访问 count 的过程需要是互斥的
> 		if(count == 0)	// 如果是第一个读进程，加锁
> 			P(wr);
> 		count++;
> 		V(mutex);
> 		v(w);
> 		read();
> 		P(mutex);
> 		count--;
> 		if(count == 0)	// 如果是最后一个读进程，解锁
> 			V(wr);
> 		V(mutex);
> 	}
> }
> ```

##### 哲学家进餐问题

> [!info] 题目描述
>  一张圆桌上坐着 5 名哲学家，每两个哲学家之间的桌上摆了一根筷子，桌子的中间是一碗米饭。
>  - 哲学家们倾注毕生的精力用于思考和进餐，哲学家在思考时，不影响他人。
>  - 只有当哲学家饥饿时，才试图拿起左右两根筷子 (一根一根地拿起)。
>  - 如果筷子已经在他人手上，则需等待。
>  - 饥饿的哲学家只有同时拿起两根筷子才可以开始进餐，当进餐完毕后，放下筷子继续思考。

1. 5 位哲学家与左右邻居中间的筷子的访问是互斥的；
2. 该问题主要需要考虑的让一名哲学家拿到左右的筷子而不再成死锁或者饥饿现象。解决的方法有两种：
	- 让他们同时拿两根筷子；
	- 对每名哲学家的动作指定规则，避免饥饿或者死锁现象的发生；
3. 信号量设置：定义互斥信号量数组 `chopstick[5]={1, 1, 1, 1, 1}`，用于对 5 个筷子的互斥访问。哲学家按照顺序编号为 0 到 4。

```c
semaphore chopstick[5] = {1, 1, 1, 1, 1};
Pi(){
	while(1){
		P(chopstick[i]);
		P(chopstick[(i+1)%5]);
		eat();
		V(chopstick[(i+1)%5]);
		V(chopstick[i]);
		think();
	};
}
```
在上面的情况下，哲学家如果分别拿起左边的筷子时，筷子已被拿光，每个哲学家都无法拿到右边的筷子，出现死锁。

为了防止死锁，可以对哲学家施加一些限制条件，例如
- 至多允许 4 名哲学家同时进餐；
- 仅当哲学家左右两边的筷子都可用时，才允许它抓起筷子；
- 对哲学家顺序编号，要求奇数号哲学家先拿左边的筷子，然后拿右边的筷子，而偶数号哲学家相反；

下面是对于第二种的实现：
```c
semaphore chopstick[5] = {1, 1, 1, 1, 1};
semaphore mutex=1;
Pi(){
	while(1){
		P(mutex);				// 规定每次只能有一个哲学家持有单数个筷子
		P(chopstick[i]);
		P(chopstick[(i+1)%5]);
		V(mutex);
		eat();
		V(chopstick[i]);
		V(chopstick[(i+1)%5]);
	}
}
```

## 管程

在使用信号量机制编写进程同步时，需要面对复杂的 PV 操作，容易出错而造成系统的死锁。管程作为一种高级同步机制被引入。管程的特性保证了进程互斥，无需程序员自己实现互斥，从而降低了死锁发生的可能性。同时管程提供了条件变量，可以让程序员灵活的实现进程同步。

管程是一种特殊的软件模块，定义了一个数据结果和能为并发进程所执行的一组操作，这组操作可以能够同步进程和改变管程中的数据。管程由下面的部分组成：
1. 管程的名称。
2. 局部于管程内部的共享数据结果说明。
3. 对于该数据结构进行操作的一组过程 (函数)。
4. 对局部于管程内部的共享数据设置初始值的语句。

> [!note] 管程的基本特征
> 1. 局部于管程的数据只能被局部于管程的过程所访问。
> 2. 一个进程只有通过管程内的过程才能进入管程访问共享数据。
> 3. 每次仅允许一个进程在管程内执行某个内部过程。
>
> 在实现上，管程可以视为一个类，我们只能通过调用该类的方法来对管程中的数据进行控制，例如获得资源、归还资源等。

> [!note] 条件变量
> 当一个进程进入管程后被阻塞，直到阻塞的原因解除时，在此期间，如果该进程不释放管程，那么其他进程无法进入管程。为此，将阻塞原因定义为了条件变量 (condition)。通常，一个进程被阻塞的原因可能有多个，因此管程中设置了多个条件变量，每个条件变量设置了一个等待队列。
>
> 对于条件变量，只能进行两种操作：
> - `x.wait`：当 `x` 对应的条件不满足时，正在调用管程的进程调用 `x.wait` 将自己插入 `x` 条件的等待队列，并释放管程。此时其他进程可以使用该管程。
> - `x.signal`：当 `x` 对应的条件发生了变化，则调用 `x.signal`，唤醒一个因 `x` 条件而阻塞的进程。

> [!note] 条件变量与信号量比较
> 1. 相似点：条件变量的 `wait/signal` 操作与信号量的 PV 操作类似，可以实现进程的阻塞和唤醒。
> 2. 不同点：条件变量是没有值的，仅实现了排队等待的功能；信号量是有值的，反映了剩余资源数，而在管程中，剩余资源数是用共享数据结构记录的。

## 死锁

> [!definition|Definition] 死锁
> 并发环境下，各个进程因争抢资源而造成的一种互相等待对方手里的资源，导致各进程都阻塞，都无法向前推进的现象，称为**死锁**。发生死锁后，若没有外力干涉，这些进程都将无法向前推进。

> [!note] 容易与死锁混淆的概念：
> 1. 死锁：进程互相等待对方手里的资源，导致各进程都阻塞，无法向前推进的现象
> 2. 饥饿：由于长期得不到想要的资源，某进程无法向前推进的现象。或者进程在信号量内无穷等待的情况。
> 3. 死循环：某进程执行过程中一直无法跳出某个循环的现象
>
> 死锁与饥饿是管理者 (操作系统) 的问题，死循环是被管理者的问题。

> [!note] 死锁与饥饿的主要差别
> 1. 发生饥饿的进程可以只有一个，但是如果有死锁现象，那么发生死锁的进程必然大于或等于两个。
> 2. 发生饥饿的进程可能处于就绪态 (由于调度算法不当导致) 或者阻塞态 (长期得不到需要的 IO 设备)；发生死锁的进程必然处于阻塞态。

### 死锁产生的必要条件

> [!note] 产生死锁的原因
> 1. 系统资源的竞争。通常系统中的不可剥夺资源不足以满足多个进程运行的需要，使得进程在运行过程中，会因为争夺资源而陷入僵局。*只有对不可剥夺资源的竞争才可能产生死锁*，对可剥夺资源 (如 CPU 或者主存) 是不会引起死锁的。
> 2. 进程推进顺序非法。请求和释放资源的顺序不当，也同样会导致死锁。
> 3. 对信号量的使用不当也会引起死锁。

产生死锁必须满足下面的四个条件，主要有一个条件不成立，死锁就不会发生：
1. **互斥条件**：只有对必须互斥使用的资源的争抢才会导致死锁。
2. **不剥夺条件**：进程所获得的资源在未使用之前，不能由其他进程强行夺走，只能主动释放。
3. **请求和保持条件**：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源由被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放。
4. **循环等待条件**：存在一种进程资源的循环等待链，链中每个进程已获得的资源同时被下一个进程所请求。

> [!note]
> 发生死锁时一定有循环等待，但是发生循环等待时未必发生死锁。即循环等待是死锁的充分不必要条件。如果同类资源数大于 1，则即使有循环等待，也未必发生死锁。但是**如果系统中每类资源都只有一个，那循环等待就是死锁的充分必要条件**。

> [!tip]
> 总结来说，对于不可剥夺资源的不合理分配，可能导致死锁。

### 死锁的处理策略

为了使系统不发生死锁，必须设法破坏死锁的 4 个必要条件之一，或者允许死锁的产生，但是当发生死锁时能够检测死锁，并有能力恢复。
1. 预防死锁：设置某些条件，破坏产生死锁的 4 个必要条件中的一个或者几个。
2. 避免死锁：在资源的动态分配中，用某种方法防止系统进入不安全状态。
3. 死锁的检测和解除：允许进程在运行过程中发生死锁，通过系统的检测机构及时检测出死锁的发生，然后采取某种措施解除死锁。

#### 预防死锁

预防死锁的思路是破环死锁发生的四个必要条件中的任意一个。

##### 破环互斥条件

如果将互斥使用的资源改造为允许共享使用，则系统不会进入死锁状态。例如 **SPOOLing** 技术，该技术将独占设备在逻辑上改造为共享设备。

> [!note] 破坏互斥条件的缺点
> 由于不是所有的资源否可以改造为可共享使用的资源，并且为了系统安全，很多地方还必须保护这种互斥性，因此很多时候无法破坏互斥条件。

##### 破坏不剥夺条件

有几种方案可以破坏不剥夺条件：
1. 当某个进程请求新的资源得不到满足时，它必须立即释放保持的所有资源，待到以后需要时再重新申请。
2. 当某个进程需要的资源被其他进程占用时，可以通过操作系统协助，将想要的资源强行剥夺。

> [!note] 破坏不剥夺条件的缺点
> - 实现起来较为复杂。
> - 释放已获得的资源可能会造成前一阶段的工作失效。因此这种方法一般只适用于已保存和恢复状态的资源，如 CPU。
> - 反复地申请和释放资源会增加系统开销，降低系统吞吐量。
> - 若采用方案一，则可以导致饥饿。

##### 破环请求和保持条件

要求进程在请求资源时不能持有不可剥夺资源，可以通过两种方式实现：
1. 采用静态分配方法，即进程在运行前一次申请完它所需要的全部资源。在它的资源没有得到满足前，不让它投入运行。一旦投入运行后，这些资源就一直归它所有，该进程就不会再请求别的资源。
2. 允许进程只获得运行初期所需的资源后，便可开始运行。进程在运行过程中再逐步释放已分配给自己且已使用完毕的全部资源后，才能请求新的资源。

> [!note] 破坏请求和保持条件的缺点
> 方法一实现起来较为简单，但是也有明显的缺点：
> - 有些资源可能只需要很短的时间，因此如果进程的整个运行都一直保持着所有资源，就会造成严重的资源浪费，资源利用率极低。
> - 可能导致某些进程饥饿。由于个别资源被其他进程长期占用，将导致等待该资源的进程迟迟不能开始运行。
>
> 方法二改进了这些缺点。

##### 破环循环等待条件

要破坏循环等待条件，可以采用顺序资源分配法。
- 首先给系统中的各类资源编号，规定每个进程必须按照编号递增的顺序请求资源，同类资源 (即编号相同的资源) 一次申请完。
- 一个进程只有已占有小编号的资源时，才有资格申请更大编号的资源。

按照此规则，已持有更大编号资源的进程不可能逆向地回来申请小编号资源，从而不会产生循环等待的现象。在任意时刻，总有一个进程拥有的资源编号是最大的，那么这个进程在之后一定可以畅通无阻的运行下去。

> [!note] 破坏循环等待条件的缺点
> 1. 不方便增加新的设备，因为可能需要重新分配所有的编号。
> 2. 进程实际使用的资源的顺序可能和编号的递增顺序不一致，会导致资源的浪费。
> 3. 必须按规定次序申请资源，用户编程麻烦。

#### 避免死锁

避免死锁同样属于实现预防策略，但是不是实现采取某种限制措施破坏死锁的必要条件，而是在每次分配资源的过程中，都要分析此次分配是否会带来死锁风险，只有在不产生死锁的情况下，系统才会为其分配资源。这种方法所施加的限制条件较弱，可以获得较好的系统性能。

> [!definition|Definition] 安全序列
> 如果系统按照这种序列分配资源，则每个进程都能顺利完成。只要找到一个安全序列，系统就是安全状态。安全状态可能有多个。

如果分配了资源之后，系统找不出任何一个安全序列，系统就进入了不安全状态。这就意味着之后可能很多进程都无法顺利的执行下去。当然，如果有进程提前归还了一些资源，那系统也有可能重新回到安全状态，不过我们在分配资源之前总是要考虑最坏的情况。

> [!warning]
> 进入不安全状态未必发生死锁，但是发生死锁时一定是处于不安全状态。

> [!note] 安全状态的作用
> 如果系统处于安全状态，就一定不会发生死锁。如果系统进入了不安全状态，就可能发生死锁。因此可以在资源分配之前先预判这次分配是否会导致系统进入不安全状态，以此决定是否答应资源分配请求。

银行家算法是最著名的死锁避免算法，其思想是：将操作系统视为银行家，操作系统管理的资源视为银行家管理的资金，进程请求资源相当于用于向银行家贷款。
- 进程运行前先声明对各种资源的最大需求量，其数目不应超过系统的资源总量。
- 当进程在运行中申请资源时：
	1. 系统必须先确定是否有足够的资源分配给该进程。
	2. 如果有足够的资源，进一步试探这次分配是否会使系统处于不安全的状态。
	3. 如果不会使系统处于不安全状态，才将资源分配给进程，否则进程等待。

> [!note] 银行家算法
> 假设系统中有 n 个进程，有 m 种资源。每个进程在运行前先声明对各种资源的最大需求数，于是可以使用一个 $n\times m$ 的矩阵表示所有进程对各种资源的最大需求数。设最大需求矩阵为 `Max`,其中 `Max[i][j]=K` 表示进程 $P_i$ 最多需要 $K$ 个资源 $R_j$。同理，系统可以使用一个 $n\times m$ 的分配矩阵 `Allocation` 表示对所有进程的资源分配情况。各个进程还需要多少各类资源可以表示为
> $$
> \text{Max} - \text{Allocation} = \text{Need}
> $$
> 此外，还需要一个长度为 m 的一维数组 `Available` 表示当前进程中还有多少可用资源。当某进程 $P_i$ 像系统申请资源，可以用一个长度为 m 的一维数组 $Request_i$ 表示本次申请的各种资源数量。银行家算法概括如下：
> 1. if Request<sub>i</sub>\[j\] <= Need\[i, j\] for j in range(m)
> 	1. if Request<sub>i</sub>\[j\] <= Available\[j\] for j in range(m)
> 		1. 系统试探着把资源分配给进程 P<sub>i</sub>，并修改相应的数据
> 		2. Available = Available - Request<sub>i</sub>
> 		3. Allocation\[i, j\]=Allocation\[i, j\] + Request<sub>i</sub>\[j\]
> 		4. Need\[i, j\]=Need\[i, j\]-Request<sub>i</sub>\[j\]
> 		5. 操作系统执行安全性算法，检查此次资源分配后，系统是否处于安全状态，若安全，才正式分配；否则，恢复相应数据，让进程阻塞等待
> 	2. else 表示尚无足够资源，P<sub>i</sub>必须等待
> 2. else 认为出错

> [!note] 安全性算法
> 检查当前剩余的可用资源能否满足某个进程的最大需求，如果可以，就把该进程加入安全序列，并把该进程持有的资源全部回收。
> 1. 初始化时安全序列为空；
> 2. 从 `Need` 矩阵中找出符合下面条件的行，将对应进程加入安全序列。
> 	- 该行对应的进程不再安全序列中
> 	- 该行小于或等于 `Work` 向量
> 3. 如果找到了，进程 $P_{i}$ 进入安全序列后，可以顺利执行，直到完毕，并释放分配给它的资源。返回步骤 2。
> 4. 如果没找到，若此时安全序列中已有所有进程，则系统处于安全状态，否则系统处于不安全状态。

#### 死锁的检查和解除

若系统为进程分配资源时不采取任何预防或避免措施，则应该提供死锁检测和避免手段。

##### 死锁的检查

> [!note] 死锁检测与死锁避免的区别
> - 死锁避免需要在进程的运行过程中一直保证之后不可能出现死锁，因此需要知道进程从开始到结束的所有资源请求。
> - 死锁检测检测某个时刻是否发生死锁，不需要知道进程在整个生命周期中的资源请求，只需要知道对应时刻的资源请求。

我们可以使用**资源分配图**来检测系统所处的状态是否为死锁状态。在资源分配图中，我们定义下面的几种结点与连线：
- 进程节点：对应一个进程；
- 资源节点：对应一类资源，一类资源可能有多个；
- 进程节点 -> 资源节点：表示进程想申请几个资源，称为请求边；
- 资源节点 -> 进程节点：表示已经为进程分配了几个资源，称为分配边；

在资源分配图中，一般使用矩形表示资源节点，矩形中的小圆表示该类资源的数量。我们可以通过化简资源分配边的方式来判断是否有死锁发生。

> [!example]- 资源分配图
> ![[image/进程管理-2.png]]

> [!note] 检测死锁的算法
> **死锁定理**：如果某时刻系统的资源分配图是不可完全简化的，那么此时系统死锁。
> 1. 在资源分配图中找到既不阻塞又不是孤点的进程 $P_i$，消去它所有的请求边和分配边，使之成为孤立的结点。
> 2. 进程 $P_i$ 所释放的资源可以唤醒某些因为资源而阻塞的进程，原来阻塞的进程可能变成非阻塞进程。
> 3. 若能消除所有的边，那么称该图是可完全简化的。即此时没有发生死锁。

##### 死锁的解除

一旦检测出死锁的发生，就应该立即解除死锁。并不是系统中的所有进程都是死锁状态，我们将发生死锁的几个进程称为死锁进程。解除死锁的主要方法有：
1. 资源剥夺法：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他死锁进程。但是需要防止被挂起的进程长时间得不到资源而饥饿。
2. 撤销进程法：强制撤销部分、甚至全部死锁进程，并剥夺这些进程的资源。
3. 进程回退法：让一个或者多个死锁进程回退到足以避免死锁的地步，这需要记录进程的历史信息，设置还原点。可以根据进程优先级、已执行时间、剩余完成时间、进程使用的资源数等原则选择回退的进程。

> [!note] 死锁进程
> 在资源分配图中，用死锁定理化简后，还有边相邻的进程就是死锁进程。

< [[操作系统/操作系统基本原理概论|操作系统基本原理概论]] | [[操作系统/内存管理|内存管理]] >
