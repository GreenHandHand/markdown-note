---
tags:
  - 并行编程
---

> [!info] 参考内容来自：[CUDA Training Series – Oak Ridge Leadership Computing Facility](https://www.olcf.ornl.gov/cuda-training-series/)

# CUDA C++ 基础

CUDA 设计是为了：
1. 充分利用 GPU 的并行性，将其用作通用计算
2. 提高性能

CUDA C++ 是指：
1. 基于工业基础的 C++
2. 是 C++ 的允许异构编程的拓展
3. 一种直观地、用于管理设备 (也就是 NVIDIA GPU)、内存之类的 API

> [!info] 在本节中，主要介绍的是 CUDA 的 C++ 接口，这是目前运用最广泛的接口。其他的一些语言也支持 CUDA，例如 Fortran, Python, Matlab 等。

## 基本概念

在 CUDA 的异构编程框架中，设备分为两端：
- Device：指 GPU 和显存 (device memory)。在 CUDA 的实现中，利用 GPU 的并行性来计算密集型任务。
- Host(TODO: 中文)：指 CPU 与内存 (host memory)。在 CUDA 实现中，剩余的、序列性的代码由 CPU 实现。

## 一般的处理流程

下面的流程简单地描述了一个通用的 GPU 处理模式：

1. 将内存中的数据复制到显存中。
	- 内存中的信息可以从 PCIe 或者 NVLink 总线上传输到显存中。
	- 这里的显存指的是 GPU 中的 DRAM，一般称为全局显存 (Global memory)。
2. 加载 GPU 程序并执行。GPU 将在内部缓存数据并进行处理，并将结果存放在显存中。
3. 将显存中的结果从 CPU 传输会内存中。

> [!note] GPU 计算是一种大规模的并行计算。

## C++ 接口

### `__global__` 函数

在 CUDA C++ 中，我们使用关键字 `__global__` 函数装饰器来指明一个函数具有如下特点：
1. 这是一个在 GPU 上运行的函数
2. 它将在 Host 端上被调用 (或者被其他的 Device 端被调用)

> [!note] nvcc 编译器
> nvcc 编译器是专门用于编译 CUDA 程序的编译器，其经过数年的发展，目前已经非常完善。可以使用与常用的 C 编译器 (例如 gcc, clang) 相同的方式来编译 CUDA 代码。
>
> nvcc 在编译过程中，会将源代码划分为 host 组件与 device 组件，其中 device 组件 (例如使用 `__global__` 声明的函数) 将被 NVIDIA 编译器编译，而 Host 组件 (例如 `main` 函数) 将会被环境中的 C++ 编辑器编译。

使用 `__global__` 声明的函数可以被 host 端调用，也可以被 device 端调用。在代码中，CUDA 规定使用三个尖括号表示在 device 上调用函数。
- 使用 `mykernel<<<grid_size, block_size>>>()` 的方式调用 device 函数。
- 这种方式也称为*内核启动 (kernel launch)*。
- 在 `<<<>>>` 中的参数是 CUDA 内核的**执行配置参数**(execution configuration)。

> [!tip] 指针
> host 访问的内存与 device 访问的显存是分离的实体，我们使用指针来访问它们。
> - Device 指针：指向 GPU 显存位置的指针。
> 	- 通常情况下在 device 代码中使用。
> 	- 通常情况下==不会==在 host 代码中被解引用。
> - Host 指针：指向 CPU 内存位置的指针。
> 	- 通常情况下==不会==在 device 代码中使用。
> 	- 通常情况下不会在 device 代码中被解引用。
> - 特殊情况：Pinned pointers, ATS, managed memory(这是什么??)

### CUDA Memory API

CUDA 提供了一些简单的 API 来操作显存，它们是仿照 C 代码的实现，因此很容易理解。
- `cudaError_t cudaMalloc(void **devPtr, size_t size)`
- `cudaError_t cudaMemcpy(void *dst, const void *src, size_t count, cudaMemcpyKind kind)`
- `cudaError_t cudaFree(void *devPtr)`

> [!tip] 上面的函数的用法类似于 C 的函数 `malloc(), memcpy(), free()`。

### 内置变量

每个执行 `__global__` 函数的 device 线程都会自动创建 `blockIdx` 对象与 `threadIdx` 对象。其中 `blockIdx` 指明了当前线程所在的块号，`threadIdx` 指明了当前线程在块内的编号。

> [!note] CUDA 层次划分 (Hierarchicy)
> 这里涉及到了 CUDA 的层次设计。在 CUDA 中，将线程划分为了三种层次：
> 1. 线程 (Thread)：执行程序的最小单位，GPU 加速的原理就是大量线程并行执行。一般而言，线程越多，GPU 程序的加速程度越大 (当然，这些线程必须是有作用的)
> 2. 线程块 (Block)：由多个线程组成，一个 block 中的线程可以利用共享内存通信，但是不同线程块之间不能通信。
> 3. 线程格 (Grid)：多个线程块的集合。
>
> 每个核函数在执行时都会自动创建变量 `blockIdx`、`blockDim`、`threadIdx` 和 `gridDim`，其中每个变量都包含三个维度 `x`、`y` 和 `z`。在构造时，可以传入每个维度的大小来构造一个多维的 Block 或 Grid。

在实践中，最常见的一种写法 (也是官方推荐写法) 是利用下面的代码来声明一个线程在全局的唯一编号：
```cpp
int idx = threadIdx.x + blockIdx.x * blockDim.x;
int idy = threadIdx.y + blockIdx.y * blockDim.y;
int idz = threadIdx.z + blockIdx.z * blockDim.z;
```

## 例程

下面是一个向量加法的函数。
```cpp
__global__ void vectorAdd(const float* A, const float* B, float* C, int size){
	int idx = threadIdx.x + blockIdx.x * blockDim.x;
	if(idx < size)
		C[idx] = A[idx] + B[idx];
}

int main()
{
	float *h_A = new float[DSIZE];
	float *h_B = new float[DSIZE];
	float *h_C = new float[DSIZE];
	assignValue(h_A, h_B, h_C);
	float *d_A, *d_B, *d_C;
	// 分配显存
	cudaMelloc(&d_A, DSIZE * sizeof(float));
	cudaMelloc(&d_B, DSIZE * sizeof(float));
	cudaMelloc(&d_C, DSIZE * sizeof(float));
	// 复制数据
	cudaMemcpy(d_A, h_A, DSIZE * sizeof(float), cudaMemcpyHostToDevice);
	cudaMemcpy(d_B, h_B, DSIZE * sizeof(float), cudaMemcpyHostToDevice);
	// 调用函数
	vectorAdd<<<DSIZE/1024, 1024>>>(d_A, d_B, d_C, DSIZE);
	// 复制回内存
	cudaMemcpyp(h_C, d_C, DSIZE * sizeof(float), cudaMemcpyDeviceToHost);
	// 清空显存
	cudaFree(d_A);
	cudaFree(d_B);
	cudaFree(d_C);
}
```

## 额外内容

### 声明多维

内核启动配置支持的前两个参数为 `gridDim` 和 `blockDim`，它们都是 `dim3` 变量，支持最多三个维度。一个二维的示例如下：
```cpp
dim3 block(block_x_dim, block_y_dim);
dim3 grid(floor(DSIZE/block.x), floor(DSIZE/block.y));
mmul<<<grid, block>>>(d_A, d_B, d_C, DSIZE);
// ... in mmul
int idx = threadIdx.x + blockIdx.x * blockDim.x;
int idy = threadIdx.y + blockIdx.y * blockDim.y;
d_A[idx + idy*DSIZE] = ...;
```

## 错误处理

CUDA 在出现错误时不会终止进程，而是通过函数调用返回值返回错误。在官方例程中，使用宏定义来报告错误。
```cpp
#define cudaCheckErrors(msg)                                                   \
    do {                                                                       \
        cudaError_t __err = cudaGetLastError();                                \
        if (__err != cudaSuccess) {                                            \
            fprintf(stderr, "Fatal error: %s (%s at %s:%d)\n", msg,            \
                    cudaGetErrorString(__err), __FILE__, __LINE__);            \
            fprintf(stderr, "*** FAILED - ABORTING\n");                        \
            exit(1);                                                           \
        }                                                                      \
    } while (0)

```
