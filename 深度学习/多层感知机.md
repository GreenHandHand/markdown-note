---
tags:
  - 深度学习
---
# 多层感知机

多层[[机器学习/感知机|感知机]]由多层神经元组成，每一层与它的上一层相连，从中接受输入；每一层与它的下一层相连，影响当前层的神经元。

> [!note] 多层感知机是最简单的神经网络，称为前馈神经网络。

## 多层感知机

多层感知机（Multilayer Perceptron, MLP）是一种常见的人工神经网络模型，通常由输入层、若干个隐藏层和输出层组成。在每一层中，都有若干个神经元（或称节点），这些神经元通过加权和和非线性激活函数进行运算，从而对输入信息进行处理和转换。

### 隐藏层

[[深度学习概念与感知机]] 结构简单，能够处理的函数限制较大，因此我们可以在网络中加入一个或者多个隐藏层来突破[[机器学习/线性模型|线性模型]]的限制，使其能够处理根据普遍的函数关系。

一般来说，隐藏层的作用如下：
1.  特征提取：隐藏层可以通过多个神经元对输入数据进行组合和调整，从而提取出更丰富、更复杂的特征信息，帮助模型学到可区分不同类别的特征。
2.  信息抽象：隐藏层可以将原始输入转化为更抽象、更高层次的特征表示，消除冗余信息，保留更为重要的特征。在深度神经网络中，随着层数增加，抽象程度也越来越高，模型能够发现更为复杂的模式。
3.  非线性变换：隐藏层包含非线性激活函数，例如 sigmoid, ReLU 等，使得神经网络可以拟合比较复杂的非线性模型，进而提高模型的表达能力。

### 从线性到非线性

在神经网络中，我们使用 $W$ 与 $b$ 来分别表示节点的权重与偏置，用 $H,O$ 分别表示隐藏层神经元的输入与输出，考虑只有一层隐藏层的神经网络，有：
$$
\begin{align}
H=XW^{(1)}+b^{(1)}\\
O=HW^{(2)}+b^{(2)}
\end{align}
$$
由于每一层直接都是线性加权求和的关系，为了使神经网络可以适应非线性的数据，我们在神经网络中引入非线性的激活函数 (activation function) $\sigma$，于是上式变为：
$$
\begin{align}
H=\sigma(XW^{(1)}+b^{(1)})\\
O=HW^{(2)}+b^{(2)}
\end{align}
$$
为了进一步提高神经网络的表示能力，我们可以通过增加隐藏层数量来拓深网络结构。然而，随着隐藏层数量增加，神经网络的计算复杂度也会呈指数级别地增长，因为每一层都是全连接的，需要大量的计算资源和时间。因此，在设计网络结构时需要权衡潜在收益和计算开销，并根据问题的特点进行选择，以取得较好的性能和效率的平衡。

### 通用近似定理

通用近似定理（Universal Approximation Theorem）是指，在一定条件下，具有单隐层（可以由多个神经元组成）的前馈神经网络可以用于任意连续函数的逼近，即在给定误差范围内，总存在一个合适的网络参数，使得神经网络可以逼近任意连续函数。

> [!quote] 通用近似定理 (Universal Approximation Theorem)
> 令 $\varphi(\cdot)$ 是一个非常数、有界、单调递增的连续函数，$\mathcal L_d$ 是一个 $d$ 维的单位超立方体 $[0,1]^d$，$C(\mathcal L_d)$ 是定义在 $\mathcal L_d$ 上的连续函数集合。对于任何一个函数 $f\in C(\mathcal L_d)$，存在一个整数 $m$，和一组实数 $v_i,b_i\in\mathbb R$ 以及实数向量 $w_i\in\mathbb R^d,i=1,\cdots,m$，以至于我们可以定义函数
> $$
F(x)=\sum_{i=1}^m v_i\varphi(w_i^Tx+b_i)
>$$
>作为函数 $f$ 的近似实现，即
>$$
\vert F(x)-f(x)\vert<\epsilon,\ \forall x\in\mathcal L_d
>$$
>其中 $\epsilon > 0$ 是一个很小的正数。

但是这并不意味着单层神经网络是解决问题的最好途径，实际上，使用更深（而不是更广）的神经网络可以更加容易的逼近许多函数。

在前馈神经网络中，实际上每一层的神经元都像是在解决同一级别的任务，它们的输出作为下一层处理更高级别的数据来源。
- 低层的神经元对不同的小特征进行检测
- 高层的神经元对底层神经元所抽取出来的不同小特征，去检测一个范围更大的特征

深层神经网络的好处是把复杂的问题变得简单。低层的数据元的输出信息可以被高层不同的神经元重复使用，因此大大降低了任务的复杂度。

> [!faq]- 网络越深越好吗?
> 拥有更多神经元的神经网络可以表达更加复杂的函数，但是在实际训练多层感知机时，网络层数通常不会超过 5 层。
> - 深层神经网络在训练时容易出现梯度消失或梯度爆炸的情况，使训练变得困难。
> - 深度较深的网络容易出现过拟合现象。
> - 随着网络层数的不断增加，还会出现网络退化的情况。

> [!note]- 网络退化
> 在增加神经网络层数的过程中，训练准确率会逐渐趋于饱和。如果继续增加层数，训练准确率反而会下降。这个现象称为网络退化，且它不同于过拟合。网络退化的主要原因在于多层网络难以学习恒等映射。
> 具体来说，多层感知机由多个[[线性代数/线性方程组|线性方程组]]和非线性激活函数的复合函数组成。在深层网络中，容易出现 [[矩阵分析/矩阵范数#矩的条件数|矩阵的条件数]] 较大的情况，即病态方程。病态方程对噪声扰动非常敏感，这会影响网络的稳定性和性能，导致网络难以正确地学习恒等变换，从而出现网络退化现象。

## 激活函数

激活函数通过计算加权和并加上偏置来确定神经元是否应该被激活，它们将输入信号转换为输出的可微计算，大多数是非线性的。

> [!note] 激活函数
> 激活函数在神经元中非常重要，为了增强网络的表示能力和学习能力，激活函数需要具备以下几点性质：
> 1. 连续并可导（允许少数点上不可导）的非线性函数
> 2. 激活函数及其导数要尽可能简单
> 3. 激活函数的导函数的值域要在一个合适的区间内

下面介绍常用的激活函数：

### Sigmoid 函数

Sigmoid 函数常称为挤压函数，它将输入变换为 $(0,1)$ 上的输出，作为传统的模拟神经元的激活，而又保持了可微可导性的函数。其定义为：
$$
\mathrm{Sigmoid}(x)=\frac{1}{1+e^{-x}}
$$
它的导数为：
$$
\frac{\mathrm d}{\mathrm dx}\mathrm{Sigmoid}(x)=\mathrm{Sigmoid(x)}(1-\mathrm{Sigmoid(x)})
$$

### Tanh 函数

与 Sigmoid 函数相同，tanh 将输入压缩到 $(-1,1)$ 范围中，其定义如下：
$$
\tanh(x)=\frac{1-e^{-2x}}{1+e^{-2x}}=\frac{e^x-e^{-x}}{e^x+e^{-x}}
$$
在输入接近 0 时，输出接近线性变换，不同于 Sigmoid 函数，tanh 函数关于原点对称，因而减少了输出偏移的问题。它的导数为：
$$
\frac{\mathrm d}{\mathrm dx}\tanh(x)=1-\tanh^2(x)
$$

> [!note] Tanh 与 Sigmoid
> - Tanh 函数是 0 中心化的，而 Sigmoid 的输出恒大于 0
> - Tanh 函数是 Sigmoid 向下平移和伸缩后的结果，均值更加接近 0，在训练时如果使用 tanh 函数代替 Sigmoid 函数中心化数据，使得数据的平均值更加接近 0，这会使下一层学习简单一点

> [!note] 非零中心化的输出会使得其后一层的神经元的输入发生偏置偏移 (bias shift)，并进一步使得梯度下降的收敛速度变慢

### ReLU 函数

修正线性单元 (rectified linear unit, ReLU) 是最受欢迎的激活函数，因为它实现简单，且表现良好。ReLU 函数被定义为输入元素与 0 之间的最大值：
$$
\mathrm{ReLU}(x)=\max(x, 0)
$$
当输入为负时，导数为 0，当输入为正数时，导数为 1。相比于传统的 sigmoid 和 tanh 激活函数，ReLU 函数具有如下优点：

1.  稀疏性：ReLU函数在输入为负时取值为0，因此能够实现神经网络中的稀疏性，即只有少量的神经元被激活。这对于模型的训练和泛化性能都有好处。
2.  计算速度快：与sigmoid和tanh等需要进行指数运算的激活函数不同，ReLU函数只需要进行简单的比较运算和取最大值操作，计算速度更快。
3.  防止梯度消失问题：当输入为正时，ReLU 函数导数恒为1；而当输入为负时，ReLU 函数导数为0，不存在梯度消失的问题。

> [!note] ReLU 具备生物学的合理性，并且计算上更加高效

但是 ReLU 也会导致**神经元死亡**的问题，即无论输入时什么，ReLU 的导数都为 0，导致该神经元及其后来的神经元的参数不再被更新。为了解决 ReLU 的不足，提出了参数化 ReLU (pReLU)，Leak ReLU 等方法。

pReLU 在 ReLU 后添加一个线性项，定义为：
$$
\mathrm{pReLU}(x)=\max(0, x) + \alpha\min(0, x)
$$
Leak ReLU 在输入为负时将导数置为一个常数，定义为：
$$
\mathrm{LeakReLU(x)}=\begin{cases}x&x>0\\x/a&x\leqslant0\end{cases}
$$

> [!tip] 
> 在不同的神经网络层中，激活函数可以不同
> - 实验结果表明，在隐藏层上使用 tanh 激活函数，总体上优于 Sigmoid 函数
> - ReLU 激活函数是最常用的默认函数，如果不确定用哪个激活函数，就使用 ReLU 或者 Leaky ReLU


## 模型选择、过拟合与欠拟合

机器学习的目标是发现模式（pattern），但是我们需要确定模型是否真正发现了一种泛化模式，而不是简单的记住了数据。

在机器学习中，当模型在训练数据上表现得比在真实分布中表现更好时，我们称之为**过拟合 (overfitting)**。也就是说，模型已经“记住”了训练数据，而没有能够泛化到新的数据。这种情况下，模型可能会忽略真正的模式并把噪音或者随机性当做模式，最终导致在测试数据上表现糟糕。

针对过拟合的技术称为正则化，其目的是在同时考虑模拟训练数据和提高模型泛化能力之间达到平衡。

### 训练误差与泛化误差

**训练误差 (training error)** 指模型在训练集上得到的误差。**泛化误差 (generalization)** 指模型应用在原始样本的分布中抽取的无穷多数据样本时，模型误差的期望。我们无法获得准确的泛化误差，但是我们可以通过将模型应用与一个独立的测试集来估计泛化误差。该测试集应当是随机抽取，由未曾在训练集中出现的样本组成。

在统计学习理论中，由大数定律 (同名定理，eponymous theorem) 给出了训练误差收敛到泛化误差的速率。在应用中，我们通常假设抽取的样本符合独立同分布性质，这在现实中往往不满足。有时候我们轻微的违背独立同分布假设，也可以在模型中得到较好的效果。

### 模型复杂性

一个模型的复杂性由许多的因素决定，以下是几个具有代表性的：
1. 可调整参数的数量
2. 参数的取值范围
3. 训练的样本数量

一般统计学家认为，一个可以轻易解释任意事实的模型是复杂的。回看前馈神经网络，根据通用近似定义，我们知道两层神经网络就可以拟合任意连续函数。因此神经网络可以建模的函数空间很大。

根据这个特点，我们可以将数据的表示学习部分也通过神经网络进行学习。

### 模型选择

在机器学习中，我们通过在评估几个候选模型后选择最终的模型。在深度学习中，我们需要比较不同的超参数对模型的影响，从而确定最佳模型。

**验证集 (validation set)** 用于评估选择模型的效果，不同于测试集，验证集在模型训练中起到了辅助调参的作用，不使用测试集来调参以避免出现过拟合的现象。

一种常用的验证方法是 K 折[[实践知识/交叉验证|交叉验证]]，用于数据稀缺时，难以获得足够的数据用于构成一个合适的验证集。我们将原始训练数据分为 $K$ 个不重叠的子集，然后执行 $K$ 次模型训练和验证，每次在 $K-1$ 个子集上进行训练，并使用剩下的一个用于验证，最后通过对 K 次实验的结果取平均值来估计训练误差和验证误差。

### 欠拟合与过拟合

在比较训练误差与验证误差时，有两种常见的情况。一种是训练误差与测试误差都很大，但是它们之间的差距很小，如果模型不能减小训练误差，则说明模型的表达能力不足，无法捕获试图学习的模式，我们有理由认为需要使用一个更加复杂的模型减小训练误差。这种现象称为欠拟合 (underfitting)。另一种是训练误差明显小于验证误差，这时候一般说明模型严重过拟合，但是这在深度学习中并不总是坏事。实际上，我们更加关注验证误差本身而不是其与训练误差之间的差别。

## 权重衰减

权重衰减是一种正则化技术，用于解决模型过拟合的问题。它也被称为 $L_2$ ​正则化，通过惩罚参数的平方和来限制模型的复杂度。

考虑下面的场景，我们想要获得可以描述目标的最简单的函数，因此我们需要一个可以度量函数与 $f=0$ 之间距离的方法，因为在所有函数中，$f=0$ 在某种意义上最简单。我们可以通过优化函数与 $f=0$ 之间距离的度量来获得更加简单的参数。然而，如何精确地测量函数与 $f=0$ 之间的距离仍然是一个困难的问题，目前还没有确切的答案。

一种简单的方法是使用线性函数 $f(x)=w^Tx$ 中权重向量的某个范数 (如 $\lVert w\rVert_2$) 来度量其复杂度。最常用的方法是将其添加到损失函数中，将原来的最小化训练标签上的预测损失调整为最小化预测损失和惩罚项之和。于是损失函数由下式给出：
$$
L(w,b)+\frac{\lambda}{2}\lVert w\rVert^2
$$
其中 $\lambda$ 是正则化权衡，通过验证集来调整。使用范数的平方可以简便计算，其中范数可以使用 $L_1$ 范数、$L_2$ 范数等。$L_1$ 范数惩罚会导致模型的权重集中在一小部分特征上，因而可以进行模型选择。而 $L_2$ 范数惩罚更加倾向于在大量特征上均匀分布权重，使模型在单个变量中的观测误差更加稳定。

在 pytorch 中，我们可以通过使用优化器中的 `weight_decay` 来传入正则化权衡超参数来使用 $L_2$ 正则化（权重衰减）。

## 暂退法

一个好的预测模型，应当是能够在位置的数据集上表现良好。经典泛化理论认为，为了缩小训练性能和测试性能之间的差距，应当以简单的模型为目标。简单性的另一种角度是平滑性，即模型不应该对微小的变化敏感，实际上，要求函数平滑与要求函数对输入的随机噪声具有适应性间存在着联系。

暂退法 (drop out) 指在计算后续层之前在网络中的每一层中注入噪声。在表面上看是在训练过程中丢弃一些神经元，在整个训练过程中，标准暂退法包括在计算下一层之前将当前层的一些节点置零。

一种注入噪声的方法是以无偏的方式注入噪声，使每一层的期望不变。例如，在模型中，在每个节点的输入加上一个均值为 0 的高斯噪声，从而产生扰动，这样做数据的期望仍然保持不变。

标准暂退法正则化中，通过丢弃节点，并将剩余的节点规范化来消除每一层的偏差。换句话说，每个中间激活值 $h$ 以概率 $p$ 被随机变量 $h'$ 替换，如下所示：
$$
h'=\begin{cases}0,&概率为p\\\dfrac{h}{1-p},&其他情况\end{cases}
$$
这样做得到的期望 $E(h')=h$。

通常，我们在测试中不使用暂退法，只在训练中使用，因为使用暂退法的目的是增强网络的稳健性，而不受一些噪声的干扰。

在 pytorch 中，我们通过在网络中添加暂退层 `nn.Dropout(p)` 来使用暂退法，在训练模型时，使用 `torch.train(True)` 可以启用暂退层，在测试时，使用 `torch.train(False)` 来禁用暂退层，此时暂退层仅起到了传递数据的功能。`F.dropout(p)` 同样可以使用暂退方法，但是不受 `torch.train` 的影响，但是可以使用参数 `training=True` 来使其获得同样的功能。

## 计算图

在 pytorch 的梯度计算中，分为前项传播和反向传播两个步骤。而自动微分则是通过这两个步骤，使用计算图计算得到。

前向传播（forward propagation 或 forward pass）指按顺序计算与储存每一步的结果。在进行前向传播的同时，还会同时绘制一个计算图，在计算图中，节点表示计算的结果，边表示计算函数。

反向传播 (backward propagation 或 backpropagation) 指计算神经网络的梯度。由于求导的链式法则，所以可以通过计算图从结果反向计算所有数值的导数，自动微分得以实现。

在计算导数时，我们需要保存计算图上的所有中间值，这就是训练神经网络比预测需要更多的内存的原因。

## 数值稳定与模型初始化

模型的初始参数的选择对模型的训练过程有着重要的影响，选择什么激活函数与什么初始化参数决定了模型收敛的速度，糟糕的选择可能会导致我们在训练的过程中遇到梯度爆炸或者梯度消失的问题。

### 梯度爆炸与梯度消失

在计算梯度时，深层的网络往往会出现多个导数相乘的局面，最终得到的梯度可能发生上溢或者下溢的现象。当我们将过多的概率相乘时，这样的问题经常出现。不稳定的梯度带来的风险不仅在于数值表示，也威胁到了算法的稳定性。**梯度爆炸 (gradient exploding)** 指多个较大的梯度相乘，导致最终的梯度非常大，使用这个梯度进行更新参数，会使参数更新过多，破环模型的平衡性。**梯度消失 (gradient vanishing)** 指多个小的梯度相乘，导致最终的梯度趋于 0，参数基本不会变化，导致模型无法学习。

还有一种问题，考虑一个隐藏层，两个神经单元，当我们将它们都初始化为一个相同的常数时，它们接受相同的输入，使用相同的激活函数，获得相同的输出，它们的梯度也相同，使用基于梯度的迭代后它们仍然是相同的值，这样的对称性永远也不会被打破。这个隐藏层的行为就和一个神经单元相同。使用梯度下降无法起到作用，使用暂退法正则化则可以打破这种对称性。

### 参数初始化

解决上面的几个问题是进行参数初始化，在训练过程中适当的进行正则化也可以进一步提高稳定性。

一般而言，对于不太复杂的问题，使用默认的参数初始化足以，即只用正态分布来初始化权重，这种方法通常是有效的。下面介绍一种 Xavier 初始化方法：

考虑没有非线性的全连接层的输出 $o_i$ 的分布，设输入层 $n_{in}$ 的输入为 $x_j$，对应的权重为 $w_{ij}$，于是输出可以有下面的式子表示：
$$
o_i=\sum_{j=1}^{n_{in}}w_{ij}x_j
$$
权重 $w_{ij}$ 都是从同一分布中抽样获得的，我们的目标就是找到这个分布。假设该分布具有期望 0，方差 $\sigma^2$，输入数据 $x_j$ 也来自期望 0 方差 $\gamma^2$ 的分布，并且 $w_{ij}$ 与 $x_j$ 彼此独立，于是有
$$
E(o_j)=\sum_{j=1}^{n_{in}}E(w_{ij}x_j)=\sum_{j=1}^{n_{in}}E(w_{ij})E(x_j)=0
$$
$$
\mathrm{Var}(o_j)=E(o_j^2)-E^2(o_j)=\sum_{j=1}^{n_{in}}E(w_{ij}^2)E(x_j^2)-0=n_{in}\sigma^2\gamma^2
$$
现在考虑反向传播过程反向的神经单元误差为 $\delta_j$，设输出层为 $n_{out}$，反向传播中最后一层的输出满足期望为 0，方差为 $\gamma^2$ 为分布，对应的权重为 $w_{ij}$ ，于是有
$$
E(\delta_{j})=\sum_{j=1}^{n_{out}}E(\frac{\partial L}{\partial w_{ij}}\frac{1}{x_j})=\sum_{j=1}^{n_{out}}E(\frac{\partial L}{\partial w_{ij}})E(\frac{1}{x_j})=0
$$
$$
\mathrm{Var}(\delta_j)=E(\delta_j^2)-E^2(\delta_j)=\sum_{j=1}^{n_{out}}E\left((\frac{\partial L}{\partial w_{ij}})^2\right)E(\frac{1}{x_j^2})-0=n_{out}\sigma^2\frac{1}{\gamma^2}
$$
为了使输出与导数的方差最小，我们需要使 $n_{out}\sigma^2=1$，$n_{in}\sigma^2=1$，否则输出或者梯度的方差可能会增大。一般情况下，输入层与输出层节点的数量不会相等，作为一种权衡，使用下面的等式：
$$
\frac{1}{2}(n_{in}+n_{out})\sigma^2=1\Leftrightarrow\sigma=\sqrt{\frac{2}{n_{in}+n_{out}}}
$$
满足上面的等式的方式有很多，常用的是使用高斯分布 $N(0,2/(n_{in}+n_{out}))$ 或者均匀分布：
$$
U(-\sqrt{\frac{6}{n_{in}+n_{out}}}，\sqrt{\frac{6}{n_{in}+n_{out}}})
$$
虽然在上面的数学推导中，假设了不存在非线性变量，但是这样的初始化方法在实践中被证明是有效的。在 pytorch 中，使用 `nn.init.xavier_normal_(parameters)` 来对参数使用 xavier 正态分布初始化，使用 `nn.init.xavier_uniform_(parameters)` 来对参数使用 xavier 均匀分布初始化。

参数初始化一种是深度学习基础研究中的热门领域，要深入研究需要阅读最新的论文。

## 环境与分布偏移

分布偏移现象是指在数据分布不均匀的情况下，模型在训练集上表现良好，但在测试集上表现不佳的现象。这是因为模型在训练过程中过度关注了训练集中的某些特征或样本，而忽略了其他特征或样本，导致在测试集上表现不佳。分布偏移现象常见于数据分布在时间、地点、人群等方面存在差异的情况下。这与数据的收集有着密切的关系。

而在模型的使用过程中环境可能是变化的，同一个模型在不同的时间效果可能大相径庭。

### 分布偏移

如果数据分布可以任意偏移，那么训练一个分类器几乎是不可能的，因为训练数据与测试环境可能完全不同。但是，如果满足一定的限制性假设，一些算法可以检测这种偏移并进行动态调整，以提高分类器的准确性。下面介绍了几种常见的分布偏移现象：

#### 协变量偏移

**协变量偏移 (covariate shift)** 指的是输入变量的分布与测试变量的分布不同导致的模型性能下降。简单来说，就是训练数据与测试数据的分布不一致导致的模型性能下降。例如，我们使用一个地区的数据进行训练，然后再另一个地区测试模型，就可能导致协变量偏移；再或者我们使用猫和狗的照片训练了一个猫狗分类器，但是在猫和狗的卡通图片集上进行测试。如果在一个与测试集的特征有本质区别的数据集上进行训练，如果没有方法来使用新的领域，可能会有很大的麻烦。

#### 标签偏移

**标签偏移 (label shift)** 则是与协变量偏移完全相反的问题。标签偏移指训练标签与测试标签的分布不同导致的模型性能下降。简单来说，就是模型在训练时学习了一种标签分布，但在测试时面对的数据却有不同的标签分布，从而影响了模型的预测准确性。在某些情况下，标签偏移与协变量偏移可能会同时存在。

#### 概念偏移

**概念偏移 (concept shift)** 现象是指标签的定义发生了变化，常出现在精神疾病的诊断、时髦和工作头衔等领域中。此外，在不同的地区，对于一个概念的理解也存在差异。例如，建立机器翻译系统时，尽管使用的是同一种语言，但美国和英国的概念有所不同。这种现象往往难以被发现，需要引起足够的注意和警惕。

### 分布偏移纠正

在某些情况下，无论分布如何偏移，模型都能正常工作，但是在另一些情况下，我们可以通过运用策略来应对这些偏移。

#### 经验风险与实际风险

在统计学中，我们将训练中使用的损失叫做经验风险 (empirical risk)
$$
\min_f\frac{1}{n}\sum_{i=1}^nl(f(x_i), y_i)
$$
经验风险是根据历史数据和模型预测出的风险，我们使用经验风险是为了近似估计实际风险 (true risk)，即从真实分布 $p(x,y)$ 上抽样所有数据的总体损失期望
$$
E_{p(x,y)}\big[\,l\big(f(x),y\big)\,\big]=\iint l\big(f(x),y\big)p(x,y)\mathrm dx\mathrm dy
$$
然而在实践中我们无法获得总体数据，因此通过最小化经验风险来近似最小化真实风险。

#### 协变量偏移纠正

假设对于带有标签的数据 $(x_i,y_i)$，我们要评估其标签的分布 $P(y\,|\,x)$。但是我们获得的观测值来自另一个分布 $q(x)$，而不是目标分布 $p(x)$。根据依赖性假设，我们获得的 $y$ 的分布是保持不变的，即 $p(y\,|\,x)=q(y\,|\,x)$，所有可以使用下面的方法进行修正
$$
\iint l(f(x),y)p(y|x)p(x)\mathrm dx\mathrm dy=\iint l(f(x),y)q(y|x)q(x)\frac{p(x)}{q(x)}\mathrm dx\mathrm dy
$$
换句话说，我们只需要根据数据来自正确分布与来自错误分布的概率之比就可以纠正协变量偏移，即使用加权经验风险最小化来训练模型：
$$
\min_f\frac{1}{n}\sum_{i=1}^{n}\beta_il(f(x_i),y_i),\quad\beta_i=\frac{p(x_i)}{q(x_i)}
$$
由于不知道 $\beta_i$ 的值，因此我们需要估计它。数学上有很多的方法可以估计这个值，包括一些使用最小范数或者最大熵原理的方法。对于这些方法，都需要来自两个分布的样本：真实的分布 $p$，通过访问测试数据获得，训练集样本 $q$，可以使用人工合成的方式获得。

这里介绍使用 [[线性模型#对数几率回归|逻辑斯蒂回归]] 的方式来估计 $\beta_i$ 的值。我们分布从两个分布中获取等量的样本并使用 $z$ 表示类别，设从 $p$ 中抽取的样本标签为 $1$，从 $q$ 中抽取的样本标签为 $0$，那么
$$
P(z=1|x)=\frac{p(x)}{p(x)+q(x)}\Rightarrow \frac{P(z=1|x)}{P(z=0|x)}=\frac{p(x)}{q(x)}
$$
根据逻辑斯蒂回归预测的结果，有
$$
\beta_i=\frac{P(z=1|x)}{P(z=-1|x)}=e^{w^Tx_i+b}
$$
于是对于一个训练集 $\{(x_1,y_1),\cdots,(x_n,y_n)\}$ 与未加标注的测试集 $\{u_1,\cdots,u_m\}$ ，一个完整的协变量纠正算法可以描述为：
1. 生成一个二元分类器训练集：$\{(x_1,0),\cdots,(x_n,0),(u_1,1),\cdots,(u_m,1)\}$
2. 使用逻辑斯蒂回归得到分类器的参数 $w^Tx+b$
3. 使用 $\beta_i=\exp(w^Tx_i+b)$ 或更好的 $\beta_i=\min(\exp(w^Tx_i+b),c)$ 对训练集进行加权
4. 最小化加权经验风险来对训练集进行训练

上述算法有一个重要的假设，即目标分布中的每个数据样本在训练时出现的概率为非零，因为当我们找到 $p(x)>0 \And q(x)=0$ 的点时，相应的重要性权重将会是无穷大。

#### 标签偏移纠正

使用与协变量偏移纠正中相同的符号，假设标签的分布随时间变化，即 $q(y)\ne p(y)$，但是类别条件分布保持不变，即 $q(x|y)=p(x|y)$，我们可以一个类似的结果：
$$
\iint l\left(f\left(x\right),y\right)p(x\mid y)p(y)\mathrm dx\mathrm dy=\iint l(f(x),y)q(x\mid y)q(y)\frac{p(y)}{q(y)}\mathrm dx\mathrm dy
$$
重新定义 $\beta_i$ 有
$$
\beta_i=\frac{p(y_i)}{q(y_i)}
$$
计算上面的式子可以通过 [[实践知识/评价指标#混淆矩阵|混淆矩阵]] 计算，我们使用 $\mu(\hat y_i)$，其中 $\hat y_i$ 表示模型预测第 $i$ 个类别时的平均准确率，当我们的分类器一开始就足够准确时，我们可以通过求解一个简单的线性系统来获得目标分布：
$$
Cp(y)=\mu(\hat y)
$$
对于 $q(y)$，我们可以通过观测源数据上的标签获得，然后通过最小化加权经验风险函数来进行训练。

#### 概念偏移纠正

概念偏移很难使用原则性的方法进行纠正，但是幸运的是概念偏移一般都是一个缓慢进行的过程，因此我们可以使用训练神经网络的方法，使其适应数据的变化，换言之，我们不再重新训练网络，而是使用新的数据来更新网络的权重。