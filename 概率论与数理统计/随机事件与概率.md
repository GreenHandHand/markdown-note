---
tags:
  - 概率论
  - 概率论与数理统计
---

# 随机事件与概率

## 概率的定义

### 随机试验

> [!definition|Definition] 随机试验
> 如果一个试验满足以下三个条件：
> 1. 试验可以在相同的条件下重复进行
> 2. 试验所有可能结果明确可知，且不止一个
> 3. 每一次试验会出现哪一个结果，事先不能确定
>
> 则称此试验为**随机试验**，简称为**试验**，用字母 $E$ 或者 $E_{1},E_{2}\cdots$ 表示。

> [!note]
> 试验是数学上的抽象，在现实生活中，很多的试验的结果不是明确可知的，但是我们可以推测其大概的范围，这类试验同样是随机试验。

> [!definition|Definition] 随机事件
> 在一次实验中可能出现，也可能不出现的结果称为**随机事件**，简称**事件**，并用大写字母 $A,B,C$ 等表示。
>
> 每一次试验中必然发生的事件称为**必然事件**，记为 $\varOmega$。每次试验中一定不发生的事件称为**不可能事件**，记为 $\varnothing$。

> [!note]
> 随机事件在一次试验中是否发生虽然不能事先确定，但是在大量重复试验的情况下，它的发生呈现一定的规律性，这门数学就是研究这种规律性。

> [!definition|Definition] 样本空间
> 随机试验的每一个可能的结果称为**样本点**，记为 $\omega$。样本点全体组成的集合称为**样本空间**，记为 $\varOmega$，即 $\varOmega=\{ \omega \}$。由一个样本点构成的事件称为**基本事件**。随机事件 $A$ 总是由若干个基本事件组成，即 $A$ 是 $\varOmega$ 的子集。

### 事件的关系与运算

在前面的定义中，我们将事件定义为集合的形式，因此事件之间的关系也和集合间的关系相同：
- 包含：如果事件 $A$ 发生必然导致事件 $B$ 发生，则称事件 $B$ 包含事件 $A$，记为 $A\subset B$。
- 相等：如果 $A\subset B$ 且 $B\subset A$，则称事件 $A$ 和事件 $B$ 相等，记为 $A=B$。^[也就是说，$A$ 与 $B$ 由一些完全相同的试验结果构成，只不过是同一事件表面上看起来不同的两个说法而已。]
- 积 (交)：称"事件 $A$ 与 $B$ 同时发生"的事件为事件 $A$ 与 $B$ 的积事件 (交事件)，记为 $A\cap B$ 或者 $AB$。
- 相容：若 $AB\neq \varnothing$, 则称事件 $A$ 与 $B$ 相容。
- 互斥：若 $AB=\varnothing$, 则称事件 $A$ 与 $B$ 互不相容，也称互斥。
- 和 (并)：称"事件 $A$ 与 $B$ 至少有一个发生"的事件为事件 $A$ 与 $B$ 的和事件 (并事件)，记为 $A\cup B$。
- 差：称"事件 $A$ 发生事件 $B$ 不发生"的事件为事件 $A$ 与 $B$ 的差事件，记为 $A-B$。
- 逆 (对立)：称"事件 $A$ 不发生"的事件为 $A$ 事件的逆事件 (对立事件)，记为 $\overline{A}$。
- 完备事件组：如果 $\displaystyle\bigcup_{i=1}^{n(\infty)}A_{i}=\varOmega,A_{i}A_{j}=\varnothing$，称有限个 (可列个) 事件 $A_{1},A_{2},\cdots,A_{n(\infty)}$ 构成一个完备事件组。
- 文氏图 (韦恩图)：事件的关系与运算可以使用集合的文氏图形象的表示。

上述定义的事件的运算遵循下面的运算规律：
1. 吸收律：若 $A\subset B$，则 $A\cup B=B,A\cap B=A$
2. 交换律：$A\cup B=B\cup A,A\cap B=B\cap A$
3. 结合律：$(A\cap B)\cap C=A\cap(B\cap C),(A\cup B)\cup C=A\cup(B\cup C)$
4. 分配律：$A\cap(B\cup C)=(A\cap B)\cup(A\cap C)$，$A\cup(B\cap C)=(A\cup B)\cap(A\cup C)$，$A\cup(B-C)=(A\cap B)-(A\cap C)$
5. 德摩根律：$\overline{A\cup B}=\overline{A}\cap \overline{B}$，$\overline{A\cap B}=\overline{A}\cup \overline{B}$

### 概率的定义

> [!definition|描述性定义] 通常将随机事件 $A$ 发生的可能性大小的度量称为事件 $A$ 发生的概率，记为 $P(A)$。

> [!definition|统计性定义] 在相同条件下做重复试验，事件 $A$ 出现的次数 $k$ 和总的试验次数 $n$ 之比 $\dfrac{k}{n}$ 称为事件 $A$ 在这 $n$ 次试验中出现的频率。当试验次数 $n$ 充分大时，频率将稳定与某个常数，$n$ 越大，频率偏离这个常数 $p$ 的可能性越小。这个常数 $p$ 称为事件 $A$ 的概率。

> [!definition|Definition] 公理化定义
> 设随机试验的样本空间为 $\varOmega$，如果对每一个事件 $A$ 都有一个确定的实数 $P(A)$，且事件函数 $P(\cdot)$ 满足
> 1. 非负性：$P(A)\geqslant 0$
> 2. 规范性：$P(\varOmega)=1$
> 3. 可列可加性：对任意可列个两两互不相容事件 $A_{1},A_{2},\cdots,A_{n},\cdots$ 有
>    $$
P\left( \bigcup_{i=1}^\infty A_{i} \right) =\sum_{i=1}^\infty P(A_{i})
>   $$
>
>则称 $P(\cdot)$ 为概率，$P(A)$ 为事件 $A$ 的概率。

> [!note]
> 1. 从概率的统计性定义可以看出，频率只是概率的估计，而非概率本身。统计性定义是无法给出某事件的概率的，但是它给出了估计概率的方法、检验结论正确性的准确。
> 2. 公理化定义界定了概率这个概念所必须满足的一些一般性质，它不解决具体场合下的概率计算，但是它可以用于判断某事件函数 $P(\cdot)$ 是否是概率。

## 古典概型与几何概型

### 古典概型

> [!info] 古典概型
> 即概率论诞生之前就已经存在的概率模型。

> [!definition|Definition] 古典概型
> 如果随机试验的样本空间满足：
> 1. 只有有限个样本点 (基本事件)；
> 2. 每个样本点 (基本事件) 发生的可能性都一样；
>
> 则称随机试验的概率模型为**古典概型**。

在古典概型中，基本事件总数为 $n$，事件 $A$ 包含 $k$ 个基本事件，也叫作有利于 $A$ 的基本事件为 $k$ 个，则 $A$ 的概率为
$$
P(A)=\frac{k}{n}=\frac{\text{事件$A$所含基本事件的个数}}{\text{基本事件总数}}
$$
由上式计算得出的概率称为 $A$ 的古典概率。

```ad-note
title: 计算古典概型
计算的关键是基本事件、样本空间的选定和基本事件数的计算
1. 列举法：基本事件不多时常用这种方法
2. 集合对应法：
	- 加法原理：将 $A$ 分为 $n$ 类，则 $A$ 的完成方法等于每一类的完成方法相加。
	- 乘法原理：将 $A$ 分为 $n$ 个步骤，则 $A$ 的完成方法等于每一步的完成方法相乘。
	- 排列：从 $n$ 个不同元素中取出 $m$ 个元素，并按照一定顺序排列：
	$$
	P_{n}^m=\dfrac{n!}{(n-m)!}
	$$
	- 组合：从 $n$ 个不同元素中取出 $m$ 个元素，组成一组：
	$$
	C_{n}^m=\dfrac{P_{n}^m}{m!}
	$$
3. 逆数法：先求对立事件，然后使用总事件数减去对立事件中的事件数。
```

> [!warning] 使用加法原理和乘法原理解决问题时，需要注意一件事件必须完整做完，才能计算概率。

### 几何概型

> [!definition|Definition] 几何概型
> 如果随机试验的样本空间满足：
> 1. 样本空间 (基本事件空间) $\varOmega$ 是一个可度量的有界区域。
> 2. 每个样本点 (基本事件) 发生的可能性都一样，即样本点落入 $\varOmega$ 的某一个可度量的子区域 $S$ 的可能性大小与 $S$ 的几何度量成正比，而与 $S$ 的位置及形状无关。
>
>则称随机试验的概率模型为**几何概型**。

在几何概型随机试验中，如果 $S_{A}$ 是样本空间 $\varOmega$ 的一个可度量的子区域，则事件 $A=\{ \text{样本点落入区域}S_{A} \}$ 的概率为
$$
P(A)=\dfrac{S_{A}\text{的几何度量}}{\varOmega\text{的几何度量}}
$$
由上式计算得出的概率称为 $A$ 的几何概率。

## 概率的性质与公式

### 性质

1. 有界性：对于任一事件 $A$，由 $0\leqslant P(A)\leqslant 1$，且 $P(\varnothing)=0, P(\varOmega)=1$。
2. 单调性：设 $A,B$ 是两个事件，若 $A\subset B$，则有
	$$
P(B-A)=P(B)-P(A),\ P(B)\geqslant P(A)
	$$

> [!note]
> - 不可能事件的概率一定是 0，但是概率是 0 的事件不一定是不可能事件。
> - 必然事件的概率一定是 1，但是概率为 1 的事件不一定是必然事件。
> - $P(A)=1 \nRightarrow A=\varOmega$
> - $P(A)=0 \nRightarrow A=\varnothing$

### 公式

1. 逆事件概率公式：对于任一事件 $A$，由 $P(\overline{A})=1-P(A)$
2. 加法公式：对于任意两个事件 $A,B$，由 $P(A\cup B)=P(A)+P(B)-P(AB)$

> [!note]
> 1. 设 $A_{1},A_{2},A_{3}$ 为任意三个事件，则有
> 	$$
\begin{aligned}
P(A_{1}\cup A_{2}\cup A_{3})&=P(A_{1})+P(A_{2})+P(A_{3})\\&-P(A_{1}A_{2})-P(A_{1}A_{3})-P(A_{2}A_{3})\\&+P(A_{1}A_{2}A_{3})
\end{aligned}
> 	$$
> 2. 若 $A_{1},A_{2},\cdots,A_{n}$ 是互不相容事件，则
> $$
P(A_{1}\cup A_{2}\cup \cdots\cup A_{n})=P(A_{1})+P(A_{2})+\cdots+P(A_{n})
> $$

3. 减法公式：$P(A-B)=P(A)-P(AB)=P(A\overline{B})$
4. 条件概率公式：设 $A,B$ 为任意两个事件，若 $P(A)>0$，我们称在已知事件 $A$ 发生的条件下，事件 $B$ 发生的概率为条件概率，记为 $P(B\mid A)$，且
	$$
P(B\mid A)=\frac{P(AB)}{P(A)}
	$$
5. 乘法公式：如果 $P(A)>0$，则 $P(AB)=P(A)P(B\mid A)$
6. 全概率公式：如果 $\displaystyle\bigcup_{i=1}^nA_{i}=\varOmega,A_{i}A_{j}=\varnothing,P(A_{i})>0$，则对任一事件 $B$，有
	$$
B=\bigcup_{i=1}^nA_{i}B,\ P(B)=\sum_{i=1}^nP(A_{i})P(B\mid A_{i})
	$$
7. 贝叶斯公式：如果 $\displaystyle\bigcup_{i=1}^nA_{i}=\varOmega,A_{i}A_{j}=\varnothing,P(A_{i})>0$，则对任一事件 $B$，只要 $P(B)>0$，就有
	$$
P(A_{j}\mid B)=\frac{P(A_{j})P(B\mid A_{j})}{\displaystyle\sum_{i=1}^nP(A_{i})P(B\mid A_{i})}
	$$

> [!note]
> 全概率公式是用于计算某个结果 $B$ 发生的可能性大小，如果一个结果 $B$ 的发生总是与多个原因 $A_{i}$ 相联系，那么在计算 $P(B)$ 时，我们一般这样处理：
> $$
B=B\varOmega=B\left( \bigcup_{i=1}^nA_{i} \right) =\bigcup_{i=1}^nA_{i}B
> $$ 
> 然后应用全概率公式计算 $P(B)$，我们通常称这种方法为**全集分解法**。

## 独立重复试验

### 独立事件

> [!definition|独立事件] 设 $A,B$ 为两个事件，如果 $P(AB)=P(A)P(B)$，则称事件 $A$ 与 $B$ 相互独立，简称 $A$ 与 $B$ 独立。

> [!tip] 独立事件的理解
> 如果有 $P(AB)=P(A)P(B)$，则有
> $$
P(B\mid A)=\frac{P(AB)}{P(A)}=P(B)
> $$
> 即事件 $A$ 发生与否不影响事件 $B$ 的发生概率。
> 
> 如果 $P(AB)>P(A)P(B)$，那么 $P(B\mid A)>P(B)$ (或者 $P(A\mid B)>P(A)$)，此时事件 $A$ 的发生有利于事件 $B$ 发生的概率。此时，称这两个事件相互有利。
> 
> 如果 $P(AB)<P(A)P(B)$，那么 $P(B\mid A)<P(B)$，此时事件 $A$ 的发生抑制事件 $B$ 发生的概率。此时，称这两个事件相互抑制。

> [!note] $n$ 个事件独立
> 设 $A_{1},A_{2},\cdots,A_{n}$ 为 $n$ 个事件，如果对其中任意有限个事件 $A_{i_{1}},A_{i_{2}},\cdots,A_{i_{k}}$，都有
> $$
P(A_{i_{1}}A_{i_{2}}\cdots A_{i_{k}})=P(A_{i_{1}})P(A_{i_{2}})\cdots P(A_{i_{k}})
> $$
> 那么称 $n$ 个事件 $A_{1},A_{2},\cdots,A_{n}$ 相互独立。
> 
> 即 $A_{1},A_{2},A_{3}$ 独立 $\implies A_{1},A_{2},A_{3}$ 两两独立，但是两两独立需要有条件 $P(A_{1}A_{2}A_{3})=P(A_{1})P(A_{2})P(A_{3})$ 才能退出 $A_{1},A_{2},A_{3}$ 独立。

独立性的判定：
1. $A$ 与 $B$ 相互独立 $\iff$ $A$ 与 $\overline{B}$ 相互独立 $\iff \overline{A}$ 与 $B$ 相互独立 $\iff \overline{A}$ 与 $\overline{B}$ 相互独立。
2. 对独立事件组不含相同事件作运算，得到的新事件组仍独立，如 $A,B,C,D$ 相互独立，则 $AB$ 与 $CD$ 独立，$A$ 与 $BC-D$ 独立。
3. 若 $P(A)=0$ 或 $P(A)=1$，则 $A$ 与任意事件 $B$ 相互独立。

> [!note]
> 1. 将相互独立的事件组中的任意几个事件替换为各自的对立事件，得到的新事件组仍相互独立。
> 2. 不可能事件和必然事件和任何事件独立。

### 独立试验序列

在同样条件下独立重复地进行一系列完全相同的试验，即每次试验的可能结果及其发生的概率都不变，每次试验是相互独立的，称这种重复试验序列为**独立试验序列概型**。

如果每次试验都只有两个结果 $A$ 和 $\overline{A}$，且在每次试验中 $A$ 发生的概率都相等 (即 $P(A)=p$)，将这种试验重复 $n$ 次，则称这种试验的概率模型为 **$n$ 重伯努利概型**。

> [!note]
> 如果用 $X$ 表示 $n$ 重伯努利概型中事件 $A$ 的发生次数，则 $X$ 服从二项分布 $B(n,p)$。
> 
