---
aliases:
  - 统计机器学习
  - statistical machine learning
  - statistical learning
  - machine learning
tags:
  - 机器学习
  - 概述
---

# 机器学习概述

统计机器学习 (statistical machine learning)，或者统计学习 (statistical learning)，是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。

>[!tip|center] 机器学习 ≈ 构建一个映射函数

## 机器学习分类

机器学习一般包括监督学习，无监督学习，强化学习，有时还包括半监督学习，主动学习。

### 监督学习

监督学习 (supervised learning) 是指从标注数据中学习预测模型的机器学习问题。标注数据表示输出与输入的对应关系，预测模型给定输入产生相应的输出。监督学习的本质是学习输入到输出的映射的统计规律。

在监督学习中，将所有输入与输出可能的取值的集合分别称为输入空间 (input space) 与输出空间 (output space)。每个具体的输入时一个实例 (instance)，通常由特征向量 (feature vector) 表示。这时，所有特征向量存在的空间称为特征空间 (feature space)。特征空间的每一维对应这一个特征，模型实际上都是定义在特征空间的。

在监督学习中，将输入与输出看作定义在特征空间与输出空间上的 [[00-笔记/概率论与数理统计/一维随机变量及其分布|随机变量]]，输入变量与输出变量用大写字母 $X,Y$ 表示。输入变量与输出变量的取值用小写字母 $x,y$ 表示。变量可以是标量，也可以是向量，都使用同类字母表示。除非特别声明，否则向量都是列向量。例如，输入实例 $x$ 的特征向量记为：
$$
x=\big(x^{(1)},x^{(2)},\cdots,x^{(i)},\cdots,x^{(n)}\big)^T
$$
其中 $x^{(i)}$ 表示 $x$ 的第 $i$ 个特征。与 $x_i$ 不同，$x_i$ 表示多个输入变量中第 $i$ 个变量。即：
$$
x_i=\big(x_i^{(1)},x_i^{(2)},\cdots,x_i^{(i)},\cdots,x_i^{(n)}\big)^T
$$
监督学习从训练数据 (training data) 集中学习模型，对测试数据 (test data) 进行预测。训练数据由特征向量与输出对组成，训练集通常表示为：
$$
T=\{(x_1,y_1),(x_2,y_2),\cdots, (x_N,y_N)\}
$$
测试数据也由同样的方式组成。输入与输出对又称为样本 (sample)。根据输入变量与输出变量的不同类型，将监督学习分为了以下几类：
- 回归问题：输入与输出变量均为连续变量
- 分类问题：输出变量为有限个离散变量
- 标注问题：输入变量与输出变量均为变量序列

监督学习假设输入变量与输出变量遵循 [[00-笔记/概率论与数理统计/多维随机变量及其分布|联合概率分布]] $P(X,Y)$。而数据被看作是以联合概率分布 $P(X,Y)$ 独立同分布产生，统计学习假设数据一定存在统计规律，目标就是学习这个规律。

监督学习的目的在与学习一个由输入到输出的映射，这一映射由模型来表示，学习的目的就是找到最好的这种模型。模型属于输入空间到输出空间的映射的集合，这个集合称为假设空间 (hypothesis space)。监督学习的模型可以是概率模型，也可以是非概率模型，分别使用条件概率分布 $P(Y|X)$ 和决策函数 (decision function) $Y=f(X)$ 表示，对具体的输入进行相应的输出预测，写作 $P(y|x)$ 或 $y=f(x)$。

>[!note]- 机器学习与深度学习的关系
>当我们用机器学习来解决一些模型识别任务，一般的流程包含：
> ```mermaid
> graph LR
> 原始数据-->数据预处理-->特征提取-->特征转换-->预测-->结果
> ```
>其中**数据预处理**、**特征提取**、**特征转换**部分称为特征工程，**预测**称为浅层学习（主要靠人工经验和特征转换方法来抽取）。机器学习方法得到的结果的好坏很大程度上取决于特征工程。
>在深度学习的视角下，这些方法的本质都是用一定的输入输出数据训练一个神经网络，在用这个神经网络读取新的输入并生成输出。

### 无监督学习

无监督学习 (unsupersived learning) 是指从无标注数据中学习预测模型的机器学习问题。无标注数据时自然得到的数据，预测模型表示数据的类别，转换或者概率。无监督学习的本质是学习数据中的统计规律或者潜在结构。一类典型的无监督学习为 [[00-笔记/机器学习/聚类]]。

模型的输入与输出的所有可能取值的集合分别称为输入空间和输出空间。每个输入时一个实例，有特征向量表示。每个输出是对输入的分析结果，有输入的类别、转换或者概率表示。模型可以是实现对数据的 [[00-笔记/机器学习/聚类|聚类]]、降维或者概率估计。

假设 $\mathcal X$ 是输入空间，$\mathcal Z$ 是隐式结构空间，要学习的模型表示为函数 $z=g(x)$ 或者条件概率分布 $P(z|x)$ 或者 $P(x|z)$ 的形式，其中 $x\in\mathcal X$ 是输入，$z\in\mathcal Z$ 是输出，包含所有可能的模型的集合称为假设空间，无监督学习旨在从假设空间中选出在给定评价标准下最优的模型。

无监督模型通过使用大量的无标注数据学习或训练，每个样本都是一个实例，训练数据表述为 $U=\{x_1,x_2,\cdots,x_N\}$。无监督模型从训练集中学习，得到一个最优模型，再对测试数据进行预测。

### 强化学习

强化学习 (reinforcement learning) 指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题。假设智能系统与环境的互动基于 [[00-笔记/强化学习/马尔科夫决策过程]] (Markov decision process)，智能系统能观测到的是与环境互动得到的数据序列，强化学习的本质是学习最优的序贯决策。

强化学习方法有基于策略的 (policy-based)、基于价值的 (value-based)，这两种属于无模型的 (model-free) 方法，还有有模型的 (model-based) 的方法。

### 半监督学习与主动学习

半监督学习 (semi-supervised learning) 指利用标注数据和未标注数据学习预测模型的机器学习问题。因为人工标注数据成本较高，半监督学习旨在利用未标注数据中的信息，辅助标注数据，进行监督学习，以较低成本达到较好的学习效果。

主动学习 (active learning) 指机器不断主动给出实例让教师进行标注，然后利用标注数据学习预测模型的机器学习问题。通常监督学习被认为是被动学习，主动学习的目标是找出对学习最有帮助的实例让教师标注，以较小的代价达到较好的学习效果。

半监督学习与主动学习更加接近监督学习。

## 其他分类方法

机器学习中可以按照其他方法对模型进行分类。

### 概率模型与非概率模型

在机器学习中，模型可以分为概率模型 (probabilistic model) 与非概率模型 (non-probabilistic model) 或者确定性模型 (deterministic model)。在监督学习中，概率模型取条件概率分布形式 $P(y|x)$，非概率模型取函数形式 $y=f(x)$；在无监督学习中，概率模型取条件概率分布形式 $P(z|x)$ 或者 $P(x|z)$，非概率模型取函数形式 $z=g(x)$。

常见的概率模型包括：[[00-笔记/机器学习/决策树]]、[[00-笔记/机器学习/朴素贝叶斯]]、[[00-笔记/机器学习/隐马尔可夫模型]]、[[00-笔记/机器学习/条件随机场]]、概率潜在语义分析、[[00-笔记/机器学习/潜在狄利克雷分配]]、[[00-笔记/机器学习/EM 算法|高斯混合模型]]。常见的非概率模型包括：[[00-笔记/机器学习/感知机]]、[[00-笔记/机器学习/支持向量机]]、[[00-笔记/机器学习/k 近邻]]、[[00-笔记/机器学习/Boost]]、[[00-笔记/机器学习/聚类#k 均值聚类|聚类]]、潜在语义分析以及神经网络。逻辑斯蒂回归可以看作是概率模型，也可以看作是非概率模型。

### 线性模型与非线性模型

非概率模型中，可以分为 [[00-笔记/机器学习/线性模型|线性模型]] (linear model) 和非线性模型 (non-linear model)。如果函数 $y=f(x)$ 或者 $z=g(x)$ 是线性函数，则称模型是线性模型，否则是非线性模型。

常见的线性模型有：感知机、线性支持向量机、k 近邻、k 均值、潜在语义分析。常见的非线性模型有：核函数支持向量机、AdaBoost、神经网络。

### 参数化模型和非参数化模型

机器学习可以分为参数化模型 (parametric model) 和参数化模型 (non-parametric model)。参数化模型假设模型的参数维度固定，模型可以由有限维参数完全刻画，非参数模型假设模型参数不固定或者无穷大，随着训练数据量的增加而不断增大。

常见的参数化模型有：感知机、朴素贝叶斯、逻辑斯蒂回归、k 均值、高斯混合模型、潜在语义分布、概率潜在语义分布、潜在狄利克雷分配、[[00-笔记/机器学习/最大熵模型]]。常见的非参数化模型有：决策树、支持向量机、AdaBoost、k 近邻。

## 统计学习方法三要素

统计学习方法都是有模型、策略和算法构成。

### 模型

机器学习首先要考虑的问题是学习什么样的模型。在监督学习中，模型就是要学习的条件概率分布或者决策函数。模型的假设空间包含所有可能的条件概率或决策函数。假设空间由 $\mathcal F$ 表示，假设空间可以定义为决策函数的集合：
$$
\mathcal F=\{f\,|Y=f_\theta(X),\theta\in R^n\}
$$
其中参数向量 $\theta$ 取值于 $n$ 维欧式空间 $R^n$，称为参数空间。假设空间也可以定义为条件概率的集合：
$$
\mathcal F=\{P|P_\theta(Y|X),\theta\in R^n\}
$$
参数 $\theta$ 与之前定义相同。

### 策略

有了模型的假设空间，接着要考虑的就是从假设空间中选取最优模型。首先引入损失函数与风险函数的概率。损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型的好坏。

#### 损失函数与风险函数

监督学习问题在假设空间 $\mathcal F$ 中选取模型 $f$ 作为决策函数，对于给定的输入 $X$ 给出相应的输出 $\hat Y=f(X)$，这个输出的预测值 $f(X)$ 与真实值可能一致也可能不一致，用一个损失函数 (loss function) 或者代价函数 (cost function) 来度量预测错误的程度，损失函数是 $f(X)$ 与 $Y$ 的非负实值函数，记为 $L(Y,f(X))$。

机器学习常用下面的几个损失函数：
1. 0-1 损失函数 (0-1 loss function)
$$
L(Y,f(X))=\begin{cases}1,&Y\ne f(X)\\0,&Y=f(X)\end{cases}
$$
2. 平方损失函数 (quadratic loss function)
$$
L(Y,f(X))=(Y-f(X))^2
$$
3. 绝对损失函数 (absolute loss function)
   $$
L(Y,f(X))=|Y-f(X)|
$$
4. 对数损失函数 (logarithmic loss function) 或者对数似然损失函数 (log-likelihood loss function)
$$
L(Y,P(Y|X))=-\log P(Y|X)
$$

损失函数越小，模型就越好。由于损失函数的输入、输出 $(X, Y)$ 是[[00-笔记/概率论与数理统计/一维随机变量及其分布|随机变量]]，遵循联合分布，所以损失函数的[[00-笔记/概率论与数理统计/随机变量的数字特征|期望]]是：
$$
\begin{align}
R_{exp}(f)&=E_p[L(Y,f(X))]\\&=\int_{\mathcal X\times\mathcal Y} L(y,f(x))P(x,y)\mathrm dx\mathrm dy
\end{align}
$$

这就是理论上模型 $f(X)$ 关于联合分布 $P(X,Y)$ 的平均意义下的损失，称为风险函数 (risk function) 或者期望损失 (expected loss)。

学习的目标就是选择期望风险最小的模型。由于联合分布未知，期望风险不能直接计算。给定数据集 $T$，则模型 $f(X)$ 关于数据集 $T$ 的平均损失称为经验风险 (empirical risk)或者经验损失 (empirial loss)，记为 $R_{\mathrm{emp}}$：
$$
R_{\mathrm{emp}}(f)=\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))
$$
期望风险是模型关于联合分布的期望损失，经验风险是模型关于训练样本集的平均损失，根据大数定律，当样本容量 $N$ 趋近无穷的时候，经验风险就区域样本风险，所以一个很自然的想法是用经验风险来估计期望风险。但是由于现实中训练样本数目有限甚至很小，所以用经验风险来估计样本风险往往不理想，需要进行一定的矫正，于是引出了监督学习的两个基本策略：经验风险最小化和结构风险最小化。

#### 经验风险最小化与结构风险最小化

在假设空间、损失函数以及训练数据集确定的情况下，经验风险函数表达式就可以确定，经验风险最小化 (empirical risk minimization, ERM) 的策略认为经验风险最小的模型就是最优的模型，根据这一策略，按照经验风险最小化求最优模型就是求解最优化问题：
$$
\min_{f\in\mathcal F}\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))
$$
当样本容量足够大时，经验风险最小化能够保证有很好的学习效果。比如极大似然估计 (maximum likelihood estimation) 就是经验风险最小化的一个例子，当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化等价与极大似然估计。

但是当样本容量很小时，经验风险最小化会产生过拟合 (over-fitting) 的现象。结构风险最小化 (structural risk minimization, SRM) 是为了防止过拟合而提出的策略。结构分析最小化等价与正则化 (regularization)。结构风险在经验风险上加上了表示模型复杂度的正则化项 (regularizer) 或者罚项 (penalty term)。在假设空间、损失函数以及训练数据集确定的情况下，结构风险的定义是：
$$
R_{\mathrm{srm}(f)}=\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))+\lambda J(f)
$$
其中 $J(f)$ 是模型复杂度，是定义在假设空间 $\mathcal F$ 上的泛函。模型 $f$ 越复杂，复杂度 $J(f)$ 越大。$\lambda \geqslant0$ 是系数，用以权衡经验风险与模型复杂度。结构风险小需要经验风险与模型复杂度同时小，结构风险小的模型往往对训练数据以及未知的测试数据都有较好的预测。

例如，贝叶斯估计中的 [[00-笔记/机器学习/最大后验估计]] (maximum posterior probability estimation, MAP) 就是结构风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价与最大后验概率估计。

结构风险最小化的策略认为结构风险最小的模型就是最优的模型，所以求解最优模型就是求解最优化问题：
$$
\min_{f\in\mathcal F}\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))+\lambda J(f)
$$

### 算法

算法指学习模型的具体方法，机器学习基于训练数据集，根据学习策略从假设空间中选择最优的模型，最后考虑用什么样的计算方法求解最优模型。这时，机器学习问题就变为了最优化问题，机器学习算法称为了最优化算法。

## 模型评估与模型选择

本节主要讨论的是监督学习中的几个重要概念。

### 训练误差与测试误差

机器学习的目的是使学习得到的模型不仅对已知的数据而且对未知的数据都能由较好的预测能力。不同的方法会给出不同的模型，当损失函数给定时，基于损失函数的模型的训练误差 (training error) 和测试误差 (test error) 就成为了学习方法的评估标准。注意，机器学习中用于评估的损失函数不一定是训练时使用的学习函数。当然，让两者相同时比价理想的。

假设学习得到的模型是 $Y=\hat f(X)$，训练误差是模型 $Y=\hat f(X)$ 关于训练数据集的平均损失：
$$
R_\mathrm{emp}(\hat f)=\frac{1}{N}\sum_{i=1}^NL(y_i,\hat{f}(x_i))
$$
测试误差是模型 $Y=\hat f(X)$ 关于测试数据集的平均损失：
$$
e_\mathrm{test}=\frac{1}{N'}\sum_{i=1}^{N'}L(y_i,\hat f(x_i))
$$
例如，当损失函数是 0-1 损失时，测试误差就变成了常见的测试数据集上的误差率 (error rate)：
$$
e_\mathrm{test}=\frac{1}{N'}\sum_{i=1}^{N'}I(y_i\ne \hat f(x_i))
$$
相应的，常见的测试数据集上的准确率 (accuracy) 为：
$$
r_\mathrm{test}=\frac{1}{N'}\sum_{i=1}^{N'}I(y_i= \hat f(x_i))
$$
显然有：
$$
r_\mathrm{test}+e_\mathrm{test}=1
$$
通常将学习方法对于未知数据的预测能力称为泛化能力 (generalization)。

### 模型选择

当假设空间中有不同复杂度（如参数个数不同）的模型时，就要面临模型选择问题 (model selection)。如果在假设空间中存在真模型，那么我们所选择的模型应当逼近真模型。如果一味地追求提高对训练数据的预测能力，所选模型的复杂度则往往会比真模型更高，这种现象称为过拟合 (over-fitting)。

#### 正则化

模型选择的典型方法是正则化 (regularization)。正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项 (regularizer) 或者罚项 (penalty term)。正则化项一般是模型复杂度的单调递增模型，模型越复杂，正则化项值就越大。例如，正则化项可以是模型参数向量的范数。

正则化一般具有下面的形式：
$$
\min_{f\in\mathcal F}\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))+\lambda J(f)
$$
正则化项可以取不同的形式，例如回归问题中，损失函数是平凡损失，正则化项可以是参数向量的 $L_2$ 范数：
$$
L(\omega)=\frac{1}{N}\sum_{i=1}^N(f(x_i;\omega)-y_i)^2+\frac{\lambda}{2}\|\omega\|^2
$$
或者是参数向量的 $L_1$ 范数：
$$
L(\omega)=\frac{1}{N}\sum_{i=1}^N(f(x_i;\omega)-y_i)^2+\lambda\|\omega\|*1
$$

正则化符合奥卡姆剃刀 (Occam's razor) 原理：在所有可能选择的模型中，能够很好的解释已知数据并且十分简单才是最好的模型，也是应该选择的模型。

#### 交叉验证

另一种常用的模型选择方式是[[00-笔记/实践知识/交叉验证|交叉验证]] (cross validation)。

如果给定的样本数据充足，进行模型选择的一种简单的方式是随机地将数据集分成三部分，分别为训练集 (training set)、验证集 (validation set) 和测试集 (test set)。训练集用于训练数据，验证集用于模型的选择，测试集用于最终对学习方法的评估。在学习到不同复杂度的模型中，选择对验证集有最小预测误差的模型。

但是在许多实际应用中数据时不充足的，为了选择更好的模型，可以采用交叉验证的方法，交叉验证的基本想法是重复的使用数据，把给定的数据进行切分，将切分的数据集组合成训练集和测试集，在此基础上反复训练、测试以及模型选择。下面是几种常用的交叉验证方法：
1. 简单交叉验证：首先随机的将已给出的数据分为两部分，一部分作为训练集，另一部分作为测试集，然后用训练集在各种条件下训练模型，从而得到不同的模型，在测试集上评价各个模型的测试误差，选出测试误差最小的模型。
2. S 折交叉验证：应用最多的是 S 折交叉验证 (S-fold cross validation)，方法如下：首先随机地将已给数据切分为 S 个互不相交的、大小相同的子集，然后利用 S-1 个子集的数据训练模型，利用余下的子集测试模型，将这一过程对可能的 S 中选择重复进行，最后选出 S 次评测中平均测试误差最小的模型。
3. 留一交叉验证：S 折交叉验证 $S=N$ 的特殊情况，称为留一交叉验证 (leave-one-out cross validation)，往往在缺乏数据的情况下使用。

## 泛化能力

学习方法的泛化能力 (generalization alility) 是指由该方法学习到的模型对于未知数据的预测能力，是学习方法本质上重要的性质。现实中采用最多的方法就是使用测试误差来评价学习方法的泛化能力，但这种评价是依赖测试数据集的。机器学习理论试图从理论上对学习方法的泛化能力进行分析。

首先给出泛化误差的定义：如果学得的模型为 $\hat f$，那么用这个模型对未知数据预测的误差即为泛化误差 (generalization error)：
$$
\begin{align}
R*\mathrm{exp}(\hat f)&=E_P[L(Y,\hat f(X))]
\\&=\int_{\mathcal{X\times Y}}L(y,\hat f(x))P(x,y)\mathrm dx\mathrm dy
\end{align}
$$
泛化误差反映了学习方法的泛化能力，事实上，泛化误差就是所学到的模型的期望风险。

### 泛化误差上界

学习方法的泛化能力分析往往是通过研究泛化误差的概率上界进行的，简称泛化误差上界 (generalization error bound)。具体来说，就是通过比较两个方法的泛化误差上界的大小来比较他们的优劣。泛化误差上界具有下面的性质：
- 它是样本的容量函数，当样本容量增加时，泛化上界趋于 0
- 它是假设空间容量的函数，假设空间容量越大，模型就越难学，泛化误差上界就越大

## 生成模型和判别模型

监督学习可以分为生成方法 (generative approach) 和判别方法 (discriminative approach)。所学到的模型分别称为生成模型 (generative model) 和判别模型 (discrimainative model)。

生成方法原理上由数据学习联合概率分布 $P(X,Y)$，然后求出条件概率分布 $P(Y|X)$ 作为预测模型，即生成模型：
$$
P(Y|X)=\frac{P(X,Y)}{P(X)}
$$
典型的生成模型有朴素贝叶斯法与隐马尔可夫模型。

而判别方法由数据直接学习决策函数 $f(X)$ 或者条件概率分布 $P(Y|X)$ 作为预测模型，判别方法关心的是对于给定的输入 $X$ 应该预测什么样的 $Y$。

生成方法的特点是可以还原出联合概率分布 $P(X,Y)$，且学习收敛相较于判别方法更快。当存在隐变量时，仍然可以用于学习，但是判别方法就不能。判别方法的特点是直接学习条件概率或者决策函数，直接面对预测，往往学习的准确率更高。由于直接学习 $P(Y|X)$ 或者 $f(X)$，可以对数据进行各种程度上的抽象、定义并使用特征，因此可以简化学习问题。

## 监督学习的应用

监督学习应用主要在三个方面：分类问题，标注问题和回归问题

### 分类问题

分类问题是监督学习中的一个核心问题，在监督学习中，当输出变量 $Y$ 取有限个值时，预测问题就变为了分类问题。监督学习从数据中学习一个分类模型或者分类决策函数，称为分类器 (classifier)，分类器对新的输入进行预测，称为分类 (classification)，可能的输出为类别 (class)。

评价分类器性能的指标一般是分类准确率 (accuracy)，其定义为：对于给定的测试集，分类器正确分类的样本数与总样本数之比。对于二分类问题常用的[[00-笔记/实践知识/评价指标|评价指标]]是精确率 (precision) 和召回率 (recall)。通常以关注的类为正类，其他类为负类，分类器在测试数据集上预测正确或者不正确的四种情况分布记为：
- TP：将正类预测为正类
- FN：将正类预测为反类
- FP：将反类预测为正类
- TN：将反类预测为反类
于是精确率定义为：
$$
P=\frac{TP}{TP+FP}
$$
召回率定义为：
$$
R=\frac{TP}{TP+FN}
$$
此外，还有 $F_1$ 定义为精确率与召回率的调和均值，即
$$
\frac{2}{F_1}=\frac{1}{P}+\frac{1}{R}\Leftrightarrow F_1=\frac{2TP}{2TP+FP+FN}
$$
当精确率和召回率都高的时候，$F_1$ 的值也高。

### 标注问题

标注 (tagging) 也是一个监督问题。可以认为标注问题是分类问题的一个推广，又是根据复杂的结构预测 (structure prediction) 问题的简单形式。标注问题的输入是一个观测序列，输出是一个标记序列或者状态序列。

### 回归问题

回归 (regression) 是监督学习的另一个重要问题，用于预测输入（自变量）与预测输出（因变量）之间的关系，特别是当输入变量的值发生变化时，输出的值随之发生变化。回归问题的学习等价与函数拟合，选择一条函数曲线使其很好地拟合已知数据且很好的预测未知数据。回归问题最常用的损失函数是平方损失，在这种情况下，回归问题可以由著名的最小二乘法 (least squares) 求解。

> [!more] 表示学习 (Representation Learning)
> **数据表示是机器学习的核心问题**。表示学习是学习数据表示的技术的集合，用于将现实世界中的数据转换为能够被计算机高效处理的形式。
> - 为了提高机器学习系统的准确率，需要将输入信息转换为有效的特征，或者更加一般性称为**表示**。
> - 如果一种算法可以自动的学习出有效的特征，并提高最终机器学习模型的性能，这种学习就叫做表示学习。
> 
> 在传统机器学习领域，数据表示主要通过特征工程实现，而特征工程需要依靠专家提取显示特征，工程量巨大，特征选取的好坏将直接决定数据表示的质量，从而影响后续任务的性能。
> 在深度学习中，数据表示和后续任务往往是联合训练，不依赖专家经验，但需要较大的训练数据集。深度学习的目标是通过构建具有一定深度的模型，可以让模型自动学习好的特征表示，从而最终提升预测或者识别的准确性。简单表示为
> $$
深度学习=表示学习+决策学习
$$
