```python
import micropip
await micropip.install('numpy')
await micropip.install('pandas')
await micropip.install('scikit-learn')
import numpy as np
import pandas as pd
from sklearn import model_selection
```

# 交叉验证

在使用机器学习算法解决实际问题之前，我们有必要直到交叉验证 (Cross-validation) 的概念。交叉验证没有一个明确的定义，这里给出一种：**交叉验证是帮助我们的模型正确的学习数据，确保不会过拟合的步骤**。这里需要先了解 [[00-笔记/深度学习/多层感知机#欠拟合与过拟合]]。

每当我们训练一个神经网络时，如果我们监控训练期间损失在训练集和测试集的下降情况，当在一个相当小的数据集上进行训练时，我们将会观察到随着训练的进行，训练集和测试集上的损失都会减少，但是在某一点上，测试集损失将会到达一个最小值，然后开始增大。**我们必须在训练集损失达到最小时停止训练**，否则模型将会过拟合。

## 奥卡姆剃刀

奥卡姆剃刀原则 (Occam's razor) 是对过拟合的一个简单的描述。在奥卡姆剃刀原则认为，当一件事情可以使用多种方法解决时，我们应该总是选择最简单的方法。事实上，如果你的模型没有遵循奥卡姆剃刀原则，那么它更可能过拟合。

## 交叉验证方法

现在回到交叉验证。为了预防过拟合，我们将训练数据划分为了两个部分。我们在一个部分上训练模型，然后在另一个部分上观察模型的表现。这实际上也是一种交叉验证方式，称为**留出集** (hold-out set)。我们常在一个非常大的数据上使用这种交叉验证方法。

验证是训练一个具有泛化能力的机器学习模型时关键的步骤，一个数据集上的交叉验证方式可能不适用于其他模型，因此我们需要选择适合交叉验证方式。但是也有一些广泛使用的交叉验证方式，这里将概括一些。

## k-折交叉验证

k-折交叉验证 (k-fold cross-validation) 将数据分为几部分，模型每次在其中的一些部分上面进行训练，并在其他部分上进行验证。sklearn 中提供了将数据划分为 k 折的函数。
```python
data = np.random.rand(100, 5)
kf = model_selection.KFold(n_splits=5)
for fold, (train, val) in enumerate(kf.split(X=data)):
	print(f"fold: {fold}, train: {train.shape}, val: {val.shape}")
```

## 分层 k-折交叉验证

对于一些标签分布不均衡的数据，直接使用 k 折交叉验证可能导致某些类型的数据量过少。使用分层采样的方式对于这样的数据集是一种更加合适的方法。这样的方式按照标签的比例将数据集进行划分。sklearn 中同样提供了相应的接口。
```python
data = np.random.rand(100, 5)
y = np.zeros(200)
y[150:] = y[150:] + 1
kf = model_selection.StratifiedKFold(n_splits=5)
for f, (t_, v_) in enumerate(kf.split(X=data, y=y)):
	print(f"fold: {f}, train: {t_.shape}, val: {v_.shape}")
```

## 留出法

虽然 k-折交叉验证得到的结果可以模拟在训练集上得到的结果，但是对于一些训练成本非常高的模型，k-交叉验证可能过于昂贵了。在数据集足够大的时候，我们可以使用简单的留出法进行训练。

留出法在时间序列数据上也经常使用。例如，我们拥有 0 到 30 单位时间的数据，我们希望预测 31 到 40 单位时间。我们可以将 21 到 30 的数据作为留出集，使用前面的数据来调整超参数。需要注意的是，在预测 31 到 40 单位时间中的数据时，我们需要使用所有的数据，否则性能可能不佳。

## N-折交叉验证

在很多情况下，我们会面临很小的数据集，这种时候，如果创建一个很大的验证集，意味着将损失大量的可学习数据。在这种情况下，我们可以在 k-折交叉验证中，令 k=N，这里的 N 是数据集中的样本数量。

这种方式在模型速度较慢的情况下非常花费时间，但是由于这种方式只在数据集很小时使用，因此这个缺陷不明显。

## 回归问题中的分层 k-折交叉验证

对于回归问题，几乎所有在分类问题中的交叉验证方法都可以使用。特别的，回归问题中的分层 k-折交叉验证需要进行特殊处理。

对于回归问题，如果发现采样得到的点在样本空间中的分布不均匀，那么就需要使用类似于分层采样的处理。具体的，我们将样本空间分成多个 bin。对于样本数量较多的情况，我们可以随意的将其分为 10 到 20 个的 bin。对于样本数量较少的情况，我们可以基于 Sturge's Rule 选择一个合适的 bin，即
$$
\text{Number of Bins}=1+\log_2(N)
$$
sklearn 中没有直接提供这样的接口，但是我们可以通过一些简单的处理得到对应的数据，这里不多赘述。

## Group k-fold

sklearn 中还提供了一个可以划分不同的大小的 fold 的接口，使用 GroupKFold 接口，并传入一个与数据集大小相同的列表，用于表示每个数据所属的 group，之后 sklearn 将会按照 group 中的描述划分训练集与验证集。
```python
data = np.random.rand(100, 2)
group = np.ones(100)
group[10:50] = 2
group[50:60] = 3
group[60:90] = 4
group[90:100] = 5

kf = model_selection.GroupKFold(n_splits=5)
for f, (t_, v_) in enumerate(kf.split(data, groups=group)):
	print(f"fold: {f}, train: {t_.shape}, val: {v_.shape}")
```

## 总结

交叉验证是在建立机器学习模型时非常重要的一步。如果你划分的验证集可以呈现训练与真实数据，那么你就可以建立一个高度泛化的模型。

这里提到的所有交叉验证方法都可以用于几乎所有的机器学习问题。对于不同的数据集，选择一个正确的交叉验证方法是很重要的问题。