---
tags:
  - 数据结构与算法
---

# 查找

> [!definition|Definition] 查找
> 在数据集合中寻找满足某种条件的数据元素的过程称为*查找*。查找的结果分为两种：
> 1. 查找成功，即在数据集合中找到了满足条件的数据元素；
> 2. 查找失败。

> [!note] 关于查找的一些术语
> 1. 查找表：用于查找的数据集合称为查找表，它由同一类型的数据元素组成，对于查找表的常见操作有*查询符合条件的数据元素*和*插入、删除数据元素*。
> 2. 静态查找表：若一个查找表的操作只涉及查找操作，则无须动态地修改查找表，此类查找表称为静态查找表。与此对应的是动态查找表。
> 	- 静态查找表：顺序查找，折半查找，散列查找等
> 	- 动态查找表：二叉排序树、散列查找
> 3. 关键字：数据元素中唯一标识元素的某个数据项的值，基于关键字的查找，查找的结果应该是唯一的。
> 4. 平均查找长度：在查找过程中，一次查找的长度是指需要比较的关键字次数，而平均查找长度则是所有查找过程中进行关键字比较次数的平均值。平均查找长度是衡量算的效率最主要的指标。

> [!example] 平均查找长度的数学定义
> 平均查找长度的数学定义为：
> $$
\text{ASL}=\sum_{i=1}^{n}P_{i}C_{i}
> $$
> 其中 $n$ 为查找表长度，$P_{i}$ 是查找第 $i$ 个数据元素的概率，一般认为每个数据元素的查找概率相等，即 $P_{i}=1/n$，$C_{i}$ 是找到第 $i$ 个数据元素所需要进行的比较次数。

> [!warning] 平均查找长度的计算是本节的核心，务必掌握每种结构的平均查找长度的计算方式。

## 基本查找方法

顺序查找、二分查找和分块查找方法是用于线性表的查找方法，它们不需要改变数据的组织方式，并且实现简单。

### 顺序查找

顺序查找又称为线性查找，即顺序扫描表中的每一个元素，直到找到目标关键字。

```cpp title:添加哨兵的线性查找
int searchSeq(int table[], int size, TYPE key){
	// 设置哨兵, 我们假设这里不会出现数组越界的情况
	table[size] = key;
	int i;

	for(i = 0; table[i] != key; i++);
	return i == size ? i : -1;
}
```

> [!tip] 哨兵
> 顺序查找结果简单，哨兵是一种对于查找的优化。在顺序查找的过程中，为了节省一些不必要的判断，我们将顺序表的一头设置为哨兵元素 (设置为查找目标)，然后从另一头开始扫描。在扫描过程中，退出条件为当前元素是否是查找目标。
>
> 通过设置哨兵，我们就可以避免大量的判断数组越界的判断语句，只需要在最后判断找到的目标究竟是先前设置的哨兵，还是查找到的目标。

> [!note] 线性查找的平均查找长度
> 对于有 $n$ 个元素的表，给定值 `key` 与表中的第 $i$ 个元素相等时，需要进行 $i$ 次关键字比较，查找成功时，平均查找长度为
> $$
\text{ASL}*\text{成功}=\sum*{i=1}^{n}P_{i}i
> $$
> 当每个元素的查找概率相等时，即 $P_{i}=1/n$，此时数学期望为
> $$
\text{ASL}*\text{成功}=\sum*{i=1}^{n}P_{i}i=\frac{n+1}{2}
> $$
> 查找不成功时，关键字的比较次数显然为 $n+1$ 次 ($n$ 个元素与一个哨兵)。

顺序查找实现简单，且泛用性强，对数据没有要求；但是当 $n$ 比较大时，平均查找长度大，效率低。因此顺序查找在数据量小的情况下比较常用，但是对于数据量大的情况，我们需要其他的方法。

> [!example]- 有序线性表的顺序查找
> 如果已知线性表是有序的，那么在扫描到比大于关键字的元素时还没有找到，那么就可以直接返回查找是失败的信息了。*~~实际上我觉得这个内容没有存在的必要，对于有序的数据我们一般不用属性查找，但是这个内容还是有应用场景的，例如链表中的查找。~~*

### 二分查找

二分查找又称为折半查找，仅用于有序的顺序表。二分查找的思想是将给定的 `key` 值每次都与表中间的元素进行比较，由于表是有序的，因此每次查找都能够淘汰一半的待查找元素。
```cpp title:二分查找
int binarySearch(int table[], int size, int key){
	int low=0, high=size-1, mid;
	while(low <= high){
		mid = (low + high) / 2;
		if(table[mid] < key){
			high = mid - 1;
		}else if(table[mid] > key){
			low = mid + 1;
		}else{
			return mid;
		}
	}
	return -1;
}
```

> [!warning]
> 1. 二分查找中，既可以向下取整，也可以向上取整，但是整个算法的取整方式必须相同。
> 2. 算法中更新方式使用 `high=mid-1` 与 `low=mid+1`，如果使用 `high=mid` 或者 `low=mid` 进行更新，算法虽然也可以通过不断缩小区间从而找到目标值，但是可能会出现死循环的情况：
>	- 考虑向下取整，此时 `high=r+1`，`low=r-1`，
>	- 计算 `mid=(r+1+r-1)/2=r`
>	- 如果此时程序使用 `low=mid` 进行更新，计算新的 `mid=(r+1+r)/2` 得到结果为 `mid=r`，此时陷入死循环。

**判定树**：二分查找的查找过程可以用一棵树来描述，称为判定树。树中每个圆形结点表示一个记录，结点中的值表示该记录的关键字值。树的叶结点都是方形的，用一个区间表示查找失败的区间。从判定树的定义可以看出来，二分查找的过程就是从树中找到一个根结点的过程，如果没有根结点对应，即找到了叶结点，说明查找失败。
![[image/查找-1.png|inline]]
若有序序列有 $n$ 个元素，则其对应的判定树有 $n$ 个圆形结点 (根结点)，$n+1$ 个叶结点。显然，二分查找的判定树是一棵**平衡二叉树**。

> [!note] 二分查找的平均查找长度
> 从判定树可以看出，二分查找的最大比较次数不会超过树的高度。假设有序表中的元素个数为 $n$，需要查找的关键字的位置为 $i$，可以得到其对应的判定树的高度 $h_{i}$ 满足 $h_{i}=\lceil \log_{2}(n_{i}+1) \rceil$。在等概率查找时，查找成功的平均查找长度为：
> $$
\begin{aligned}
\text{ASL}*\text{成功}&=\frac{1}{n}\sum*{i=1}^{n}h_{i}=\frac{1}{n}\sum_{i=1}^{n}\lceil \log_{2}n_{i} \rceil \\&=\frac{1}{n}\log_{2}(1+2\times 2+\cdots+h\times 2^{h-1})\\&=\frac{n+1}{n}\log_{2}(n+1)-1\approx \log_{2}(n+1)-1
\end{aligned}
> $$
> 也就是二分查找的时间复杂度为 $O(\log_{2}n)$。

> [!tip] 在实际计算二分查找的平均查找长度时，可以根据数据画出判定树，然后根据判定树的结点层级进行计算。

二分查找的实现简单，且查找速度快 (基本是最快的一种方法了)，但是对于数据的要求高，需要我们时刻维护一个有序的数据表，这个操作的代价过于高了，因此二分查找一般适合用于数据变化频率小的场景。

> [!example]- 判定树的形状
> 题目来源：![[image/查找-12.png]]
> 根据折半查找可以使用向上取整或者向下取整的策略，但是二者只能使用一个。我们可以根据这个性质来判断哪些平衡二叉树不是判定树：
> 1. 如果使用同一种取整方式，那么二叉树的叶子结点的朝向一定是相同的，题目中的 `b` 与 `c` 选项由于左右子树的叶子朝向不一致，故错误。
> 2. 如果使用同一种取整方式，那么每个二叉树的左右子树的大小是确定的，如果使用向下取整，那么左子树总是大于等于右子树；如果使用向上取整，则右子树总是大于等于左子树。题目中的 `d` 排除。

### 分块查找

分块查找又称为索引顺序查找，它吸收了顺序查找与二分查找的优点，既有动态结构，又适合快速查找。分块查找将查找表分为若干子块，块的元素可以是无序的，但是块间的元素需要是有序的，即**第一个块中最大的关键字小于第二个块中最小的关键字**。基于这个性质，我们可以为每个块建立一个索引表，表中记录每个块的最大值 (最小值) 与各个块第一个元素的地址 (最后一个块)，索引表按照块的关键字大小排序。

分块查找的过程为：
1. 在索引表中找到待查记录所在的块，可以使用顺序查找或者二分查找
2. 在对应的索引块内顺序查找

> [!note] 分块查找的**平均查找长度**
> 分块查找的平均查找长度为索引查找和块内查找的平均长度之和。假设将长度为 $n$ 的查找表均匀的分为 $b$ 块，每个块由 $s$ 个记录，在等概率的情况下，若在块内和索引表中均采用顺序查找，则平均查找长度为
> $$
> \text{ASL}=L_{1}+L_{s}=\frac{b+1}{2}+\frac{s+1}{2}=\frac{s^{2}+2s+n}{2s}
> $$
> 若 $s=\sqrt{ n }$，则平均查找长度取得最小值 $\sqrt{ n }+1$。

> [!warning] 当分块的数目取 $\sqrt{ n }$ 时，平均查找长度最小，为 $\sqrt{ n }+1$。

## 树形查找

### 二叉排序树

从 [[#二分查找]] 中我们可以发现，有序的树形结构有利于查找元素。二叉排序树就是一种基于树形结构，有利于查找、插入和删除数据的实现。

> [!definition|Definition] 二叉排序树
> 二叉排序树是具有下面特性的二叉树：
> 1. 若左子树非空，则左子树上所有结点的值均小于根结点的值。
> 2. 若右子树非空，则右子树上所有结点的值均大于根结点的值。
> 3. 左、右子树也分布是一棵二叉排序树。

> [!tip]
> 根据二叉排序树的定义，我们可以得到**左子树结点的值 < 根结点的值 < 右子树结点的值**，因此对二叉排序树使用*中序遍历*，可以得到一个递增的有序序列。

#### 查找

二叉排序树的查找是从根结点开始，沿着某个分支逐层向下比较的过程。即每次查找都与根结点比较，如果 `key` 大于根结点，则查找右子树。如果 `key` 小于根结点，则查找左子树。

#### 插入

二叉排序树可以在查找的同时插入树中不存在的关键字值。插入结点的过程如下：
1. 若原二叉排序树为空，则直接插入；
2. 否则，若关键字 `key` 小于根结点值且左子树为空，则插入到左子树中，否则对左子树递归
3. 否则，若关键字 `key` 大于根结点值且右子树为空，则插入到右子树中，否则对右子树递归

> [!note] 二叉排序树的构造
> 从一棵空树出发，依次输入元素，将它们插入二叉排序树中的合适位置，即可构造出二叉排序树。

#### 删除

在二叉排序树中删除一个结点时，不能把以该结点为根的子树上的结点全部删除，必须先将被删除结点从二叉排序树的链表上摘下，并将其子结点重新与二叉链表相连，同时确保二叉排序树的性质不会丢失。删除操作按照下面的三种情况来处理：
1. 若被删除结点 `z` 是叶结点，则直接删除。
2. 若被删除结点 `z` 只有一棵左子树或右子树，则让 `z` 的子树成为 `z` 父结点的子树，替代 `z` 的位置。
3. 若被删除结点 `z` 有左、右两棵子树，则令 `z` 的中序第一个子女替代 `z`，然后将问题转换为从二叉排序树中删除这个这个子女，此时就转变为了第一或者第二种情况。

> [!example]-
> ![[image/查找-6.png#inline|右子树为空]]
> ![[image/查找-7.png#inline|左子树为空]]
> ![[image/查找-8.png#inline|左右子树均不为空]]

> [!note] 二叉排序树的平均查找长度
> 二叉排序树的查找效率，主要取决于树的高度。若二叉排序树的左、右子树的高度之差的绝对值不超过 1，它的平均查找长度为 $O(\log_{2}n)$。若二叉排序树是只有一个左 (右) 孩子的单支树，则其平均查找长度为 $O(n)$。
>
> 在最坏的情况下，构造二叉排序树的输入序列是有序的，则会形成一个倾斜的单支树，此时二叉排序树的性能显著变坏。

> [!tip] 对比二分查找
> 1. 二分查找的对象是有序顺序表，若有插入和删除点的操作，所花的时间为 $O(n)$
> 2. 二叉排序树的查找、插入、删除的时间复杂度均为 $O(\log_{2}n)$。
> 3. 当有序表是静态查找表时，宜采用顺序表作为其存储结构，使用二分查找实现查找操作；当有序表是动态查找表，则应选择二叉排序树作为其逻辑结构。

### 平衡二叉树

为了避免树的高度增长过快，降低二叉排序树的性能，规定在插入和删除结点时，要保证任意结点左、右子树高度差绝对值不超过 1，将这样的二叉树称为**平衡二叉树**，也称为 AVL 树。

> [!definition|平衡因子] 定义左子树与右子树的高度差为该结点的平衡因子，平衡二叉树的平衡因子只能是-1、0 或者 1。

#### 插入

每当在二叉排序树中插入 (或删除) 一个结点时，首先检查其插入路径上的结点是否因为此次操作而导致了不平衡。

若导致了不平衡，则先找到插入路径上离插入结点最近的平衡因子绝对值大于 1 的结点 $A$，再对以 $A$ 为根的子树，在保持二叉排序树特性的前提下，调整各结点的位置关系，使之重新达到平衡。

> [!warning]
> 每次调整的都是最小不平衡子树，即距离插入结点最近的、平衡因子绝对值大于 1 的结点作为根的子树。

二叉平衡树的插入过程的前半部分与二叉排序树相同，但是在新结点插入后，若造成查找路径上某结点的不平衡，则需要对该结点进行调整。

1. LL 平衡旋转^[在 $A$ 的左孩子的左子树中插入导致不平衡，右单旋转]
```cpp
void LL(Tree &A){
	TNode B = A->lchild;
	A->lchid = B->rchild;
	B->rchild = A;
	A = B; // 修改根结点
}
```
![[image/查找-2.png#center|LL平衡旋转，右单旋转]]

2. RR 平衡旋转^[在 $A$ 的右孩子的右子树中插入导致不平衡，左单旋转]
```cpp
void RR(Tree& A){
	TNode B = A->rchild;
	A->rchild = B->lchild;
	B->rchild = A;
	A = B;
}
```
![[image/查找-3.png#center|RR平衡旋转，左单旋转]]

3. LR 平衡旋转^[在 $A$ 的左孩子的右子树中插入导致不平衡，先左后右双旋转]
```cpp
void LR(Tree &A){
	TNode B = A->lchild;
	LL(B);
	RR(A);
}
```
![[image/查找-4.png#center|LR平衡旋转，先左后右双旋转]]

4. RL^[在 $A$ 的右孩子的左子树中插入导致不平衡，先右后左双旋转]
```cpp
void RL(Tree &A){
	TNode B = A->rchild;
	RR(B);
	LL(A);
}
```
![[image/查找-5.png#center|RL平衡旋转，先右后左双旋转]]

> [!tip] 记忆方式
> 在不平衡结点的左子树插入需要右旋，右子树插入需要左旋，后进先出 (栈)。

> [!note]
> 在 LR 和 RL 插入方式中，新结点是插入 $C$ 的左子树还是右子树，不影响旋转的方式，区别仅在于旋转后的平衡二叉树的左右子树平衡因子不同，但是仍然符合平衡二叉树的定义。

#### 删除

与平衡二叉树的插入操作类似。
1. 删除结点 (同 [[#二叉排序树#删除|二叉排序树的删除]])。
2. 一路向上找到最小的不平衡子树。
3. 记最小不平衡子树的左右孩子中，深度较深的孩子为 $A$，在 $A$ 的左右孩子中，深度较深的孩子为 $B$，此时，根据 $B$ 的位置来调整平衡，调整方式同 [[#平衡二叉树#插入|插入操作]] ：
	- $B$ 在 LL：$A$ 右单旋
	- $B$ 在 RR：$A$ 左单旋
	- $B$ 在 LR：$B$ 先左旋，再右旋
	- $B$ 在 RL：$B$ 先右旋，再左旋
4. 如果不平衡向上传导，继续调整。

> [!note] 平衡二叉树的平均查找长度
> 平衡二叉树的查找方式与排序二叉树相同，因此在查找过程中关键字的比较次数不超过树的深度。
>
> 假设 $n_{h}$ 表示深度为 $h$ 的平衡二叉树中含有的最少结点数，显然，有 $n_{0}=0,n_{1}=1,n_{2}=2$ 并且有 $n_{h}=n_{h-2}+n_{h-1}+1$。含有 $n$ 个结点的平衡二叉树的最大深度为 $O(\log_{2}n)$，即平均查找效率为 $O(\log_{2}n)$。

> [!tip]- 可以记下结论 $n_{h}=n_{h-2}+n_{h-1}+1$
> 由于平衡二叉树要求左右子树的深度之差的绝对值小于等于 1，因此不妨保持左右子树的深度之差为 1，即左子树深度总是比右子树大 1。根据平衡二叉树的递归定义，可以得到左右子树的结点数分别为 $n_{h-1}$ 和 $n_{h-2}$, 于是可以得到递推式 $n_{h}=n_{h-2}+n_{h-1}+1$。

### 红黑树

为了保持 AVL 树的平衡性，在插入和删除操作后，会非常频繁的调整全树整体拓扑结构，代价较大。为此在 AVL 树的平衡标准上进一步放宽条件，引入了红黑树的结构。

> [!definition|Definition] 红黑树
> 一棵红黑树 (RBT) 是满足如下*红黑性质*的 [[#二叉排序树]] ：
> 1. 每个结点要么是红色的，要么是黑色的。
> 2. 根结点是黑色的。
> 3. 叶结点 (虚构的外部结点、`NULL` 结点，即**查找失败的结点**) 都是黑色的。
> 4. 不存在两个相邻的红结点 (即红结点的父结点和孩子结点均是黑色的)。
> 5. 对每个结点，从该结点到任意一个叶结点的简单路径上，所含黑结点的数量相同。

为了便于理解，这里引入了 $n+1$ 个外部叶结点用于表示空结点，以保证红黑树中每个结点的左、右孩子均非空。

> [!example] 红黑树的判断
> 判断红黑树可以按照下面的顺序判断：
> 1. 是否是二叉排序树？(左>根>右或者左<根<右)
> 2. 根是否为黑色？
> 3. 是否存在相邻的红结点？
> 4. 左右子树的黑结点数量是否一致？

> [!note] 红黑树的特性
> 从某结点出发 (不含该结点) 到达一个叶结点的任意一个简单路径上的黑结点总数称为该结点的*黑高* (记为 `bh`)。根结点的黑高称为红黑树的黑高。
> 1. **从根到叶结点的最长路径不大于最短路径的 2 倍。**
>    根据性质 5，可以得到当从根到任意一个叶结点的简单路径最短时，这条路径必然全由黑结点构成。
>    根据性质 4，可以得到当某条路径最长时，这条路径必然是黑红结点相间构成，此时红结点和黑结点的数量相同。
> 2. **有 $n$ 个内部结点的红黑树的高度 $h\leqslant 2\log_{2}(n+1)$**。
>    当一棵红黑树的黑高为 $bh$ 时，当红黑树为一个全是黑节点的满二叉树时，该红黑树的结点最少，即红黑树此时的高度至少为 $2^{bh}-1$。
>    由上一个结论，从根到叶结点的任何一条简单路径上都至少有一半是黑结点。因此，根的黑高至少是 $h/2$，于是有 $n\geqslant 2^{h/2}-1$。
>    这说明红黑树的查找效率为 $O(\log_{2}n)$。

#### 插入

红黑树的插入过程的前半部分与二叉排序树相同，而红黑树中插入之后需要对结点进行调整，以满足红黑树的性质。

1. 先查找，确定插入位置，插入新结点
2. 染色
	- 若新结点<span style="background:rgba(92, 92, 92, 0.8); color:rgb(255,255,255);">是根</span>，则染为<span style="background:rgba(92, 92, 92, 0.8); color:rgb(255,255,255);">黑色</span>
	- 若新结点<span style="background:#ff4d4f; color:rgb(255,255,255)">非根</span>，则染为<span style="background:#ff4d4f; color:rgb(255,255,255)">红色</span>
3. 若染色后新结点不满足红黑树定义 [^满足红黑树定义的快速判断方法]，则需要进行调整，使其重新满足红黑树定义。这里说明两个术语：叔结点 [^叔结点]，爷结点 [^爷结点]，我们根据新结点的叔结点的颜色来进行后续操作：
	- 叔结点是黑色，则需要根据新结点相对于爷结点的位置，对父结点进行旋转操作，这里的旋转方式与 [[#平衡二叉树#插入|平衡二叉树的插入]] 完全相同
		- LL，右单旋
		- RR，左单旋
		- LR，先左旋，再右旋
		- RL，先右旋，再左旋
		- 最后交换原来父结点与爷结点的颜色
	- 叔结点是红色，将父结点、叔结点染为黑色，爷结点染为红色，接着向上递归

[^满足红黑树定义的快速判断方法]: 可以直接判断新结点的父节点是否是红色 (即是否违反红结点不能相邻的性质)。

[^叔结点]: 在二叉树中，叔结点表示一个结点**父节点的兄弟结点**。

[^爷结点]: 在二叉树中，爷结点表示一个结点**父结点的父结点**。

#### 删除

*~~红黑树的删除操作过于复杂，这里只要了解一些关于删除的简单内容即可~~*。

> [!note] 红黑树删除操作的时间复杂度为 $O(\log_{2}n)$

## B 树

> [!tip] $m$ 阶 B 树即所有结点的平衡因子均等于 0 的 $m$ 路平衡查找树。

> [!definition|Definition] B 树
> 一棵 $m$ 阶 B 树或为空树，或为满足以下性质的 $m$ 叉树：
> 1. 树中每个结点至多有 $m$ 棵子树，至多有 $m-1$ 个关键字。
> 2. 若根结点不是叶结点，则至少有 2 棵子树，即至少有 1 个关键字。
> 3. 除根结点外的所有非结点至少有 $\lceil m/2 \rceil$ 棵子树，即至少有 $\lceil m/2 \rceil-1$ 个关键字。
> 4. 所有非叶结点的结构如下：
>     $$
\begin{array}{|c|c|c|}
\hline
n & P_{0} & K_{1} & P_{1} & K_{2} & P_{2} & \cdots & K_{n} & P_{n}\\
\hline
\end{array}
>     $$
>     其中，$K_{i}$ 为结点的关键字，且满足 $K_{1}<K_{2}<\cdots<K_{n}$；$P_{i}(i=1,2,\cdots,n)$ 为指向子树根结点的指针，且指针 $P_{i-1}$ 所指子树中所有结点的关键字均小于 $K_{i}$，$P_{i}$ 所指子树中所有结点的关键字均大于 $K_{i}$；$n(\lceil m/2 \rceil-1\leqslant n\leqslant m-1)$ 为结点中关键字的个数。
> 5. 所有的叶结点都出现在同一层次上，并且不带信息。(可以视为外部结点或者失败结点)

> [!warning] n 阶 B 树中的 n 指的是子树的个数，因此每个节点中的关键字的个数最多为 n-1

> [!note] B 树也写为 B-树，这里 '-' 为连字符，因此不能称为 “B 减树”。

> [!note] B 树的效率分析
> 设含 $n$ 个关键字的 $m$ 阶 B 树，则
> 1. **最小高度**为 $\log_{m}(n+1)$：
>    - 假设有一棵高度为 $h$、每个结点都是满的 B 树，则第一层有 $m-1$ 个关键字，对应 $m$ 棵子树。
>    - 第二层有 $m(m-1)$ 个关键字，对应 $m^2$ 棵子树。
>    - 对于高度为 $h$ 的满 B 树，关键字总数为 $m-1 + m(m-1) + m^2(m-1) + \cdots + m^{h-1}(m-1) = (m-1)\left(1 + m + m^2 + \cdots + m^{h-1}\right)$。
>    - 这是一个等比数列求和问题，可以得到高度为 $h$ 的满 B 树最多有关键字数量 $m^h - 1$。
>    - 因此，含有 $n$ 个关键字的 B 树的高度满足 $h \leqslant \log_{m}(n+1)$。
> 2. **最大高度**为 $\log_{\lceil m/2 \rceil}\left(\dfrac{n+1}{2}\right) + 1$：
>    - 假设有一棵高度为 $h$，且每个结点的关键字尽可能少的 B 树。
>    - 根据 B 树的定义，根节点至少有两个分叉，其余结点至少有 $\lceil m/2 \rceil$ 个分叉。
>    - 于是可以得到最后的叶子结点数目为 $2\lceil m/2 \rceil^{h-1}$。
>    - 含有 $n$ 个关键字的 B 树一定含有 $n+1$ 个叶子结点。
>    - 由此得到不等式 $2\lceil m/2 \rceil^{h-1} \geqslant n+1$。
>    - 解得 $h \geqslant \log_{\lceil m/2 \rceil}\left(\dfrac{n+1}{2}\right) + 1$。

### 查找

B 树是对二叉排序树的一种扩展。在二叉排序树中，每个节点通过一个关键字将数据划分为左右两个部分，即左子树和右子树，查找时需在这两个部分中做出选择。而在 $n$ 阶 B 树中，每个节点能够存储多达 $n−1$ 个关键字，这些关键字将数据划分为 $n$ 个部分，对应 $n$ 棵子树。因此，在 B 树中查找元素的过程如下：
1. **定位关键字**：首先确定目标元素在当前节点所存储的关键字序列中的相对位置。这可以通过顺序查找或二分查找等方式实现。
2. **选择子树**：根据目标元素相对于当前节点关键字的位置，选择相应的子树继续搜索。这一过程递归地进行，直至找到目标元素或到达叶子节点（即没有子树的节点）为止。

### 插入

B 树的插入操作主要涉及两个步骤：
1. **定位**：
	- 通过 B 树的查找方式找到待插入元素应插入的具体位置。这个位置通常是某个终端节点（叶子节点）。
2. **插入**：
	- 将元素插入到定位好的终端节点中。
	- 如果终端节点已满，则执行分裂操作。

**分裂操作**：
- 当一个节点已满（即包含 $m-1$ 个关键字），需要将其分裂为两个新的节点，并将中间的关键字提升到父节点中。
	- 将节点的关键字从 $\lceil m/2 \rceil$ 处分成两个部分，形成两个新的节点。
	- 将第 $\lceil m/2 \rceil$ 个关键字上提到父节点中作为分界关键字。
	- 如果父节点也已满，则重复上述分裂过程，直到不再需要分裂或到达根节点。

> [!warning]
> - 在执行分裂操作时，如果根节点分裂导致新的根节点出现，那么树的高度会增加 1。
> - 分裂操作可能需要沿着路径递归向上执行，直到找到一个不再满的节点或达到根节点。

通过这样的步骤，可以确保 B 树在插入新元素后仍然保持其结构特性，从而保证高效的查找性能。

> [!example]- 分裂操作
> ![[image/查找-9.png#center|B树插入操作]]

### 删除

B 树的删除操作通常涉及关键字的删除以及随后可能的结点调整或合并。以下是具体的步骤：
1. **删除关键字**：
   - 如果被删除的关键字位于**终端结点**（叶子结点），则直接删除。
   - 如果被删除的关键字位于**非终端结点**，则使用它的直接前驱 [^直接前驱] 或直接后继 [^直接后继] 替换它，然后问题转化为在终端结点中删除关键字。
2. **调整或合并**：
   - 如果删除后，终端结点中的关键字数量少于 $\lceil m/2 \rceil$，则需要进行调整：
     - **兄弟够借**：
       - 若此结点的右兄弟结点的关键字个数多于 $\lceil m/2 \rceil$，则借用右兄弟结点的一个关键字^[当前结点后继的后继。] 和父节点中的分界关键字^[当期结点的后继。] 来填充当前结点。
       - 若此结点的左兄弟结点的关键字个数多于 $\lceil m/2 \rceil$，则借用左兄弟结点的一个关键字^[当前结点的前驱。] 和父节点中的分界关键字^[当前结点前驱的前驱。] 来填充当前结点。
     - **兄弟不够借**：
       - 若被删除的关键字的左右兄弟的关键字个数均等于 $\lceil m/2 \rceil-1$，则将当前结点与其中一个兄弟结点及父结点中的一个关键字^[当前结点的前驱。] 合并。
       - 由于合并操作会导致父结点中的关键字个数减少，因此如果合并后父结点中的关键字数量不满足 B 树的性质，则需要对父结点进行相同的调整或合并操作。
         - 如果递归操作一直进行到根结点，导致根结点中的关键字个数减少到 0，则将根结点删除，并将合并后的子树作为新的根结点。

通过这样的步骤，可以确保在删除关键字后，B 树仍然保持其结构特性，从而维持良好的平衡性和高效的查找性能。

[^直接前驱]: 即左子树的最右结点。
[^直接后继]: 即右子树的最左结点。

> [!example]- 删除结点
> ![[image/查找-10.png#center|删除结点]]

### B+ 树

B+ 树是应数据库所需而出现的一种 B 树的变形树。

> [!definition|Definition] B+ 树
> 一棵 $m$ 阶 B+ 树应满足下列条件：
> 1. 每个分支结点最多有 $m$ 棵子树 (孩子结点)。
> 2. 非叶根结点至少有两棵子树，其他每个分支结点至少有 $\lceil m/2 \rceil$ 棵子树。
> 3. 结点的子树个数与关键字个数相等。
> 4. 所有叶结点包含全部关键字及指向相应记录的指针，叶结点中将关键字按大小顺序排列，并且相邻叶结点按大小顺序互相链接起来 (支持顺序查找)。
> 5. 所有分支结点 (可视为索引的索引) 中仅包含它的各个子结点 (即下一级的索引块) 中关键字的最大值及指向其子结点的指针。

> [!tip] B+ 树其实就是增加了索引的有序线性表。

> [!note] B+ 树与 B 树的对比
> 1. B+ 树中，具有 $n$ 个关键字的结点含有 $n$ 棵子树。在 B 树中，具有 $n$ 个关键字的结点含有 $n+1$ 棵子树。
> 2. B+ 树中，叶结点包含了全部的关键字与指向相应记录的指针，非叶结点中出现的关键字也会出现在叶结点中。B 树汇总，最外层的终端结点的关键字与其余结点的关键字是不重复的。
> 3. B+ 树中，叶结点包含信息，所有的非叶结点仅起到了索引的作用, 只包含对应子树的最大关键词与指向该子树的指针，不含有对应记录的存储地址。
> 4. B+ 树中，用一个指针指向关键字最小的叶结点，使得所有叶结点串成了一个线性链表。
> 5. B+ 树无论如何都要找到叶结点才能确定是否找到目标对象。

> [!example]- B+ 树的结构
> ![[image/查找-11.png#center|B+树结构]]

> [!info]- B+ 树为什么性能高？
> B+ 树的每个索引中只保存了下一层的指针，而不保存数据，使得在索引中一个关键字对应的信息量较小。而计算机在读取索引时是以磁盘块为单位读取的，这种结构可以使一个磁盘块包含尽可能多的关键字的信息，使得 B+ 树的阶更大，树高更矮，读取磁盘的次数更少，查找更快。

> [!tip] m 阶 B 树与 B+ 树的对比
> |      性质    |    B 树    |     B+ 树      |
> | :------: | :-------: | :----------: |
> | 结点关键字的个数 |  $m-1$ 个  |    $m$ 个     |
> |   非叶结点   | 保存数据、划分子树 |   仅起索引的作用    |
> |   关键字    |  每个结点不重复  | 非叶结点保存叶结点的最大 |
> |   存取方式   |   随机存取    |  顺序存取和随机存取   |

## 散列表

 > [!info] 散列表 (hash table)
 > 在现代软件开发和算法设计中，散列表（Hash Table）作为一种高效的数据结构，扮演着极其重要的角色。它允许我们以接近常数时间复杂度的方式进行数据的插入、删除和查找操作，极大地提高了程序的性能。散列表之所以能够如此高效，得益于它独特的设计原理——通过散列函数将数据映射到表中的特定位置，从而实现了快速访问。

> [!definition|散列函数] 散列函数 (哈希函数) 把查找表中的关键字映射成该关键字对应的地址的函数，记为 `Hash(key)=Addr`。

> [!definition|散列表] 散列表 (哈希表) 是根据关键字而直接进行访问的数据结构，也就是说，散列表通过散列函数建立了关键字与存储地址之间的一种直接映射关系。

在理想情况下，对散列表进行查找的时间复杂度为 $O(1)$，即与表中元素的个数无关。

### 散列函数的构造方法

> [!note] 构造散列函数的目标
> 1. 散列函数的定义域必须包含全部关键字，而值域的范围则依赖与散列表的大小 (散列函数的值域不能超过散列表的范围)。
> 2. 散列函数计算出的地址应该尽可能均匀地分布在整个地址空间，尽可能地减少冲突。
> 3. 散列函数应尽量简单，能在较短的时间内计算出任意一个关键字对应的散列地址。

下面介绍一些常用的散列函数构造方法：
1. **除留余数法**：`H(key) = key % p`。设散列表的表长为 $m$，取一个不大于 $m$ 但是最接近或者等于 $m$ 的质数 `p`。
2. **直接定址法**：`H(key) = key` 或者 `H(key) = a*key + b`。这种方法不会产生冲突，适合关键字的分布基本连续的情况。
3. **数字分析法**：选取数码分布较为均匀的若干位作为散列地址。
4. **平方取中法**：取关键字的平方值的中间几位作为散列地址。适合用于关键字的每位取值都不够均匀的情况。

### 冲突

任何实际出来的散列函数都不可能绝对的避免冲突，为此必须考虑在发生冲突时应该如何处理。

#### 拉链法

拉链法使用一种朴素的思想处理冲突：把所有同义词 [^同义词] 存储在一个链表中。其操作过程为：
1. 插入操作：散列表中存储链表指针，当插入一个元素时，将其插入到散列地址对应的链表中。(插入方式如果没有说明，默认为头插法)
2. 查找操作：计算出散列地址，然后检查对应的链表是否包含目标值。
3. 删除操作：计算出散列地址，然后在链表中找到目标元素，然后删除。

[^同义词]: 通过散列函数映射到同一地址的元素。

> [!note] 如果在插入链表的时候，保持链表是有序的，可以提高查找的效率。

#### 开放定址法

开放定址法的基本思想为：如果发生冲突，给新元素找另外一个空闲位置。数学递推公式为：
$$
H_{i}=(H(\text{Key})+d_{i}) \% m
$$
式中，$H(\text{key})$ 为散列函数，$i=1,2,\cdots,k(k\leqslant m-1)$；$m$ 表示散列表表长，$d_{i}$ 为增量序列。

> [!note] 增量序列的取法
> 1. **线性探测法**：$d_{i}=0,1,2,3,\cdots,m-1$。
> 2. **平方探测法**：$d_{i}=1^{2},-1^{2},2^{2},-2^{2},\cdots,k^{2},-k^{2}$。
> 3. **双散列法**：$d_{i}=i\times H_{2}(\text{key})$。使用两个散列函数，当第一个散列函数得到的结果冲突时，使用第二个散列函数计算关键字地址的增量。
> 4. **伪随机序列法**：实现设置一个伪随机序列，每次 $d_{i}$ 都取该伪随机序列中第 $i$ 个元素。

> [!note] 堆积现象
> 在线性探测法中，可能将第 $i$ 个散列地址的同义词存储到第 $i+1$ 个单元中，这会使得本应该存储在 $i+1$ 散列地址的元素争夺第 $i+2$ 个散列地址的元素的地址，依次类推，使得散列表的存储效率大大降低。这种现象被称为**聚集** (或者**堆积** )。
>
> 使用平方探测法可以避免出现堆积现象，但是它的缺点是不能探测到散列表上的所有单元，但是至少能够探测到一半的单元。

> [!tip] 开放定址法的删除
> 采用开放定址法时，不能随便删除物理表中已有的元素，否则会截断其他同义词元素的查找路径，因此要删除一个元素时，可以做一个删除标记，进行逻辑删除。但是这样做的副作用是执行多次删除后，表面上看散列表是满的，但是实际上有很多的位置未利用。

### 散列查找性能分析

虽然散列表在关键字与记录的存储位置之间建立了直接映射，但是由于冲突的产生，使得散列表的查找过程仍然是一个给定值和关键词进行比较的过程。因此，仍然需要以平均查找长度作为衡量散列表的查找效率的度量。

散列表的查找效率主要取决于三个因素：散列函数、处理冲突和装填因子。其中装填因子定义为
$$
\alpha=\frac{\text{表中的记录数}n}{\text{散列表长度}m}
$$
装填因子定义为一个表的装满程度，散列表的平均查找长度依赖于散列表的装填因子 $\alpha$，而不直接依赖于 $n$ 或 $m$。

> [!tip] 散列表的重点
> 考研要求在给出散列表长度、元素个数及散列函数和解决冲突的方法后，在求出散列表的基础上计算出查找成功时的平均查找长度和查找不成功的平均查找长度。

---
< [[数据结构/图|图]] | [[数据结构/排序|排序]] >
