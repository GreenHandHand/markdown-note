---
aliases:
  - line
  - line detection
tag:
  - 计算机视觉
---

# 直线检测

给定一幅图像中点的集合，检测直线。这项任务实际上是图像目标检测任务的一个子集，在计算机视觉的早期被研究。

在进行了[[边缘检测]]之后，我们可以得到一些用于描述物体边界的像素。在此基础上，我们可以通过这些像素来对物体的形状进行判断。

## Naïve 直线检测

在边缘的基础上，我们可以计算每一对边缘像素，然后计算它们的直线表达式，并核对其他的像素中是否存在满足该表达式的像素。

对于 $N$ 个边缘像素图像，计算复杂度为 $O(N^2)$。这是最简单直接的进行直线检测的方式，但是我们可以使用霍夫变换以更低的代价进行计算。

## 霍夫变换

霍夫变换是图像处理中一个重要的算法。它通过一种投票算法检测具有特定形状的物体，该过程在参数空间中通过累计计算结果的局部最大值得到一个符合特定形状的集合作为霍夫变换的结果。该方法可以进行圆、直线、椭圆等形状的检测。

霍夫变换在 1962 年由 Paul Hough 首次提出，并在 1972 年被推广使用，是图像处理领域内从图像中检测几何形状的基本方法之一。经典霍夫变换用来检测图像中的直线，后来霍夫变换经过拓展可以通过任意形状物体的识别。

霍夫变换运用两个空间坐标之间的变换，将一个空间中具有相同形状的曲线或者直线映射到另一个空间坐标的一个点上形成峰值，从而将检测任意形状的问题转换为了统计峰值问题。

### 霍夫变换直线检测算法

设图像中的边缘点的坐标为 $(x_i,y_i)$，则可以使用 $y_i=ax_i+b$ 表示经过该点的所有直线。现在，我们将 $a$ 与 $b$ 作为变量，则对于所有的**边缘点对**，我们可以求得对应其对应的 $a$ 与 $b$ 的值。

或者说，我们将原来的 $(x_i,y_i)$ 坐标空间转化到了 $(a,b)$ 的参数空间。对于参数空间的的每一条直线 $b=-x_ia+y_i$，我们可以求得其交点坐标 $(a',b')$，如果有多条直线相交与这个点上，就说明这些直线都满足 $y=a'x+b'$ 这个参数方程，于是有这些点在同一条直线上。

在实际中，我们使用一个二维数组来记录这些交点坐标，每当计算得到两个像素对应的 $(a',b')$，我们将这个数组中的对应值增加 1。最后，我们可以将这个数组中值大于特定阈值的所有点视为一条直线。

将用于直线的霍夫变换推广一下，我们可以很容易得到用于任意具有参数表达式的图形检测。于是霍夫变换进行检测的算法可以描述如下：
```pseudo
	\begin{algorithm}
	\caption{Hough Transform Algorithm}
	\begin{algorithmic}
	\State  For the equation $f(x,y;\lambda_1,\lambda_2,\cdots)$ that requires detection do.
		\For{each $(x,y)$ edge point} 
			\State vote on cells that satisfy the corresponding $(\lambda_1,\lambda_2,\cdots)$ equation
		\EndFor 
		\State Find cells with more votes than threshold
	\end{algorithmic}
	\end{algorithm}
```

> 在实际中，我们常在极坐标中计算直线检测，极坐标有两个好处：
> 1. 极坐标中的参数 $\theta$ 是有界的，因此可以很好的控制计数矩阵的大小。
> 2. 极坐标中可以表示斜率为 0 的直线，但是在直角坐标中不可以。

霍夫变换进行检测具有下面的特点：
1. 好处：概念简单，易于实现，可以处理缺失、遮挡数据，可以处理多种形状的物体
2. 缺陷：对具有许多参数的对象而言计算上复杂。仅寻找单一类型的对象。共线的线段无法分开。可能会被“表面上的线”所欺骗。无法确定线段的长度和位置。

## RANSAC

RANSAN (Random Sample Consensus) 随机采样一致算法是从一组含有外点 (outliers) 的数据中正确估计数学模型参数的迭代算法。该算法描述如下：
```pseudo
	\begin{algorithm}
	\caption{RANSAC}
	\begin{algorithmic}
		\Repeat 
			\State Randomly select a seed group of points on which perform a model estimate
			\State Compute model parameters from seed group
			\State Calaulate distances and find inliers to this model
			\State If the number of inliers is sufficiently large, recompute least-squares estimate of model on all of the inliers
		\Until{iterated k times} 
	\Return The model with the largest number of inliers
	\end{algorithmic}
	\end{algorithm}
```
在该算法中，需要指名的一个超参数是迭代的次数，除了根据经验进行选择，这个超参数的值是可以估算的。假设 $w$ 是内点在数据中的占比，$n$ 是估计模型需要的数据数量，$k$ 是采样次数，那么可以计算下面的这些概率：
1. 经过一次采样得到正确的模型的概率：$w^n$
2. 经过一次采样得到错误的模型的概率：$1-w^n$
3. 经过 $k$ 次采样得到错误模型的概率：$(1-w^n)^k$
4. 经过 $k$ 次采样，得到至少一次正确的模型的概率 $(1-(1-w^n))^k$

我们可以得出结论，只要选择了足够多的采样次数，可以将错误的出现率降到非常低。

最后，RANSAC 方法是一种通用的方法，适用于各种模型拟合问题，实现简单，易于计算其错误率。

但是 RANSAC 方法只能处理适度百分比的离群值，超过这个限度成本就会激增，在现实中，许多实际问题存在高比例的离群值，但有时通过选择随机子集的方式可能有所帮助。